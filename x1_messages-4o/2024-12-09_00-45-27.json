[
    {
        "role": "user",
        "content": "I'm trying to use the Python LRU Cache decorator from this source: http://code.activestate.com/recipes/578078-py26-and-py30-backport-of-python-33s-lru-cache/. I've created a decorated class method with this decorator, but it ends up creating a global cache that applies to all instances of my class 'Test'. However, my intent was to create a per instance cache. When I instantiate three 'Test' objects, I want to have three separate LRU caches, rather than a single LRU cache for all three instances. I noticed this issue when calling the cache_info() on the different class instances' decorated methods; they all return the same cache statistics, which is extremely unlikely given they are being interacted with very different arguments. Here is my code:\n\n```python\nfrom lru_cache import lru_cache\nclass Test:\n    @lru_cache(maxsize=16)\n    def cached_method(self, x):\n         return x + 5\n```\n\nAnd here are the cache statistics I get from all three instances:\n\n```python\nCacheInfo(hits=8379, misses=759, maxsize=128, currsize=128)\nCacheInfo(hits=8379, misses=759, maxsize=128, currsize=128)\nCacheInfo(hits=8379, misses=759, maxsize=128, currsize=128)\n```\n\nIs there a decorator or trick that would allow me to easily cause this decorator to create a cache for each class instance?"
    },
    {
        "role": "assistant",
        "content": "To achieve a per-instance cache using the LRU cache mechanism, you can modify your approach to bind the cache to each instance rather than the method itself. This can be done by using a custom decorator or by managing the cache within the instance. Here's how you can implement it by initializing the cache in the `__init__` method of your class:\n\n```python\nfrom functools import lru_cache, partialmethod\n\nclass Test:\n    def __init__(self):\n        # Create a per-instance cache using functools.lru_cache\n        self.cached_method = lru_cache(maxsize=16)(self._cached_method)\n    \n    def _cached_method(self, x):\n        return x + 5\n\n    def cache_info(self):\n        # Return cache info for the current instance's cached method\n        return self.cached_method.cache_info()\n\n# Example usage\ntest1 = Test()\ntest2 = Test()\ntest3 = Test()\n\n# Use the cached method\nprint(test1.cached_method(10))\nprint(test2.cached_method(20))\nprint(test3.cached_method(30))\n\n# Check cache info\nprint(test1.cache_info())\nprint(test2.cache_info())\nprint(test3.cache_info())\n```\n\n### Explanation:\n\n1. **Instance-Specific Cache**: By moving the cache initialization to the `__init__` method, each instance of the class `Test` will have its own cache.\n\n2. **Method Wrapping**: The `_cached_method` is the actual method that does the computation. The `cached_method` is a wrapper around `_cached_method` that applies the LRU cache.\n\n3. **Cache Info**: You can access the cache information specific to each instance using the `cache_info` method.\n\nThis approach ensures that each instance of `Test` has its own LRU cache, and the cache statistics will reflect the operations performed on each individual instance."
    }
]