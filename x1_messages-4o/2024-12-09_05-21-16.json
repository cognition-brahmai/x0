[
    {
        "role": "user",
        "content": "I am using Pytorch's multiprocessing module to spawn a couple of processes within an OpenMPI distributed back-end. The code I have written is below. When I run this code using OpenMPI, I understand that it creates two processes with ranks [0, 1], each of which spawn new processes with their local rank as 0. However, when I try to communicate between these two sub-processes of the main process, I receive an error saying \"Default process group is not initialized\". How can I make these sub-processes communicate, specifically the [0, 0] process sending something to the [1, 0] process?\n\n<pre><code>def run(rank_local, rank, world_size, maingp):\n    print(\"I WAS SPAWNED \", rank_local, \" OF \", rank)\n\n    tensor = torch.zeros(1)\n    tensor += 1\n\n    if rank == 0:\n        tensor += 100\n        dist.send(tensor, dst=1)\n    else:\n        print(\"I am spawn: \", rank, \"and my tensor value before receive: \", tensor[0])\n        dist.recv(tensor, src=0)\n        print(\"I am spawn: \", rank, \"and my tensor value after  receive: \", tensor[0])\n\n\nif __name__ == '__main__':\n\n    # Initialize Process Group\n    dist.init_process_group(backend=\"mpi\", group_name=\"main\")\n    maingp = None #torch.distributed.new_group([0,1])\n    mp.set_start_method('spawn')    \n\n    # get current process information\n    world_size = dist.get_world_size()\n    rank = dist.get_rank()\n\n    # Establish Local Rank and set device on this node\n    mp.spawn(run, args=(rank, world_size, maingp), nprocs=1)\n</code></pre>\n\nThe error received is as follows:\n\n<pre><code>-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/home/usama/anaconda3/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\", line 19, in _wrap\n    fn(i, *args)\n  File \"/home/usama/code/test/code.py\", line 19, in run\n    dist.send(tensor, dst=1)\n  File \"/home/usama/anaconda3/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py\", line 666, in send\n    _check_default_pg()\n  File \"/home/usama/anaconda3/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py\", line 191, in _check_default_pg\n    \"Default process group is not initialized\"\nAssertionError: Default process group is not initialized\n</code></pre>"
    },
    {
        "role": "assistant",
        "content": "The issue you're encountering is related to the initialization of the default process group in your sub-processes. When you spawn new processes using `torch.multiprocessing`, these sub-processes do not automatically inherit the distributed environment from the parent process. You need to initialize the process group in each of the spawned processes.\n\nHere's how you can modify your code to ensure that each spawned process is part of the process group and can communicate with each other:\n\n```python\nimport torch\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\ndef run(rank_local, rank, world_size, maingp):\n    # Initialize Process Group\n    dist.init_process_group(backend=\"mpi\", rank=rank, world_size=world_size)\n\n    print(\"I WAS SPAWNED \", rank_local, \" OF \", rank)\n\n    tensor = torch.zeros(1)\n    tensor += 1\n\n    if rank_local == 0:\n        tensor += 100\n        dist.send(tensor, dst=1)\n    else:\n        print(\"I am spawn: \", rank_local, \"and my tensor value before receive: \", tensor[0])\n        dist.recv(tensor, src=0)\n        print(\"I am spawn: \", rank_local, \"and my tensor value after  receive: \", tensor[0])\n\n    # Cleanup\n    dist.destroy_process_group()\n\nif __name__ == '__main__':\n    # Initialize Process Group in main process\n    dist.init_process_group(backend=\"mpi\")\n    \n    # get current process information\n    world_size = dist.get_world_size()\n    rank = dist.get_rank()\n\n    # Spawn processes\n    mp.set_start_method('spawn')    \n    mp.spawn(run, args=(rank, world_size, None), nprocs=1)\n```\n\n### Key Points:\n1. **Initialization in Sub-processes**: Each sub-process must initialize its own process group. This is why `dist.init_process_group` is called inside the `run` function.\n\n2. **Rank and World Size**: When initializing the process group in the sub-process, you need to provide the correct `rank` and `world_size`. This ensures that each sub-process knows its place in the distributed setting.\n\n3. **Process Group Cleanup**: After the communication is done, it's a good practice to destroy the process group using `dist.destroy_process_group()` to clean up resources.\n\n4. **Backend Consistency**: Make sure the backend used (`mpi` in this case) is correctly supported and configured in your environment.\n\nThis setup should allow the spawned sub-processes to communicate correctly within the MPI distributed setting."
    }
]