[
    {
        "role": "user",
        "content": "How can I adjust the NLTK sentence tokenizer to handle terminal double quotes and titles like \"Mrs.\" correctly? I am using NLTK to analyze classic texts and I am having trouble tokenizing the text by sentence. For instance, when I try to tokenize a snippet from Moby Dick, the output is not as expected. I'd prefer a solution that allows me to modify a simple heuristic rather than having to train my own parser. Here is the code I am using:\n\n```python\nimport nltk\nsent_tokenize = nltk.data.load('tokenizers/punkt/english.pickle')\n\nsample = 'A clam for supper? a cold clam; is THAT what you mean, Mrs. Hussey?\" says I, \"but that\\'s a rather cold and clammy reception in the winter time, ain\\'t it, Mrs. Hussey?\"'\n\nprint \"\\n-----\\n\".join(sent_tokenize.tokenize(sample))\n```\n\nThe output I get is:\n```\n\"A clam for supper?\n-----\na cold clam; is THAT what you mean, Mrs.\n-----\nHussey?\n-----\n\" says I, \"but that\\'s a rather cold and clammy reception in the winter time, ain\\'t it, Mrs.\n-----\nHussey?\n-----\n\"\n```\nThis is not ideal as it breaks up the sentence in the wrong places."
    },
    {
        "role": "assistant",
        "content": "To improve the sentence tokenization for your text, especially to handle terminal double quotes and titles like \"Mrs.\" correctly, you can customize the Punkt tokenizer in NLTK by adding specific abbreviations and modifying sentence boundary detection. Here's how you can adjust your code:\n\n1. **Customize Abbreviations**: Add common titles or abbreviations that the tokenizer should recognize as non-sentence boundaries.\n\n2. **Adjust Sentence Boundary Detection**: Modify the tokenizer's behavior to better handle quotes.\n\nHere's how you can do it:\n\n```python\nimport nltk\nfrom nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n\n# Define custom abbreviations to help the tokenizer\npunkt_param = PunktParameters()\nabbreviation_patterns = ['Mrs', 'Mr', 'Dr', 'Prof', 'Sr', 'Jr']\npunkt_param.abbrev_types = set(abbreviation_patterns)\n\n# Initialize the tokenizer with the custom parameters\ntokenizer = PunktSentenceTokenizer(punkt_param)\n\n# Sample text\nsample = ('A clam for supper? a cold clam; is THAT what you mean, Mrs. Hussey?\" says I, '\n          '\"but that\\'s a rather cold and clammy reception in the winter time, ain\\'t it, Mrs. Hussey?\"')\n\n# Tokenize the sample text\nresult = tokenizer.tokenize(sample)\n\n# Print the tokenized sentences\nprint(\"\\n-----\\n\".join(result))\n```\n\n### Explanation:\n\n1. **PunktParameters**: This allows you to customize the behavior of the Punkt tokenizer. By defining `abbrev_types`, you let the tokenizer know which abbreviations shouldn't be treated as sentence boundaries.\n\n2. **Quotes Handling**: The Punkt tokenizer should handle quotes better with these adjustments, but if you still encounter issues, consider preprocessing your text to temporarily replace terminal quotes with unique markers and then revert them post-tokenization.\n\nThis setup should provide more accurate sentence tokenization for texts like \"Moby Dick\" where titles and quotes are prevalent. If further customization is needed, you might also consider post-processing the results to fine-tune the sentence splits based on specific rules you define."
    }
]