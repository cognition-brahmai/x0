[
    {
        "role": "user",
        "content": "I am working with a Celery task, which is something like this:\n```python\n@task()\ndef async_work(info):\n    ...\n```\nI may need to call async_work with some information at any time. However, for some specific reasons, I need to ensure that only one async_work is running at any given time and all other calling requests must wait. I tried implementing this with the following code:\n```python\nis_locked = False    \n@task()\ndef async_work(info):\n    while is_locked:\n        pass\n    is_locked = True\n    ...\n    is_locked = False\n```\nBut, the system is throwing an error saying it's invalid to access local variables. How can I solve this issue?"
    },
    {
        "role": "assistant",
        "content": "The problem you are encountering is due to the fact that the `is_locked` variable is not shared across different instances of the task execution. Each task runs in its own process, and thus, the `is_locked` variable is local to each process. This means that your current approach won't effectively ensure that only one task runs at a time.\n\nTo achieve the desired behavior, you can use a distributed lock. One common way to implement this in a Celery task is by using Redis as a locking mechanism. Here's how you can do it:\n\n1. Install the `redis` library if you haven't already:\n\n   ```bash\n   pip install redis\n   ```\n\n2. Use a Redis lock in your task:\n\n```python\nfrom celery import shared_task\nimport redis\nimport time\n\n# Initialize the Redis client\nredis_client = redis.StrictRedis(host='localhost', port=6379, db=0)\n\n@shared_task(bind=True)\ndef async_work(self, info):\n    lock_name = \"async_work_lock\"\n    lock = redis_client.lock(lock_name, timeout=60)  # Timeout to avoid deadlocks\n\n    try:\n        if lock.acquire(blocking=True):\n            # Perform the task\n            print(f\"Processing: {info}\")\n            time.sleep(10)  # Simulate work by sleeping\n            # Complete the task\n    finally:\n        lock.release()\n```\n\n### Key Points:\n- **Redis Lock**: We create a lock using the `redis-py` library. The lock is unique across the Redis server, meaning that only one task can hold it at any moment.\n- **Timeout**: The `timeout` parameter ensures that the lock is automatically released if the task takes too long, preventing potential deadlocks if a task fails and doesn't release the lock.\n- **Blocking**: By setting `blocking=True`, other tasks will wait until the lock becomes available.\n\nMake sure your Redis server is running and configured correctly to use this solution. This approach will ensure that only one `async_work` task runs at a time, and others wait until the lock is released."
    }
]