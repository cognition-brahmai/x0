[
    {
        "role": "user",
        "content": "I have recently started using 'poetry' for dependency management in a project where we use PyTorch. Our work involves both machines with no access to a CUDA GPU and workstations with CUDA GPUs. How can I use poetry to ensure every developer is using the same PyTorch version? Is there a way I can set the total path to the different online wheels, similar to how 'pip3' install is done? Here's the 'pip3' command we use: \n\n```python\npip3 install torch==1.3.1+cpu torchvision==0.4.2+cpu -f https://download.pytorch.org/whl/torch_stable.html\n```\n\nI would like to avoid adding them directly to git, and the closest option I've found in poetry is either downloading them manually and then using the `file = X` command."
    },
    {
        "role": "assistant",
        "content": "To manage PyTorch dependencies using poetry across different environments (with and without CUDA GPUs), you can leverage poetry's support for custom package sources along with its ability to specify platform-specific dependencies. Here\u2019s how you can configure your `pyproject.toml` to achieve this:\n\n1. **Add the PyTorch Custom Source:**\n\n   You can specify the custom source URL for the PyTorch wheels in the `[tool.poetry.source]` section of your `pyproject.toml`. Unfortunately, poetry doesn\u2019t support `-f` like pip does directly, but you can specify the `source` as an alternative.\n\n   ```toml\n   [tool.poetry.source]\n   name = \"pytorch\"\n   url = \"https://download.pytorch.org/whl/torch_stable.html\"\n   ```\n\n2. **Specify the Dependencies:**\n\n   In the `[tool.poetry.dependencies]` section, you can specify conditional dependencies based on the environment. Poetry doesn\u2019t support platform tags like `+cpu` directly, but you can specify optional dependencies and then install them conditionally.\n\n   ```toml\n   [tool.poetry.dependencies]\n   python = \"^3.8\"  # or your specific Python version\n   torch = { version = \"1.3.1\", source = \"pytorch\" }\n   torchvision = { version = \"0.4.2\", source = \"pytorch\" }\n\n   [tool.poetry.extras]\n   cpu = [\"torch==1.3.1+cpu\", \"torchvision==0.4.2+cpu\"]\n   cuda = [\"torch==1.3.1+cu102\", \"torchvision==0.4.2+cu102\"]\n   ```\n\n3. **Installing the Correct Version:**\n\n   When you're setting up your environment, you can use the `--extras` flag to specify whether you want to install CPU or CUDA versions:\n\n   ```sh\n   # For CPU-only machines\n   poetry install --extras \"cpu\"\n\n   # For machines with CUDA\n   poetry install --extras \"cuda\"\n   ```\n\n4. **Handling Platform Constraints:**\n\n   Alternatively, you can use platform markers if your project is designed to run only on specific platforms. However, since this is more about CUDA vs. CPU, using extras is typically more flexible.\n\n5. **Environment Variables or Scripts:**\n\n   If you want to automate which dependencies get installed based on the machine, you could also use environment variables or simple scripts to detect the presence of a GPU and then pass the appropriate extras flag to the `poetry install` command.\n\nBy setting up your `pyproject.toml` in this way and using the extras feature, you can ensure that all developers are using the same version of PyTorch suitable for their specific environment without manually managing wheel files."
    }
]