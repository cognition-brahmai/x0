[
    {
        "role": "user",
        "content": "I am trying to update a MongoDB collection using the Python driver (pymongo). My requirement is to insert each item that does not already exist from the daily stock of documents I receive. I also want to keep track of the first time I inserted them, and the last time I saw them in an update. I do not want to have duplicate documents or remove a document which has previously been saved but is not in my update. I estimate that 95% of the records are unmodified from day to day. My current approach, provided below, is very slow (40 mins for less than 100 000 records, and I have millions of them in the update). I am seeking a faster method to achieve this. \n\n```\nfor each document in update:\n      existing_document = collection.find_one(document)\n      if not existing_document:\n           document['insertion_date'] = now\n      else:\n           document = existing_document\n      document['last_update_date'] = now\n      my_collection.save(document)\n```"
    },
    {
        "role": "assistant",
        "content": "Your current approach has performance issues primarily because of the repeated queries and updates for each document in the loop. Instead, you can make use of MongoDB's `bulk_write` operations to perform batch updates and inserts, which can significantly improve performance.\n\nHere's an optimized approach using `bulk_write` with `UpdateOne` and `InsertOne` operations:\n\n```python\nfrom pymongo import MongoClient, UpdateOne, InsertOne\nfrom datetime import datetime\n\n# Establish a connection to your MongoDB\nclient = MongoClient('mongodb://localhost:27017/')\ndb = client['your_database']\ncollection = db['your_collection']\n\n# Your daily stock of documents\ndaily_documents = [...]  # Replace this with your list of documents\n\n# Get the current time for insertion and update timestamps\nnow = datetime.now()\n\noperations = []\nfor doc in daily_documents:\n    # Create a filter to find an existing document\n    filter_doc = {'_id': doc['_id']}  # Assuming each document has a unique _id\n\n    # Prepare the update operation\n    update_doc = {\n        '$setOnInsert': {'insertion_date': now},\n        '$set': {'last_update_date': now}\n    }\n\n    # Add the operation to the list\n    operations.append(\n        UpdateOne(filter_doc, update_doc, upsert=True)\n    )\n\n# Perform bulk write operation\nif operations:\n    result = collection.bulk_write(operations)\n    print(f\"Matched: {result.matched_count}, Modified: {result.modified_count}, Upserts: {result.upserted_count}\")\n\n# Close the MongoDB connection\nclient.close()\n```\n\n### Key Improvements:\n1. **Bulk Operations**: This approach uses `bulk_write` to perform all updates and inserts in a single batch, reducing the overhead of multiple database round trips.\n\n2. **`UpdateOne` with `upsert=True`**: This ensures that if a document with the specified `_id` exists, it will be updated; otherwise, it will be inserted.\n\n3. **Timestamps with `$setOnInsert` and `$set`**: This efficiently sets the timestamps, updating `last_update_date` on every run and setting `insertion_date` only on the first insert.\n\n4. **Efficient Filtering**: Uses the `_id` field to uniquely identify documents for updates. Ensure that your documents have a unique identifier, which is typically `_id`.\n\nThis should significantly reduce the time taken for updates and inserts, especially when dealing with large datasets."
    }
]