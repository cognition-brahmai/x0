[
    {
        "role": "user",
        "content": "Why does multiprocessing utilize only a single core after importing numpy in Python? I am attempting to parallelize a CPU-intensive `for` loop using `joblib`, but all worker processes seem to be assigned to the same core resulting in no performance gain. I am running Ubuntu 12.10 (3.5.0-26) on a laptop with 4 cores. How can I make these processes execute on different cores? The code I'm using is as below:\n\n```python\nfrom joblib import Parallel,delayed\nimport numpy as np\n\ndef testfunc(data):\n    # some very boneheaded CPU work\n    for nn in xrange(1000):\n        for ii in data[0,:]:\n            for jj in data[1,:]:\n                ii*jj\n\ndef run(niter=10):\n    data = (np.random.randn(2,100) for ii in xrange(niter))\n    pool = Parallel(n_jobs=-1,verbose=1,pre_dispatch='all')\n    results = pool(delayed(testfunc)(dd) for dd in data)\n\nif __name__ == '__main__':\n    run()\n```"
    },
    {
        "role": "assistant",
        "content": "The issue you're experiencing with multiprocessing and numpy can often be traced back to how numpy is linked with certain libraries like OpenBLAS or MKL, which themselves use multithreading. When these libraries are used in conjunction with parallel processing libraries like `joblib`, it can lead to oversubscription of threads, where multiple threads are trying to execute on the same core, thereby reducing performance.\n\nHere are some steps you can take to address this issue:\n\n1. **Limit Numpy Threading:**\n   Numpy, when linked with OpenBLAS or MKL, might use its own threading. You can limit this by setting the number of threads used by these libraries to 1. This can be done by setting environment variables before running your Python script:\n\n   ```bash\n   export OMP_NUM_THREADS=1\n   export OPENBLAS_NUM_THREADS=1\n   export MKL_NUM_THREADS=1\n   ```\n\n   You can also set these within your Python script using `os.environ`:\n\n   ```python\n   import os\n   os.environ['OMP_NUM_THREADS'] = '1'\n   os.environ['OPENBLAS_NUM_THREADS'] = '1'\n   os.environ['MKL_NUM_THREADS'] = '1'\n   ```\n\n2. **Check CPU Affinity:**\n   Sometimes, the operating system may set CPU affinity for processes in a way that limits them to a single core. You can check and set CPU affinity using the `taskset` command on Linux to ensure that your Python process can utilize all cores.\n\n3. **Avoid Oversubscription:**\n   Ensure that the number of jobs (`n_jobs`) you are setting in `Parallel` is equal to or less than the number of physical cores available. Setting it to `-1` should automatically utilize all cores, but you can also experiment with setting it explicitly to the number of physical cores.\n\n4. **Profile and Debug:**\n   Use profiling tools to analyze where the bottlenecks are occurring. Libraries like `cProfile` or `line_profiler` can help identify if the problem is with how the computation is structured or if there's a specific line causing the issue.\n\n5. **Consider Alternative Libraries:**\n   If the performance issue persists, consider using alternative libraries for parallel processing such as `concurrent.futures` or multiprocessing directly, which might offer different performance characteristics.\n\nBy setting the number of threads for these libraries to 1, you should see an improvement in your parallel processing performance as it allows joblib to manage the distribution of work across multiple cores more effectively."
    }
]