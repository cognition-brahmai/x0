[
    {
        "role": "user",
        "content": "How can I get a filtered list of files in a directory using Python? I need to filter these files based on a specific pattern (for example, '145592*.jpg'), similar to using 'ls 145592*.jpg' in the terminal. I am currently thinking of using a for loop to iterate through the results of an 'os.listdir()' and to append all the matching files to a new list. But considering the large number of files in the directory, is there a more efficient or built-in method to achieve this?"
    },
    {
        "role": "assistant",
        "content": "Yes, there is a more efficient and convenient way to get a filtered list of files in a directory based on a specific pattern using Python. You can use the `glob` module, which is designed for pattern matching in file names. It works similarly to the shell's wildcard functionality.\n\nHere's how you can use the `glob` module to achieve your goal:\n\n```python\nimport glob\nimport os\n\n# Define the directory and the pattern\ndirectory_path = '/path/to/your/directory'\npattern = '145592*.jpg'\n\n# Use glob to find all files that match the pattern\nmatched_files = glob.glob(os.path.join(directory_path, pattern))\n\n# Output the list of matched files\nfor file in matched_files:\n    print(file)\n```\n\n### Explanation:\n\n- **`glob.glob(pattern)`**: This function returns a list of file paths that match the given pattern. The pattern can include wildcards like `*`, `?`, and `[]`.\n\n- **`os.path.join(directory_path, pattern)`**: This is used to create the full search pattern by combining the directory path with the file pattern.\n\nUsing `glob` is more efficient and concise than manually iterating through the directory with a for loop and filtering files, especially when dealing with a large number of files. It leverages underlying system capabilities for pattern matching, making it both fast and easy to use."
    }
]