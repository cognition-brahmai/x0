[
    {
        "role": "user",
        "content": "How can I write out large data files to a CSV file in chunks using Pandas? I have large data files (1M rows x 20 cols) and I am only interested in 5 columns. I am trying to read the file into a dataframe in chunks and then write to a CSV file. However, I am not finding any method to write out the data to a CSV file in chunks. Here is the code I am currently using:\n\n```python\nwith open(os.path.join(folder, filename), 'r') as src:\n    df = pd.read_csv(src, sep='\\t',skiprows=(0,1,2),header=(0), chunksize=1000)\n    for chunk in df:\n        chunk.to_csv(os.path.join(folder, new_folder,\n                              \"new_file_\" + filename), \n                              columns = [['TIME','STUFF']])\n```\nBut this doesn't append the CSV file. How can I solve this?"
    },
    {
        "role": "assistant",
        "content": "To write out data in chunks to a CSV file using Pandas, you can use the `mode` parameter in the `to_csv()` function to append to the file rather than overwrite it. Also, ensure you include `header` in the first chunk only. Here's how you can modify your code:\n\n```python\nimport os\nimport pandas as pd\n\n# Define the source file and output file paths\nfolder = 'your_folder_path'\nfilename = 'your_filename.txt'\nnew_folder = 'output_folder'\noutput_file = os.path.join(folder, new_folder, \"new_file_\" + filename)\n\n# Create the output folder if it doesn't exist\nos.makedirs(os.path.join(folder, new_folder), exist_ok=True)\n\n# Read and process the file in chunks\nwith open(os.path.join(folder, filename), 'r') as src:\n    df_iter = pd.read_csv(src, sep='\\t', skiprows=(0, 1, 2), header=(0), chunksize=1000)\n    for i, chunk in enumerate(df_iter):\n        # Select only the columns you're interested in\n        subset = chunk[['TIME', 'STUFF']]\n        \n        # Write to CSV with mode 'a' to append, and header only for the first chunk\n        subset.to_csv(output_file, mode='a', header=(i == 0), index=False)\n```\n\n### Key Points:\n1. **Chunksize**: This parameter allows you to read the file in chunks, which is useful for large files.\n2. **Mode 'a'**: The `mode='a'` argument in `to_csv` allows appending to the file instead of overwriting it.\n3. **Header**: Write the header only once, during the first chunk, to avoid duplicating the column names.\n\nReplace `'your_folder_path'` and `'your_filename.txt'` with your actual folder path and file name. This code should help you efficiently process large files and write the desired columns to a CSV in chunks."
    }
]