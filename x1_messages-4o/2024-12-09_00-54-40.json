[
    {
        "role": "user",
        "content": "I'm working on generating a depth map using an uncalibrated stereo system with OpenCV. I'm able to obtain the fundamental matrix by identifying correspondent points using SIFT and then applying `cv2.findFundamentalMat`. I then use `cv2.stereoRectifyUncalibrated` to get the homography matrices for each image. Following this, I use `cv2.warpPerspective` to rectify and compute the disparity, but the depth map I get is not satisfactory. The values appear very high which makes me wonder if I should be using `warpPerspective` or if I should be calculating a rotation matrix from the homography matrices I obtained with `stereoRectifyUncalibrated`. I'm uncertain about the projective matrix when dealing with the homography matrix obtained with `stereoRectifyUncalibrated`. Could there be a mistake in my procedure? Here is a part of my code:\n\n```python\n# Obtainment of the correspondent point with SIFT\nsift = cv2.SIFT()\n\n# Find the keypoints and descriptors with SIFT\nkp1, des1 = sift.detectAndCompute(dst1,None)\nkp2, des2 = sift.detectAndCompute(dst2,None)\n\n# FLANN parameters\nFLANN_INDEX_KDTREE = 0\nindex_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\nsearch_params = dict(checks=50)\n\nflann = cv2.FlannBasedMatcher(index_params,search_params)\nmatches = flann.knnMatch(des1,des2,k=2)\n\ngood = []\npts1 = []\npts2 = []\n\n# Ratio test as per Lowe's paper\nfor i,(m,n) in enumerate(matches):\n    if m.distance < 0.8*n.distance:\n        good.append(m)\n        pts2.append(kp2[m.trainIdx].pt)\n        pts1.append(kp1[m.queryIdx].pt)\n\npts1 = np.array(pts1)\npts2 = np.array(pts2)\n\n# Computation of the fundamental matrix\nF,mask= cv2.findFundamentalMat(pts1,pts2,cv2.FM_LMEDS)\n\n# Obtainment of the rectification matrix and use of the warpPerspective to transform them...\npts1 = pts1[:,:][mask.ravel()==1]\npts2 = pts2[:,:][mask.ravel()==1]\n\npts1 = np.int32(pts1)\npts2 = np.int32(pts2)\n\np1fNew = pts1.reshape((pts1.shape[0] * 2, 1))\np2fNew = pts2.reshape((pts2.shape[0] * 2, 1))\n\nretBool ,rectmat1, rectmat2 = cv2.stereoRectifyUncalibrated(p1fNew,p2fNew,F,(2048,2048))\n\ndst11 = cv2.warpPerspective(dst1,rectmat1,(2048,2048))\ndst22 = cv2.warpPerspective(dst2,rectmat2,(2048,2048))\n\n# Calculation of the disparity\nstereo = cv2.StereoBM(cv2.STEREO_BM_BASIC_PRESET,ndisparities=16*10, SADWindowSize=9)\ndisp = stereo.compute(dst22.astype(uint8), dst11.astype(uint8)).astype(np.float32)\nplt.imshow(disp);plt.colorbar();plt.clim(0,400)#;plt.show()\nplt.savefig(&quot;0gauche.png&quot;)\n\n# Plot depth by using disparity focal length `C1[0,0]` from stereo calibration and `T[0]` the distance between cameras\nplt.imshow(C1[0,0]*T[0]/(disp),cmap='hot');plt.clim(-0,500);plt.colorbar();plt.show()\n```\n\nI'm also trying to mount the reconstruction matrix with the homography matrix obtained with `stereoRectifyUncalibrated`, but the results are not satisfactory. Could there be a mistake in my approach?"
    },
    {
        "role": "assistant",
        "content": "Generating a depth map using an uncalibrated stereo system can be challenging because of the lack of intrinsic camera parameters and precise calibration between the images. Let's go through the steps you are taking and identify potential issues and improvements:\n\n1. **Feature Matching**: You're using SIFT for feature detection and FLANN for matching, which is a solid choice. The ratio test is also a good practice to filter out false matches. Ensure that your `des1` and `des2` are not empty and that you have enough good matches after the ratio test.\n\n2. **Fundamental Matrix**: You're computing the fundamental matrix using `cv2.findFundamentalMat` with `cv2.FM_LMEDS`, which is suitable for handling outliers. Ensure that the points are indeed corresponding and the mask is correctly applied.\n\n3. **Stereo Rectification**: \n   - You are using `cv2.stereoRectifyUncalibrated` to obtain the homography matrices. These matrices transform the images into a common plane, but keep in mind that they do not ensure the images are perfectly aligned like calibrated rectification would.\n   - It's crucial to ensure that the homography matrices are applied correctly. The `cv2.warpPerspective` should use these matrices to align the images for disparity computation.\n\n4. **Disparity Calculation**:\n   - You're using `cv2.StereoBM`, which is designed for calibrated stereo pairs. Since you are using an uncalibrated setup, the disparity might not be as accurate.\n   - Ensure the disparity range (`ndisparities`) and `SADWindowSize` are appropriate for your images. You might need to adjust these parameters based on your scene and image resolution.\n\n5. **Depth Map Calculation**:\n   - You're using the formula `C1[0,0]*T[0]/(disp)` for depth, which assumes you have the focal length (`C1[0,0]`) and the baseline (`T[0]`). These values need to be known or estimated accurately for meaningful depth values.\n   - Ensure that disparity values are not zero before division, as this would lead to infinite depth values. You might need to apply a mask to handle this.\n\n6. **Rectification with Homography**:\n   - The homography matrices from `stereoRectifyUncalibrated` do not directly provide rotation and translation between the cameras. If possible, try to estimate these parameters separately if they are critical for your application.\n   - Consider using a more advanced disparity algorithm like `cv2.StereoSGBM` which might provide better results with uncalibrated images.\n\n7. **Debugging and Verification**:\n   - Visualize intermediate results (rectified images, disparity map) to ensure each step is producing expected outputs.\n   - Use synthetic data or a known setup to verify the pipeline if possible.\n\n8. **Alternative Approaches**:\n   - If possible, calibrate your cameras or use a known stereo setup. This will significantly improve the quality of your depth map.\n   - Explore machine learning-based methods for depth estimation which might work better with uncalibrated data.\n\nBy carefully checking each step and considering these suggestions, you should be able to identify the source of the issue and improve the quality of your depth map."
    }
]