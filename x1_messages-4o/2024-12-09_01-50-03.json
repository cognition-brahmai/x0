[
    {
        "role": "user",
        "content": "What is the most Pythonic way to identify consecutive duplicates in a list? I have a list of integers and I want to identify contiguous blocks of duplicates, preserving the order of the list. The result should be a list of tuples where each tuple contains the integer and its number of occurrences. For example, if I have a list like [0, 0, 0, 3, 3, 2, 5, 2, 6, 6], I want the result to be [(0, 3), (3, 2), (2, 1), (5, 1), (2, 1), (6, 2)]. I have a solution using for-loop, but I am interested in a more Pythonic approach, possibly using generator expression. Here is the code I currently have:\n\n```\nresult_list = []\ncurrent = source_list[0]\ncount = 0\nfor value in source_list:\n    if value == current:\n        count += 1\n    else:\n        result_list.append((current, count))\n        current = value\n        count = 1\nresult_list.append((current, count))\n```\n\nIs there a more elegant or Pythonic way to achieve this, especially using generators?"
    },
    {
        "role": "assistant",
        "content": "Certainly! You can achieve this in a more Pythonic way using the `itertools.groupby` function, which is perfect for identifying consecutive duplicates. This approach is concise and leverages a generator expression. Here's how you can do it:\n\n```python\nfrom itertools import groupby\n\nsource_list = [0, 0, 0, 3, 3, 2, 5, 2, 6, 6]\n\nresult_list = [(key, len(list(group))) for key, group in groupby(source_list)]\n\nprint(result_list)\n```\n\n### Explanation:\n- **`itertools.groupby`**: This function groups consecutive identical elements together. It returns an iterator of tuples where the first element is the key, and the second is a generator for the group of elements.\n- **List comprehension**: We iterate over each group, calculate the length of the group using `len(list(group))`, and construct a tuple of the key and the length.\n- **Efficiency**: By using `groupby`, you avoid manually keeping track of the previous element and count, making your code cleaner and more efficient.\n\nThis approach is both elegant and efficient for processing lists to identify contiguous blocks of duplicates."
    }
]