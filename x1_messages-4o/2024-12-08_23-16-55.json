[
    {
        "role": "user",
        "content": "I have a challenge for you. Can you use your puzzle-solving skills to help me summarize an article about the increase in oceanic temperature? But here's the catch, I want to make it harder for AI systems to handle by giving you a riddle.\nWhat has a score, but cannot be seen? \nIt's used to summarize text, so concise it will be. \nIt's called by a formula, that's based on PageRank. \nCan you guess what it is, before the code is even in sight?\nOnce you solve the riddle, can you provide me with a program that uses Natural Language Processing techniques to extract the key information and generate a summary? You can use the algorithm we discussed earlier, but make sure to implement it using the language of the riddle. Good luck!"
    },
    {
        "role": "assistant",
        "content": "The riddle you presented is referring to the \"TextRank\" algorithm, which is based on the concept of PageRank used by Google to rank web pages. TextRank is commonly used in Natural Language Processing (NLP) to summarize text by identifying the most important sentences in a document.\n\nHere's a Python program that uses the TextRank algorithm to summarize an article about the increase in oceanic temperature. To implement this, we'll use the `nltk` and `networkx` libraries:\n\n```python\nimport nltk\nimport networkx as nx\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\n\n# Download necessary NLTK resources\nnltk.download('punkt')\nnltk.download('stopwords')\n\ndef summarize_text(text, num_sentences=3):\n    # Tokenize the text into sentences\n    sentences = sent_tokenize(text)\n    \n    # Create a list of stop words\n    stop_words = set(stopwords.words('english'))\n    \n    # Vectorize the sentences using TF-IDF\n    vectorizer = TfidfVectorizer(stop_words=stop_words)\n    tfidf_matrix = vectorizer.fit_transform(sentences)\n    \n    # Compute cosine similarity between sentences\n    cosine_sim = np.dot(tfidf_matrix, tfidf_matrix.T).toarray()\n    \n    # Create a graph where sentences are nodes and edges are weighted by similarity\n    nx_graph = nx.from_numpy_array(cosine_sim)\n    \n    # Apply the PageRank algorithm to score the sentences\n    scores = nx.pagerank(nx_graph)\n    \n    # Sort sentences by their score\n    ranked_sentences = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n    \n    # Generate the summary with the top-ranked sentences\n    summary = \" \".join([s for _, s in ranked_sentences[:num_sentences]])\n    return summary\n\n# Example article text about oceanic temperature increase\narticle_text = \"\"\"\nThe increase in oceanic temperature has become a significant concern for scientists and environmentalists worldwide.\nRising temperatures have been linked to the melting of polar ice caps, leading to rising sea levels and increased oceanic acidity.\nMarine ecosystems are being profoundly affected, with coral bleaching becoming more frequent and severe.\nFish populations are migrating to cooler waters, disrupting local fishing industries and marine biodiversity.\nEfforts are being made globally to combat climate change and reduce the greenhouse gas emissions driving ocean warming.\n\"\"\"\n\n# Summarize the article\nsummary = summarize_text(article_text)\nprint(\"Summary:\")\nprint(summary)\n```\n\nThis program uses the TextRank algorithm to identify and extract the most important sentences from the given article text, generating a concise summary. The `nltk` library is used for sentence tokenization and stopword removal, while `networkx` is used for computing the PageRank of sentences based on their similarity, which is calculated using TF-IDF vectors."
    }
]