[
    {
        "role": "user",
        "content": "I am trying to create a dataframe from a list in Spark SQL. I am using Spark version 2.1 and I have a list in PySpark, for example: `test_list = [['Hello', 'world'], ['I', 'am', 'fine']]`. How can I create a dataframe from this list, where the dataframe's type is like `DataFrame[words: array<string>]`?"
    },
    {
        "role": "assistant",
        "content": "To create a DataFrame from a list in PySpark with Spark version 2.1, you can use the `createDataFrame` method provided by the `SparkSession`. Since you want the DataFrame to have a schema with an array of strings, you can achieve this by using a Row object and specifying the schema appropriately.\n\nHere is how you can do it:\n\n```python\nfrom pyspark.sql import SparkSession, Row\nfrom pyspark.sql.types import ArrayType, StringType, StructType, StructField\n\n# Initialize SparkSession\nspark = SparkSession.builder \\\n    .appName(\"Create DataFrame from List\") \\\n    .getOrCreate()\n\n# Your list\ntest_list = [['Hello', 'world'], ['I', 'am', 'fine']]\n\n# Convert the list to Rows\nrow_list = [Row(words=x) for x in test_list]\n\n# Define the schema\nschema = StructType([\n    StructField(\"words\", ArrayType(StringType()), True)\n])\n\n# Create a DataFrame\ndf = spark.createDataFrame(row_list, schema)\n\n# Show the DataFrame\ndf.show(truncate=False)\n\n# Print the schema\ndf.printSchema()\n```\n\nThis code snippet does the following:\n\n1. Initializes a Spark session.\n2. Converts each sublist in `test_list` into a Row object with the field name `words`.\n3. Defines a schema where `words` is an array of strings (`ArrayType(StringType())`).\n4. Creates a DataFrame using the converted list of Rows and the defined schema.\n5. Displays the DataFrame and its schema.\n\nThis should create a DataFrame with the desired structure."
    }
]