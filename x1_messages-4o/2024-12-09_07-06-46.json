[
    {
        "role": "user",
        "content": "I am working with TensorFlow and I have created a tensor using the following code:\n\n<pre><code>graph = tf.Graph()\nwith graph.as_default():\n  train_dataset = tf.placeholder(tf.int32, shape=[128, 2])\n  embeddings = tf.Variable(\n    tf.random_uniform([50000, 64], -1.0, 1.0))\n  embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n  embed = tf.reduce_sum(embed, reduction_indices=0)\n</code></pre>\n\nI am encountering an issue with an operation not behaving as expected, and need to understand the dimensions of the tensor 'embed'. I am aware that this can be achieved at runtime, but as this is a simple operation, I'm seeking a more straightforward method. How can I get the dimensions of a tensor during graph construction time in TensorFlow?"
    },
    {
        "role": "assistant",
        "content": "In TensorFlow, you can determine the shape of a tensor during graph construction time by using the `get_shape()` method. This method returns the shape of the tensor as a `TensorShape` object, which provides information about the dimensions of the tensor. Note that `get_shape()` provides the static shape information if it's available, but it won't execute the graph to infer dynamic shapes.\n\nHere's how you can use it in your code to obtain the shape of the `embed` tensor:\n\n```python\nimport tensorflow as tf\n\ngraph = tf.Graph()\nwith graph.as_default():\n    train_dataset = tf.placeholder(tf.int32, shape=[128, 2])\n    embeddings = tf.Variable(\n        tf.random_uniform([50000, 64], -1.0, 1.0))\n    embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n    embed = tf.reduce_sum(embed, reduction_indices=0)\n\n    # Get the shape of the tensor at graph construction time\n    embed_shape = embed.get_shape()\n\nprint(\"Shape of embed tensor:\", embed_shape)\n```\n\nHere's a breakdown of what you should expect for the `embed` tensor:\n\n1. `train_dataset` has a shape of `[128, 2]`, meaning you are looking up embeddings for 128 pairs of indices.\n2. `embeddings` has a shape of `[50000, 64]`.\n3. `tf.nn.embedding_lookup(embeddings, train_dataset)` will result in a tensor of shape `[128, 2, 64]`, because for each of the 128 pairs of indices, you get two vectors from the embeddings of size 64.\n4. `tf.reduce_sum(embed, reduction_indices=0)` will sum over the first dimension (128 in this case), resulting in a tensor of shape `[2, 64]`.\n\nThe `embed_shape` should thus be `[2, 64]`. If your operations are not behaving as expected, double-check that the dimensions align with your intentions, especially in the context of the reduction operation."
    }
]