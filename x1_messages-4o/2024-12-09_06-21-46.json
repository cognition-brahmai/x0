[
    {
        "role": "user",
        "content": "How can I split a text into n-grams in Python? I'm currently aware of how to split my text into bigrams and trigrams using the Natural Language Toolkit (NLTK) like so:\n\n```python\nimport nltk\nfrom nltk import bigrams\nstring = \"I really like python, it's pretty awesome.\"\nstring_bigrams = bigrams(string)\nprint(string_bigrams)\n```\n\nHowever, I am looking for a method to split my text into four-grams, five-grams, or even hundred-grams. Does such a method exist?"
    },
    {
        "role": "assistant",
        "content": "Yes, you can definitely split your text into n-grams of any size using NLTK in Python. To achieve this, you can use the `nltk.util.ngrams` function, which allows you to specify the `n` for n-grams. Here's how you can do it:\n\n```python\nimport nltk\nfrom nltk import ngrams\n\n# Your input string\nstring = \"I really like python, it's pretty awesome.\"\n\n# Tokenize the string into words\ntokens = nltk.word_tokenize(string)\n\n# Define the n for n-grams (e.g., 4 for four-grams, 5 for five-grams)\nn = 4  # Change this value to any number you'd like\n\n# Generate n-grams\nn_grams = ngrams(tokens, n)\n\n# Print the generated n-grams\nfor grams in n_grams:\n    print(grams)\n```\n\nMake sure to have the `punkt` tokenizer models downloaded in NLTK to use `word_tokenize`. You can download it by running:\n\n```python\nnltk.download('punkt')\n```\n\nWith this method, you can generate n-grams of any size by changing the value of `n` in the `ngrams` function."
    }
]