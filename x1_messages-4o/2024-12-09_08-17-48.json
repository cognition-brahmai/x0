[
    {
        "role": "user",
        "content": "How can I set dependencies between two DAGs in Airflow, where one DAG (B) is dependent on the successful completion of another DAG (A)? DAG A runs nightly, while DAG B runs monthly. However, DAG B takes a long time to run, leading me to keep it in a separate DAG for better SLA reporting. How can I ensure that DAG B only runs after a successful run of DAG A on the same day?"
    },
    {
        "role": "assistant",
        "content": "To set dependencies between two DAGs in Apache Airflow, where DAG B is dependent on the successful completion of DAG A, you can use several approaches. Here are a couple of common methods to achieve this:\n\n### 1. ExternalTaskSensor\n\nYou can use the `ExternalTaskSensor` to wait for a task in DAG A to complete before starting DAG B. Here's how you can set it up:\n\n1. **In DAG A:**\n\n   Ensure DAG A has a task with a known task ID that you want DAG B to wait for. For example, let's say you have a task in DAG A with the task ID `final_task`.\n\n2. **In DAG B:**\n\n   Add an `ExternalTaskSensor` at the beginning of DAG B to wait for the successful completion of `final_task` in DAG A.\n\n   ```python\n   from airflow import DAG\n   from airflow.sensors.external_task import ExternalTaskSensor\n   from airflow.operators.dummy_operator import DummyOperator\n   from datetime import datetime, timedelta\n\n   default_args = {\n       'owner': 'airflow',\n       'depends_on_past': False,\n       'start_date': datetime(2023, 1, 1),\n       'retries': 1,\n       'retry_delay': timedelta(minutes=5),\n   }\n\n   dag_b = DAG(\n       'dag_b',\n       default_args=default_args,\n       schedule_interval='@monthly',\n       catchup=False,\n   )\n\n   wait_for_dag_a = ExternalTaskSensor(\n       task_id='wait_for_dag_a',\n       external_dag_id='dag_a',  # The DAG ID of DAG A\n       external_task_id='final_task',  # The task ID you are waiting for in DAG A\n       check_existence=True,\n       mode='poke',\n       poke_interval=300,  # 5 minutes\n       timeout=3600,  # 1 hour\n       dag=dag_b,\n   )\n\n   start_dag_b = DummyOperator(\n       task_id='start_dag_b',\n       dag=dag_b,\n   )\n\n   wait_for_dag_a >> start_dag_b\n   ```\n\n### 2. TriggerDagRunOperator\n\nAnother approach is to use the `TriggerDagRunOperator` in DAG A to trigger DAG B once DAG A completes successfully. However, this approach requires you to manage the scheduling logic to ensure DAG B only runs monthly.\n\n1. **In DAG A:**\n\n   Add a `TriggerDagRunOperator` to trigger DAG B after the final task in DAG A completes.\n\n   ```python\n   from airflow import DAG\n   from airflow.operators.dagrun_operator import TriggerDagRunOperator\n   from airflow.operators.dummy_operator import DummyOperator\n   from datetime import datetime, timedelta\n\n   default_args = {\n       'owner': 'airflow',\n       'depends_on_past': False,\n       'start_date': datetime(2023, 1, 1),\n       'retries': 1,\n       'retry_delay': timedelta(minutes=5),\n   }\n\n   dag_a = DAG(\n       'dag_a',\n       default_args=default_args,\n       schedule_interval='@daily',\n       catchup=False,\n   )\n\n   final_task = DummyOperator(\n       task_id='final_task',\n       dag=dag_a,\n   )\n\n   trigger_dag_b = TriggerDagRunOperator(\n       task_id='trigger_dag_b',\n       trigger_dag_id='dag_b',\n       dag=dag_a,\n   )\n\n   final_task >> trigger_dag_b\n   ```\n\n### Considerations\n\n- **Schedule Alignment:** Ensure that the scheduling of DAG B is aligned with the monthly requirement, and it checks for the last successful run of DAG A within the same month.\n- **Error Handling:** Consider the error handling scenarios where DAG A might fail, and DAG B should not be triggered.\n- **Performance:** Be mindful of the performance impact of sensors, especially if they are set to a short `poke_interval`.\n\nBy using these techniques, you can ensure that DAG B runs only after a successful run of DAG A. Choose the method that best fits your workflow and operational requirements."
    }
]