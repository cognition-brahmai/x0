[
    {
        "role": "user",
        "content": "In Keras, should the custom loss function return a single loss value for the batch or an array of losses for every sample in the training batch? When learning the Keras API in TensorFlow(2.3), I found an example of a custom loss function:\n\n```\ndef custom_mean_squared_error(y_true, y_pred):\n    return tf.math.reduce_mean(tf.square(y_true - y_pred))\n```\nThe `reduce_mean` function in this custom loss function will return a scalar. Is this the correct way to define a loss function? My understanding is that the first dimension of the shapes of `y_true` and `y_pred` is the batch size, and the loss function should return loss values for every sample in the batch, giving an array of shape `(batch_size,)`. However, the above function gives a single value for the whole batch. Could anyone provide some guidance on this?\n\nAdditionally, I read the source code of Model class and found that when a loss function is provided to `Model.compile()` method, it is used to construct a `LossesContainer` object, which is stored in `Model.compiled_loss`. This loss function passed to the constructor of `LossesContainer` class is used once again to construct a `LossFunctionWrapper` object. According to the source code of `LossFunctionWrapper` class, the overall loss value for a training batch is calculated by the `LossFunctionWrapper.__call__()` method, which returns a single loss value for the whole batch. However, the `LossFunctionWrapper.__call__()` first calls the `LossFunctionWrapper.call()` method to obtain an array of losses for every sample in the training batch. These losses are finally averaged to get the single loss value for the whole batch. This is why I believe the custom loss function should return an array of losses, instead of a single scalar value."
    },
    {
        "role": "assistant",
        "content": "In Keras, the custom loss function can be defined in different ways depending on your requirements and the specific use case. However, it's essential to understand how Keras processes loss functions during training.\n\nWhen you define a custom loss function in Keras, it typically operates on individual samples within a batch. The way you decide to implement the function can return either:\n\n1. **A single scalar loss for the entire batch**, which is often done by computing the average of individual losses across the batch. This is the approach in your example, where `tf.math.reduce_mean` computes the mean squared error across all samples in the batch, resulting in a single scalar value.\n\n2. **An array of losses for each sample in the batch**, which can be achieved by performing the computation without reducing the dimensions, thereby returning a loss value for each sample.\n\nThe choice between these two approaches depends on how you want to handle the aggregation of loss values across a batch. Keras will handle both scenarios effectively:\n\n- If your custom loss function returns a single scalar value for the batch (like in your example), Keras will use this value directly as the batch loss.\n  \n- If your custom loss function returns an array of losses (one for each sample), Keras will automatically average these values to compute the batch loss, unless you specify a different reduction strategy.\n\nThe source code behavior you mentioned, where `LossFunctionWrapper.__call__()` integrates both individual sample losses and their reduction to a single value, aligns with this flexibility. By default, Keras expects the loss to be reduced to a scalar, either by the function itself or by Keras' internal logic.\n\nTherefore, both implementations are correct, depending on what you intend to achieve:\n\n- If you want to control how losses are aggregated (e.g., using a custom reduction method), you might return an array and handle aggregation yourself.\n\n- If you prefer simplicity and default behavior, returning a scalar from your custom loss function is perfectly acceptable, as Keras will interpret it as the loss for the entire batch.\n\nIn conclusion, your understanding is correct that you can return an array of per-sample losses, but returning a scalar is also a standard practice, as Keras will manage the reduction automatically."
    }
]