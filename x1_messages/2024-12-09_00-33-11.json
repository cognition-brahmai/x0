[
    {
        "role": "user",
        "content": "Write a JavaScript function that removes duplicates from an array without using Set."
    },
    {
        "role": "assistant",
        "content": "Sure, I can help you with that! So, you need a JavaScript function that removes duplicates from an array, but you can't use the built-in `Set` object. That's an interesting challenge. Let's think about how we can approach this.\n\nFirst, I need to understand what a duplicate is in an array. A duplicate is an element that appears more than once in the array. So, if I have an array like [1, 2, 2, 3, 4, 4, 5], the duplicates are 2 and 4, and I want to remove them so that each element appears only once.\n\nOne way to do this is to create a new array and add elements to it only if they haven't been added before. To check if an element has already been added, I can keep track of the elements that are already in the new array.\n\nI can use a loop to iterate through the original array and check each element. For each element, I'll check if it's already in the new array. If it's not, I'll add it; if it is, I'll skip it.\n\nLet me try to write some pseudocode for this:\n\n```\nfunction removeDuplicates(array) {\n  let uniqueArray = [];\n  for (let i = 0; i < array.length; i++) {\n    let currentElement = array[i];\n    if (!uniqueArray.includes(currentElement)) {\n      uniqueArray.push(currentElement);\n    }\n  }\n  return uniqueArray;\n}\n```\n\nThis seems straightforward. I'm initializing an empty array called `uniqueArray`. Then, for each element in the original array, I'm checking if it's already in `uniqueArray` using the `includes` method. If it's not, I add it using `push`.\n\nLet me test this pseudocode with an example. Suppose the input array is [1, 2, 2, 3, 4, 4, 5].\n\n- Start with `uniqueArray` empty: []\n\n- First element is 1. Since 1 is not in `uniqueArray`, add it: [1]\n\n- Second element is 2. 2 is not in `uniqueArray`, add it: [1, 2]\n\n- Third element is 2 again. 2 is already in `uniqueArray`, skip it.\n\n- Fourth element is 3. 3 is not in `uniqueArray`, add it: [1, 2, 3]\n\n- Fifth element is 4. 4 is not in `uniqueArray`, add it: [1, 2, 3, 4]\n\n- Sixth element is 4 again. 4 is already in `uniqueArray`, skip it.\n\n- Seventh element is 5. 5 is not in `uniqueArray`, add it: [1, 2, 3, 4, 5]\n\nSo, the final `uniqueArray` is [1, 2, 3, 4, 5], which is correct.\n\nBut wait, I should consider if the array contains elements other than numbers, like strings or objects. Does the function handle different data types?\n\nLet's test with an array containing strings: [\"apple\", \"banana\", \"apple\", \"orange\"]\n\n- Start with `uniqueArray` empty: []\n\n- First element is \"apple\". Not in `uniqueArray`, add it: [\"apple\"]\n\n- Second element is \"banana\". Not in `uniqueArray`, add it: [\"apple\", \"banana\"]\n\n- Third element is \"apple\". Already in `uniqueArray`, skip it.\n\n- Fourth element is \"orange\". Not in `uniqueArray`, add it: [\"apple\", \"banana\", \"orange\"]\n\nLooks good.\n\nWhat about an array with objects?\n\nLet's say we have an array of objects: [{id: 1}, {id: 2}, {id: 1}]\n\n- First element is {id: 1}. Not in `uniqueArray`, add it: [{id: 1}]\n\n- Second element is {id: 2}. Not in `uniqueArray`, add it: [{id: 1}, {id: 2}]\n\n- Third element is {id: 1}. Is it already in `uniqueArray`?\n\nWait, in JavaScript, when comparing objects, `includes` uses reference equality, not value equality. So even if two objects have the same properties, if they are different instances, `includes` will consider them unequal.\n\nSo, in this case, even though the third element has the same properties as the first one, it's a different object, so `includes` would consider it unique and add it to the `uniqueArray`.\n\nBut maybe that's not what we want. Depending on the use case, we might want to consider objects with the same properties as duplicates.\n\nFor example, if I have an array of objects like [{id: 1}, {id: 2}, {id: 1}], and I want to remove duplicates based on the `id` property, then I should end up with [{id: 1}, {id: 2}].\n\nTo handle this, I need to modify my function to consider objects as duplicates based on a specific property, like `id`.\n\nThis complicates things a bit, because I need to handle different data types differently.\n\nMaybe I should make the function handle primitive types like numbers and strings, and for objects, either handle them based on a specific property or consider them unique based on reference.\n\nFor simplicity, let's assume that the array contains either all primitive types or all objects with a specific property to check for duplicates.\n\nAlternatively, I can make the function more generic by allowing the user to provide a function that determines whether two elements are equal.\n\nThis is similar to how some array methods in JavaScript allow a comparator function.\n\nSo, perhaps I can add an optional parameter to the function that is a function for comparing elements.\n\nIf it's not provided, it defaults to using the strict equality operator (`===`).\n\nIf it is provided, it uses that function to determine equality.\n\nThis way, the user can provide a custom comparison function for objects, for example, to compare based on a specific property.\n\nLet me think about how to implement that.\n\nFirst, define the function with an optional comparator function.\n\n```\nfunction removeDuplicates(array, comparator) {\n  let uniqueArray = [];\n  for (let i = 0; i < array.length; i++) {\n    let currentElement = array[i];\n    let isDuplicate = false;\n    for (let j = 0; j < uniqueArray.length; j++) {\n      if (comparator) {\n        if (comparator(currentElement, uniqueArray[j])) {\n          isDuplicate = true;\n          break;\n        }\n      } else {\n        if (currentElement === uniqueArray[j]) {\n          isDuplicate = true;\n          break;\n        }\n      }\n    }\n    if (!isDuplicate) {\n      uniqueArray.push(currentElement);\n    }\n  }\n  return uniqueArray;\n}\n```\n\nIn this version, I'm iterating through the `uniqueArray` to check for duplicates using either the provided comparator function or the strict equality operator.\n\nThis should handle both primitive types and objects, depending on the comparator function provided.\n\nLet's test this function with the earlier examples.\n\nFirst, with numbers:\n\n```\nremoveDuplicates([1, 2, 2, 3, 4, 4, 5]);\n// Should return [1, 2, 3, 4, 5]\n```\n\nThis should work as before.\n\nNow, with strings:\n\n```\nremoveDuplicates([\"apple\", \"banana\", \"apple\", \"orange\"]);\n// Should return [\"apple\", \"banana\", \"orange\"]\n```\n\n\u4e5f\u5e94\u8be5\u6b63\u5e38\u5de5\u4f5c\u3002\n\n\u73b0\u5728\uff0c\u5bf9\u4e8e\u5bf9\u8c61\u6570\u7ec4\uff0c\u5047\u8bbe\u6211\u4eec\u6709\u4e00\u4e2a\u6bd4\u8f83\u51fd\u6570\uff0c\u6839\u636eid\u5c5e\u6027\u68c0\u67e5\u91cd\u590d\u9879\uff1a\n\n```\nconst arr = [{id: 1}, {id: 2}, {id: 1}];\nconst comparator = (a, b) => a.id === b.id;\nremoveDuplicates(arr, comparator);\n// \u5e94\u8be5\u8fd4\u56de [{id: 1}, {id: 2}]\n```\n\n\u8fd9\u5e94\u8be5\u5de5\u4f5c\uff0c\u56e0\u4e3a\u6bd4\u8f83\u51fd\u6570\u4f1a\u68c0\u67e5id\u662f\u5426\u76f8\u7b49\u3002\n\n\u518d\u8003\u8651\u4e00\u4e2a\u60c5\u51b5\uff0c\u5bf9\u8c61\u6709\u591a\u4e2a\u5c5e\u6027\uff0c\u4f46\u6211\u4eec\u8981\u6839\u636e\u67d0\u4e2a\u7279\u5b9a\u5c5e\u6027\u6765\u5224\u65ad\u91cd\u590d\u3002\n\n\u4f8b\u5982\uff1a\n\n```\nconst arr = [{id: 1, name: 'Alice'}, {id: 2, name: 'Bob'}, {id: 1, name: 'Alice'}];\nconst comparator = (a, b) => a.id === b.id && a.name === b.name;\nremoveDuplicates(arr, comparator);\n// \u5e94\u8be5\u8fd4\u56de [{id: 1, name: 'Alice'}, {id: 2, name: 'Bob'}]\n```\n\n\u5982\u679c\u6bd4\u8f83\u51fd\u6570\u68c0\u67e5id\u548cname\u90fd\u76f8\u7b49\uff0c\u5219\u89c6\u4e3a\u91cd\u590d\u3002\n\n\u6216\u8005\uff0c\u5982\u679c\u53ea\u6839\u636eid\u5224\u65ad\u91cd\u590d\uff1a\n\n```\nconst comparator = (a, b) => a.id === b.id;\nremoveDuplicates(arr, comparator);\n// \u5e94\u8be5\u8fd4\u56de [{id: 1, name: 'Alice'}, {id: 2, name: 'Bob'}]\n```\n\n\u8fd9\u6837\u53ef\u4ee5\u53bb\u9664id\u76f8\u540c\u7684\u5bf9\u8c61\uff0c\u5373\u4f7fname\u4e0d\u540c\u3002\n\nWait a minute, in the last example, if two objects have the same id but different names, and I only consider id for duplication, then I should keep only one of them.\n\nBut in reality, if I have [{id: 1, name: 'Alice'}, {id: 1, name: 'Bob'}], and I only care about id, I might want to keep only one of them, perhaps the first one encountered.\n\nMy current function should handle that, as it stops upon finding the first duplicate based on the comparator.\n\nBut in this case, both objects have the same id, but different names. So, depending on the comparator, it might consider them duplicates or not.\n\nIf the comparator only checks id, then yes, they are duplicates, and only the first one should be kept.\n\nThat seems correct.\n\nAnother consideration is performance. The current implementation has a time complexity of O(n^2), because for each element in the original array, it may iterate through the entire uniqueArray.\n\nThis could be inefficient for large arrays.\n\nIs there a way to optimize this?\n\nOne optimization is to use an object (hash map) to keep track of elements that have already been added.\n\nIn JavaScript, objects have fast lookup times because they are hashed.\n\nSo, I can create an object where the keys are the stringified versions of the elements, and the values are boolean flags indicating whether the element has been added.\n\nBut, stringifying objects can be tricky, and may not always work as expected, especially for complex objects.\n\nFor primitive types, stringifying is straightforward.\n\nFor objects, I might need to define a way to create a unique key based on the properties I'm considering for duplication.\n\nThis adds complexity, but can improve performance to O(n).\n\nLet me think about how to implement this.\n\nI can modify the function to use a map to track seen elements.\n\nIf a comparator is provided, I need to decide how to create keys for the map based on the comparator.\n\nThis might be too involved, and could lead to errors if not done carefully.\n\nAlternatively, I can provide two versions: one for primitive types using a map, and one for objects using the comparator approach.\n\nBut that might be confusing for the user.\n\nMaybe it's better to stick with the original approach for simplicity, especially since the user can provide a comparator function for more complex cases.\n\nAlternatively, I can provide an option for the user to specify a key function that returns a unique identifier for each element, which can then be used as a map key.\n\nThis way, the user can decide how to identify duplicates, whether it's based on a specific property or a combination of properties.\n\nLet me consider that.\n\nSo, the function could accept a key function that takes an element and returns a value to be used for uniqueness checks.\n\nFor example:\n\n```\nfunction removeDuplicates(array, keyFn) {\n  const seen = {};\n  const uniqueArray = [];\n  for (let i = 0; i < array.length; i++) {\n    const currentElement = array[i];\n    const key = keyFn ? keyFn(currentElement) : String(currentElement);\n    if (!seen[key]) {\n      seen[key] = true;\n      uniqueArray.push(currentElement);\n    }\n  }\n  return uniqueArray;\n}\n```\n\nIn this version, if a key function is provided, it's used to generate a key for each element, which is then checked in the `seen` object.\n\nIf no key function is provided, it defaults to stringifying the element.\n\nThis should work for primitive types, as stringifying them is unique.\n\nFor objects, the user can provide a key function that returns a unique identifier, such as `element => element.id`.\n\nLet's test this with some examples.\n\nFirst, with numbers:\n\n```\nremoveDuplicates([1, 2, 2, 3, 4, 4, 5]);\n// Should return [1, 2, 3, 4, 5]\n```\n\nThis should work, as stringifying numbers is unique.\n\nWith strings:\n\n```\nremoveDuplicates([\"apple\", \"banana\", \"apple\", \"orange\"]);\n// Should return [\"apple\", \"banana\", \"orange\"]\n```\n\nAlso works.\n\nWith objects, using a key function:\n\n```\nconst arr = [{id: 1, name: 'Alice'}, {id: 2, name: 'Bob'}, {id: 1, name: 'Alice'}];\nremoveDuplicates(arr, element => element.id);\n// Should return [{id: 1, name: 'Alice'}, {id: 2, name: 'Bob'}]\n```\n\nHere, the key function is `element => element.id`, so it will use the id as the key.\n\nEven if there are multiple objects with the same id but different names, only the first one will be added to the uniqueArray.\n\nThis seems efficient, with a time complexity of O(n), since object property lookups are O(1).\n\nThis is better than the previous O(n^2) approach.\n\nBut, there's a potential issue with this approach when dealing with objects that have the same properties but are different instances.\n\nFor example:\n\n```\nconst obj1 = {id: 1, name: 'Alice'};\nconst obj2 = {id: 1, name: 'Alice'};\nconst arr = [obj1, obj2];\nremoveDuplicates(arr, element => element.id);\n// Should return [obj1]\n```\n\nThis is because both objects have the same id, so the second one is considered a duplicate.\n\nBut in reality, obj1 and obj2 are different objects, so if I only care about reference equality, I might want both of them.\n\nHowever, in most cases, when dealing with objects in arrays, duplicates are determined based on some identifying property, like id.\n\nSo, this approach should suffice for most use cases.\n\nAnother consideration is that stringifying objects using `JSON.stringify` could be an option to create unique keys, but it's expensive and may not work for all objects, especially those with functions or circular references.\n\nUsing a key function provided by the user is more flexible and efficient.\n\nNow, let's think about edge cases.\n\nWhat if the array is empty?\n\n```\nremoveDuplicates([]);\n// Should return []\n```\n\nThat's straightforward.\n\nWhat if the array has only one element?\n\n```\nremoveDuplicates([1]);\n// Should return [1]\n```\n\nAlso simple.\n\nWhat if all elements are duplicates?\n\n```\nremoveDuplicates([2, 2, 2, 2]);\n// Should return [2]\n```\n\nCorrect.\n\nWhat if the array contains a mix of types, like numbers and strings?\n\n```\nremoveDuplicates([1, '1', 2, '2']);\n// Should return [1, '1', 2, '2']\n```\n\nBecause 1 and '1' are different types, and 2 and '2' are different types.\n\nYes, because stringifying 1 is '1', and stringifying '1' is also '1', so they would be considered duplicates.\n\nWait, no.\n\nLet's see:\n\n- For 1, key is String(1) which is '1'\n\n- For '1', key is String('1') which is '1'\n\n- So, they have the same key, and only the first one would be added.\n\nIs that desired?\n\nDepends on the use case. If you consider 1 and '1' as duplicates, then this is fine.\n\nIn JavaScript, 1 and '1' are different values, but in some contexts, they might be considered the same.\n\nHowever, in my function, since I'm stringifying them, they would be considered duplicates.\n\nIf the user wants to treat them as distinct, they can provide a key function that returns a unique key for each type.\n\nFor example:\n\n```\nremoveDuplicates([1, '1', 2, '2'], element => typeof element + element);\n// Would return [1, '1', 2, '2']\n```\n\nBecause the keys would be 'number1', 'string1', 'number2', 'string2', which are all unique.\n\nThis gives flexibility to the user.\n\nAnother edge case: what if the key function returns a value that is not suitable for object property names, like an object or an array?\n\nIn JavaScript, object property names are strings, so non-string keys would be coerced to strings.\n\nFor example, if the key function returns an object, it would be coerced to '[object Object]', which might not be unique.\n\nSo, the user should ensure that the key function returns a string that uniquely identifies the element.\n\nTo make it more robust, maybe I can throw an error if the key is not a string.\n\nBut that might be too restrictive, as sometimes users might want to use symbols as keys.\n\nWait, in older JavaScript versions, object keys can be symbols, but for consistency and compatibility, it's better to stick with strings.\n\nSo, perhaps in the function, I can ensure that the key is always a string by using `String(key)`.\n\nLet me adjust the function accordingly.\n\n```\nfunction removeDuplicates(array, keyFn) {\n  const seen = {};\n  const uniqueArray = [];\n  for (let i = 0; i < array.length; i++) {\n    const currentElement = array[i];\n    const key = keyFn ? keyFn(currentElement) : String(currentElement);\n    if (!seen[key]) {\n      seen[key] = true;\n      uniqueArray.push(currentElement);\n    }\n  }\n  return uniqueArray;\n}\n```\n\nHere, I'm ensuring that the key is always a string by using `String(key)` if a key function is provided, or directly using the stringified element if not.\n\nThis should handle most cases.\n\nBut, to make it even better, perhaps I should allow the key function to return any value, and then stringify it inside the function.\n\nLet me modify it:\n\n```\nfunction removeDuplicates(array, keyFn) {\n  const seen = {};\n  const uniqueArray = [];\n  for (let i = 0; i < array.length; i++) {\n    const currentElement = array[i];\n    const key = keyFn ? keyFn(currentElement) : currentElement;\n    const stringKey = String(key);\n    if (!seen[stringKey]) {\n      seen[stringKey] = true;\n      uniqueArray.push(currentElement);\n    }\n  }\n  return uniqueArray;\n}\n```\n\nThis way, the key function can return any type, and it's stringified to be used as a map key.\n\nThis should cover most use cases.\n\nNow, let's consider if the array is very large. Since we're using an object as a map, which has efficient lookup times, this should perform well even for large arrays.\n\nAnother consideration is the order of elements in the resulting array. The function maintains the original order, which is usually desired when removing duplicates.\n\nBut, if the user doesn't care about the order, we could use other methods to make it more efficient.\n\nHowever, maintaining order is important in most cases, so it's better to keep it as is.\n\nLet me think about whether there are any built-in JavaScript methods that can help here, without using Set.\n\nActually, ES6 introduced the `Map` object, which is similar to an object but can handle keys of any type, not just strings or symbols.\n\nBut, if I use a `Map`, I can store the keys in a more flexible way.\n\nHowever, since the user specifically asked not to use `Set`, I'm assuming that using `Map` is allowed, as they are different constructs.\n\nUsing a `Map` could be more efficient and flexible, especially for object keys.\n\nLet me try rewriting the function using `Map`.\n\n```\nfunction removeDuplicates(array, keyFn) {\n  const seen = new Map();\n  const uniqueArray = [];\n  for (let i = 0; i < array.length; i++) {\n    const currentElement = array[i];\n    const key = keyFn ? keyFn(currentElement) : currentElement;\n    if (!seen.has(key)) {\n      seen.set(key, true);\n      uniqueArray.push(currentElement);\n    }\n  }\n  return uniqueArray;\n}\n```\n\nThis is similar to the previous version, but using `Map` instead of an object.\n\nThe advantage is that `Map` can handle keys of any type, so the user doesn't have to worry about stringifying them.\n\nThis makes the function more robust and easier to use.\n\nFor example, if the user wants to remove duplicates based on a complex object property, using `Map` would handle it correctly.\n\nLet me test this with an example.\n\n```\nconst arr = [{id: 1, name: 'Alice'}, {id: 2, name: 'Bob'}, {id: 1, name: 'Alice'}];\nremoveDuplicates(arr, element => element.id);\n// Should return [{id: 1, name: 'Alice'}, {id: 2, name: 'Bob'}]\n```\n\nHere, the key is the id, which is a number, and `Map` can handle number keys without any issues.\n\nAnother example with objects as keys:\n\n```\nconst obj1 = {id: 1};\nconst obj2 = {id: 2};\nconst arr = [obj1, obj2, obj1];\nremoveDuplicates(arr, element => element);\n// Should return [obj1, obj2]\n```\n\nIn this case, the key is the object itself. Since `Map` uses reference equality for keys, and `obj1` is the same object reference, it will correctly identify duplicates based on reference equality.\n\nThis is useful if you have multiple references to the same object and want to remove those duplicates.\n\nHowever, if you have different objects with the same properties, `Map` will consider them different keys, which might not be desired.\n\nFor example:\n\n```\nconst obj1 = {id: 1};\nconst obj2 = {id: 1};\nconst arr = [obj1, obj2];\nremoveDuplicates(arr, element => element);\n// Would return [obj1, obj2], because they are different objects\n```\n\nIf you want to consider them duplicates based on properties, you need to provide a key function that extracts the identifying property, like `element => element.id`.\n\nThis way, both objects would have the same key and only the first one would be added.\n\nThis seems like a good approach.\n\nI think using `Map` is better than using an object for tracking seen elements, as it handles various key types more gracefully.\n\nBut, since the user specifically asked not to use `Set`, and `Map` is also an ES6 feature, I should check if using `Map` is allowed.\n\nPerhaps the user wants a solution that works in older JavaScript environments that don't support ES6 features.\n\nIf that's the case, then using `Map` might not be acceptable.\n\nAlternatively, I can provide both versions: one using a plain object for older browsers, and one using `Map` for modern environments.\n\nBut, to keep it simple, I'll stick with the plain object version, assuming that the user wants a solution that works in older environments.\n\nNow, let's consider if there are any other ways to remove duplicates without using `Set`.\n\nOne alternative is to use the `filter` method combined with the `indexOf` method.\n\nHere's how it could look:\n\n```\nfunction removeDuplicates(array) {\n  return array.filter((item, index) => array.indexOf(item) === index);\n}\n```\n\nThis works by keeping only the elements where their index is the first occurrence in the array.\n\nThis is a concise way to remove duplicates for primitive types.\n\nLet's test it with [1, 2, 2, 3, 4, 4, 5]:\n\n- For 1, indexOf(1) is 0, which matches the index, so keep it.\n\n- For 2, indexOf(2) is 1, which matches index 1, so keep it.\n\n- For the second 2, indexOf(2) is still 1, which doesn't match index 2, so remove it.\n\n- And so on.\n\nThis seems to work.\n\nBut, there's a catch: `indexOf` uses strict equality (`===`) to compare elements.\n\nSo, for objects, it will compare by reference, not by value.\n\nFor example:\n\n```\nconst arr = [{id: 1}, {id: 2}, {id: 1}];\nremoveDuplicates(arr);\n// Would return [{id: 1}, {id: 2}, {id: 1}]\n```\n\nBecause each object is a different reference.\n\nThis might not be the desired behavior, depending on the use case.\n\nSo, while this method is concise, it has limitations when dealing with objects.\n\nAdditionally, `indexOf` has a time complexity of O(n), and since it's called for each element in the array, the overall time complexity is O(n^2).\n\nThis could be inefficient for large arrays.\n\nComparatively, my earlier approach using a map or an object for tracking seen elements is more efficient, with O(n) time complexity.\n\nTherefore, I think the map/object approach is better for general use.\n\nAnother alternative is to use the `reduce` method.\n\nHere's how it could be done:\n\n```\nfunction removeDuplicates(array) {\n  return array.reduce((accumulator, current) => {\n    if (!accumulator.includes(current)) {\n      accumulator.push(current);\n    }\n    return accumulator;\n  }, []);\n}\n```\n\nThis is similar to my initial pseudocode, but using `reduce` instead of a for loop.\n\nIt still has the same limitations and performance issues as the initial approach, with O(n^2) time complexity due to the `includes` method.\n\nSo, again, not ideal for large arrays.\n\nTherefore, I'll stick with the map/object approach for tracking seen elements, as it's more efficient.\n\nNow, let's think about how to make this function more user-friendly.\n\nPerhaps I can add default behavior for common data types.\n\nFor example, for numbers and strings, no key function is needed.\n\nFor objects, I can provide a default key function that uses a specific property, like `id`.\n\nBut, different objects may have different identifying properties, so it's better to let the user provide the key function as needed.\n\nAlternatively, I can make the key function accept multiple arguments, allowing the user to create a composite key based on multiple properties.\n\nFor example:\n\n```\nremoveDuplicates(arr, element => element.id + '_' + element.name);\n```\n\nThis way, duplicates would only be considered if both id and name are the same.\n\nThis is flexible enough for most use cases.\n\nAnother consideration is whether to remove duplicates in a case-insensitive manner for strings.\n\nFor example, if the array contains ['Apple', 'apple', 'APPLE'], should they be considered duplicates or not?\n\nBy default, string comparison in JavaScript is case-sensitive, so 'Apple' and 'apple' would be considered different.\n\nIf the user wants case-insensitive comparison, they can provide a key function that converts strings to lowercase:\n\n```\nremoveDuplicates(['Apple', 'apple', 'APPLE'], element => element.toLowerCase());\n// Would return ['Apple']\n```\n\nThis is a good approach.\n\nNow, to make the function even more versatile, I could allow the key function to return multiple keys, perhaps as an array, and concatenate them into a single string key.\n\nBut, that might be overcomplicating things.\n\nI think the current approach is sufficient.\n\nLet me summarize the final function:\n\n```\nfunction removeDuplicates(array, keyFn) {\n  const seen = {};\n  const uniqueArray = [];\n  for (let i = 0; i < array.length; i++) {\n    const currentElement = array[i];\n    const key = keyFn ? keyFn(currentElement) : String(currentElement);\n    const stringKey = String(key);\n    if (!seen[stringKey]) {\n      seen[stringKey] = true;\n      uniqueArray.push(currentElement);\n    }\n  }\n  return uniqueArray;\n}\n```\n\nThis function takes an array and an optional key function.\n\nIt maintains a map of seen keys to track duplicates.\n\nIt iterates through the array, computes the key for each element (using the key function if provided), and adds the element to the uniqueArray if its key hasn't been seen before.\n\nThis approach is efficient and flexible, handling various data types and allowing the user to define what constitutes a duplicate.\n\nI believe this should satisfy the user's requirement for a JavaScript function to remove duplicates from an array without using `Set`.\n\n**Final Solution**\n\nTo remove duplicates from an array in JavaScript without using the `Set` object, you can use the following function. This function allows for flexibility in handling different data types and provides an option to specify a key function for complex objects.\n\n```javascript\nfunction removeDuplicates(array, keyFn) {\n  const seen = {};\n  const uniqueArray = [];\n  for (let i = 0; i < array.length; i++) {\n    const currentElement = array[i];\n    const key = keyFn ? keyFn(currentElement) : String(currentElement);\n    const stringKey = String(key);\n    if (!seen[stringKey]) {\n      seen[stringKey] = true;\n      uniqueArray.push(currentElement);\n    }\n  }\n  return uniqueArray;\n}\n```\n\n### Explanation\n\n1. **Basic Usage**: For primitive types like numbers and strings, the function automatically handles duplicates by stringifying the elements.\n    ```javascript\n    const numbers = [1, 2, 2, 3, 4, 4, 5];\n    console.log(removeDuplicates(numbers)); // Output: [1, 2, 3, 4, 5]\n    ```\n\n2. **Handling Objects**: For objects, you can provide a key function to specify which property should be used to determine uniqueness.\n    ```javascript\n    const arr = [{id: 1, name: 'Alice'}, {id: 2, name: 'Bob'}, {id: 1, name: 'Alice'}];\n    console.log(removeDuplicates(arr, element => element.id)); // Output: [{id: 1, name: 'Alice'}, {id: 2, name: 'Bob'}]\n    ```\n\n3. **Case-Insensitive Strings**: For case-insensitive comparisons, use a key function that converts strings to lowercase.\n    ```javascript\n    const fruits = ['Apple', 'apple', 'APPLE'];\n    console.log(removeDuplicates(fruits, element => element.toLowerCase())); // Output: ['Apple']\n    ```\n\nThis approach ensures efficiency and flexibility, making it suitable for various scenarios where duplicates need to be removed from an array."
    }
]