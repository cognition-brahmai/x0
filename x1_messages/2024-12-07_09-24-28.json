[
    {
        "role": "user",
        "content": "Implement a simple LRU (Least Recently Used) cache in Python that supports get and put operations with O(1) time complexity."
    },
    {
        "role": "assistant",
        "content": "Implementing a Least Recently Used (LRU) cache in Python that supports get and put operations with O(1) time complexity requires careful design to ensure efficiency. One effective way to achieve this is by using a combination of a dictionary and a doubly-linked list. The dictionary provides fast access to cache items, while the doubly-linked list helps in maintaining the order of item usage.\n\n### Approach\n\n1. **Dictionary**: \n   - Used to store references to the cache items for O(1) access.\n   - Keys are the cache keys, and values are pointers to the corresponding nodes in the doubly-linked list.\n\n2. **Doubly-Linked List**:\n   - Each node in the list contains the cache key and value.\n   - The list maintains the order of usage, with the most recently used items near the head and the least recently used items near the tail.\n\n3. **Operations**:\n   - **Get Operation**:\n     - If the key exists, move the corresponding node to the head of the list (indicating recent use) and return the value.\n     - If the key does not exist, return -1.\n   - **Put Operation**:\n     - If the key already exists, update its value and move the node to the head.\n     - If the key does not exist, create a new node, add it to the head, and insert it into the dictionary.\n     - If the cache is at capacity, remove the least recently used item (the tail node) from both the list and the dictionary.\n\n### Solution Code\n\n```python\nclass Node:\n    def __init__(self, key, value):\n        self.key = key\n        self.value = value\n        self.prev = None\n        self.next = None\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.head = Node(0, 0)\n        self.tail = Node(0, 0)\n        self.head.next = self.tail\n        self.tail.prev = self.head\n\n    def _remove(self, node):\n        prev_node = node.prev\n        next_node = node.next\n        prev_node.next = next_node\n        next_node.prev = prev_node\n\n    def _add(self, node):\n        node.prev = self.head\n        node.next = self.head.next\n        self.head.next.prev = node\n        self.head.next = node\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            node = self.cache[key]\n            self._remove(node)\n            self._add(node)\n            return node.value\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            node = self.cache[key]\n            self._remove(node)\n            del self.cache[key]\n        if len(self.cache) == self.capacity:\n            tail_node = self.tail.prev\n            self._remove(tail_node)\n            del self.cache[tail_node.key]\n        new_node = Node(key, value)\n        self._add(new_node)\n        self.cache[key] = new_node\n```\n\n### Explanation\n\n1. **Node Class**:\n   - Represents an element in the doubly-linked list, containing the key, value, and pointers to the previous and next nodes.\n\n2. **LRUCache Class**:\n   - **Initialization**:\n     - `capacity`: Maximum number of items the cache can hold.\n     - `cache`: Dictionary to store references to nodes.\n     - `head` and `tail`: Dummy nodes to simplify list operations.\n   - **_remove Method**:\n     - Removes a node from the list.\n   - **_add Method**:\n     - Adds a node to the head of the list.\n   - **get Method**:\n     - Retrieves a value by key, moves the accessed node to the head, and returns the value.\n     - Returns -1 if the key is not found.\n   - **put Method**:\n     - Inserts or updates a key-value pair.\n     - If the key exists, removes the old node before adding the new one.\n     - If the cache is full, removes the least recently used item (tail node).\n\nThis implementation ensures that both get and put operations are performed in constant time, O(1), meeting the requirements for an efficient LRU cache."
    }
]