[
    {
        "role": "user",
        "content": "Implement a Python script that monitors a specified directory for new files. When a new file is detected, the script should compress it using gzip and store the compressed version in another specified directory. The script should use command line arguments for specifying the source and destination directories."
    },
    {
        "role": "assistant",
        "content": "Okay, I'm going to try to create a Python script that watches a specific folder for new files. As soon as a new file shows up, I need to compress it using gzip and then save the compressed file in another folder that I'll specify. I also need to use command line arguments to set the source and destination directories. Let's break this down step by step.\n\nFirst, I need to understand what tools and modules I'll be using in Python for this task. I know that Python has a module called `os` for interacting with the operating system, and `sys` for command line arguments. For monitoring the directory, I think I can use the `watchdog` library, which provides a way to watch for file system events. And for compressing files, I'll use the `gzip` module.\n\nBut wait, I need to make sure that `watchdog` is installed because it's not a built-in module. I can install it using pip. Also, I should check if the user has it installed or if I need to include installation instructions.\n\nAlright, starting with the command line arguments. I need to accept two directories: the source directory to watch and the destination directory to store the compressed files. I can use the `sys.argv` list to get the arguments passed to the script.\n\nSo, the script should be run like this:\n\n```bash\n\npython monitor_and_compress.py /path/to/source /path/to/destination\n\n```\n\nI need to make sure that the script checks if the correct number of arguments are provided and handle cases where they're missing or incorrect.\n\nNext, I need to set up the watchdog to monitor the source directory for new files. The watchdog library provides a `Observer` class that can watch for events like file creation.\n\nI'll need to create an event handler that specifies what to do when a new file is created. In this case, the action is to compress the file using gzip and move the compressed version to the destination directory.\n\nLet me recall how gzip works in Python. The `gzip` module allows us to read and write gzip-encoded files. To compress a file, I can open the original file in binary read mode, open the destination file in binary write mode using `gzip.open()`, and then copy the content from the source to the destination.\n\nI should also consider the file names for the compressed files. Probably, I'll keep the same name but with a `.gz` extension appended.\n\nWait, gzip usually appends `.gz` to the file name, so I need to ensure that the compressed file has the original name plus `.gz`.\n\nAlso, I need to handle cases where files with the same name already exist in the destination directory. Maybe I should check for that and handle duplicates appropriately, like renaming the file or skipping it.\n\nMoreover, I should think about the performance. If a large file is being written to the source directory, I need to make sure that my script doesn't try to compress it before it's fully written. Maybe I should add a small delay after detecting a new file to ensure it's complete.\n\nAlternatively, perhaps I can check if the file size hasn't changed for a certain period before proceeding to compress it.\n\nBut that might complicate things. Maybe for now, I'll assume that the files are dropped entirely into the directory without being written gradually.\n\nI also need to consider different types of files: text files, binary files, etc. Gzip should handle both, but I need to make sure to handle them in binary mode.\n\nLet me outline the steps in code:\n\n1. Import necessary modules: `sys`, `os`, `gzip`, and `watchdog`.\n\n2. Check and retrieve command line arguments for source and destination directories.\n\n3. Set up the watchdog observer to monitor the source directory.\n\n4. Define an event handler that triggers on new file creation.\n\n5. In the event handler, compress the new file using gzip and save it to the destination directory.\n\n6. Start the observer thread and keep the script running to continue monitoring.\n\nBut I need to look into the watchdog library more closely to see how to implement the event handler.\n\nFrom what I remember, I need to create a class that inherits from `watchdog.events.FileSystemEventHandler` and override the `on_created` method, which is called when a file is created.\n\nInside the `on_created` method, I'll get the event object which contains the path of the new file. Then, I can read the file, compress it, and save it to the destination directory.\n\nI should also handle exceptions, like if the file can't be read or written, or if there's no space left on the destination drive.\n\nAdditionally, I should consider logging to keep track of which files are being compressed and any errors that occur.\n\nPython has a `logging` module that I can use for this purpose.\n\nI should set up logging to write to a file, so I have a record of the script's activities.\n\nLet me think about the structure of the script:\n\n- Import necessary modules.\n\n- Set up logging.\n\n- Check and parse command line arguments.\n\n- Define the event handler class.\n\n- Set up the watchdog observer.\n\n- Start the observer and keep the script running.\n\nI need to make sure that the script can be stopped gracefully, maybe by capturing Ctrl+C and stopping the observer thread properly.\n\nAlso, I should validate that the source and destination directories exist and are writable.\n\nLet me think about how to implement the compression function.\n\nI'll need a function that takes the source file path and the destination directory path, compresses the file, and saves it in the destination directory with the appropriate name.\n\nSomething like this:\n\n```python\n\nimport gzip\n\nimport shutil\n\ndef compress_file(src_path, dest_dir):\n\n    with open(src_path, 'rb') as f_in:\n\n        base = os.path.basename(src_path)\n\n        dest_path = os.path.join(dest_dir, base + '.gz')\n\n        with gzip.open(dest_path, 'wb') as f_out:\n\n            shutil.copyfileobj(f_in, f_out)\n\n```\n\nThis function opens the source file in binary read mode, opens the destination file in binary write mode using gzip, and copies the content from the source to the destination.\n\nI should also consider if I need to preserve the original file's metadata, like timestamps, but for now, maybe that's not necessary.\n\nWait, gzip files have their own metadata, including the compression time, but not necessarily the original file's modification time.\n\nIf it's important to preserve the original modification time, I might need to set it on the compressed file.\n\nBut that might be complicated, so perhaps I'll leave it for now.\n\nI should also think about error handling in this function. For example, if the source file doesn't exist or can't be read, or if there's no space left on the destination drive.\n\nI can use try-except blocks to catch IOErrors and log appropriate messages.\n\nNow, regarding the event handler.\n\nI need to create a class that inherits from `watchdog.events.FileSystemEventHandler` and override the `on_created` method.\n\nIn the `on_created` method, I'll get an event object that has the `src_path` attribute, which is the path of the new file.\n\nI need to check if it's a file (not a directory) and then call the compression function.\n\nAlso, I should log that a new file was detected and that compression has started.\n\nAfter compression, I should log that the file has been compressed and saved to the destination.\n\nHere's a rough sketch:\n\n```python\n\nfrom watchdog.events import FileSystemEventHandler\n\nclass CompressHandler(FileSystemEventHandler):\n\n    def __init__(self, dest_dir):\n\n        super().__init__()\n\n        self.dest_dir = dest_dir\n\n    def on_created(self, event):\n\n        if event.is_directory:\n\n            return\n\n        src_path = event.src_path\n\n        logging.info(f'New file detected: {src_path}')\n\n        try:\n\n            compress_file(src_path, self.dest_dir)\n\n            logging.info(f'Compressed and saved to: {dest_path}')\n\n        except IOError as e:\n\n            logging.error(f'Error compressing {src_path}: {e}')\n\n```\n\nI need to make sure that `dest_path` is correctly defined in the log message.\n\nActually, in the `compress_file` function, `dest_path` is local to that function, so I need to return it or store it in an instance variable if I need to access it outside the function.\n\nAlternatively, I can construct `dest_path` in the `on_created` method and pass it to `compress_file`.\n\nLet me adjust the function to accept `dest_path` as well.\n\n```python\n\ndef compress_file(src_path, dest_path):\n\n    with open(src_path, 'rb') as f_in:\n\n        with gzip.open(dest_path, 'wb') as f_out:\n\n            shutil.copyfileobj(f_in, f_out)\n\n```\n\nThen, in the `on_created` method:\n\n```python\n\ndef on_created(self, event):\n\n    if event.is_directory:\n\n        return\n\n    src_path = event.src_path\n\n    base = os.path.basename(src_path)\n\n    dest_path = os.path.join(self.dest_dir, base + '.gz')\n\n    logging.info(f'New file detected: {src_path}')\n\n    try:\n\n        compress_file(src_path, dest_path)\n\n        logging.info(f'Compressed and saved to: {dest_path}')\n\n    except IOError as e:\n\n        logging.error(f'Error compressing {src_path}: {e}')\n\n```\n\nThis seems better.\n\nNow, I need to set up the watchdog observer to watch the source directory and use this event handler.\n\nI'll need to create an `Observer` object, schedule it to watch the source directory with the event handler, and then start the observer.\n\nI should also ensure that the script keeps running to continue monitoring.\n\nTo handle stopping the script gracefully, I can capture the KeyboardInterrupt exception (Ctrl+C) and stop the observer before exiting.\n\nHere's a rough outline:\n\n```python\n\nfrom watchdog.observers import Observer\n\ndef main():\n\n    source_dir = sys.argv[1]\n\n    dest_dir = sys.argv[2]\n\n    # Set up logging\n\n    logging.basicConfig(filename='compress.log', level=logging.INFO)\n\n    # Validate directories\n\n    if not os.path.isdir(source_dir):\n\n        logging.error(f'Source directory does not exist: {source_dir}')\n\n        sys.exit(1)\n\n    if not os.path.isdir(dest_dir):\n\n        logging.error(f'Destination directory does not exist: {dest_dir}')\n\n        sys.exit(1)\n\n    # Set up event handler and observer\n\n    handler = CompressHandler(dest_dir)\n\n    observer = Observer()\n\n    observer.schedule(handler, source_dir, recursive=False)\n\n    # Start observer\n\n    observer.start()\n\n    try:\n\n        while True:\n\n            time.sleep(1)\n\n    except KeyboardInterrupt:\n\n        observer.stop()\n\n    observer.join()\n\nif __name__ == '__main__':\n\n    if len(sys.argv) != 3:\n\n        print('Usage: python monitor_and_compress.py /path/to/source /path/to/destination')\n\n        sys.exit(1)\n\n    main()\n\n```\n\nI need to import `time` for the sleep function and make sure all other modules are imported at the top.\n\nI should also consider adding more robust error handling and maybe options for verbose logging or other features, but for now, this should suffice.\n\nI should test this script by creating a new file in the source directory and verifying that it's compressed and appears in the destination directory.\n\nI should also test with different types of files to ensure that gzip handles them correctly.\n\nAdditionally, I should check what happens if the destination directory is not writable or if there's insufficient space.\n\nI need to make sure that the script doesn't crash in such scenarios but logs the error appropriately.\n\nAlso, I should consider if I need to handle multiple file creations concurrently. Watchdog's observer should handle multiple events, but I need to ensure that the event handler can handle multiple compressions without stepping on each other's toes.\n\nPerhaps using threading to handle each compression in a separate thread would be a good idea, but that might complicate things.\n\nFor now, I'll assume that files are created one at a time or that the event handler can handle sequential compressions without issues.\n\nI should also think about excluding certain files, like log files or temporary files, but that might be beyond the scope for this initial implementation.\n\nAnother consideration is to check if the file already exists in the destination directory before compressing and copying it again.\n\nMaybe I can add a check to see if a file with the same name already exists in the destination and skip compression if it does.\n\nBut this might not be ideal, as the file contents could be different.\n\nAlternatively, I could compare file modification times or checksums, but that would add complexity.\n\nPerhaps for now, I'll allow overwriting files in the destination directory.\n\nI should also think about the script's performance, especially if the source directory contains a large number of files or if files are being created rapidly.\n\nGzip compression is generally fast, but for very large files, it might take some time.\n\nI need to ensure that the event handler doesn't block the observer from detecting new events while compressing a file.\n\nAgain, using threading for compression might help in such cases.\n\nBut to keep things simple, I'll proceed without threading for now.\n\nI should also consider if I need to handle symbolic links or other special file types in the source directory.\n\nGzip should handle regular files, but symbolic links might need special attention.\n\nPerhaps I can modify the event handler to ignore non-regular files.\n\nHere's an updated `on_created` method:\n\n```python\n\ndef on_created(self, event):\n\n    if event.is_directory:\n\n        return\n\n    src_path = event.src_path\n\n    if not os.path.isfile(src_path):\n\n        logging.info(f'Ignoring non-regular file: {src_path}')\n\n        return\n\n    base = os.path.basename(src_path)\n\n    dest_path = os.path.join(self.dest_dir, base + '.gz')\n\n    logging.info(f'New file detected: {src_path}')\n\n    try:\n\n        compress_file(src_path, dest_path)\n\n        logging.info(f'Compressed and saved to: {dest_path}')\n\n    except IOError as e:\n\n        logging.error(f'Error compressing {src_path}: {e}')\n\n```\n\nThis way, only regular files are compressed, and other types are ignored.\n\nI should also think about file name collisions in the destination directory.\n\nIf two files with the same name are compressed at different times, the latter will overwrite the earlier one.\n\nTo prevent this, I could include timestamps in the destination file names, but that might complicate things.\n\nAlternatively, I could use a unique identifier or check if a file with the same name already exists and handle it accordingly.\n\nBut for now, I'll assume that file names are unique or that overwriting is acceptable.\n\nAnother thing to consider is that gzip can compress files in place, but since I need to save the compressed version to a different directory, I need to specify a separate destination path.\n\nI should also think about the file permissions and ownership.\n\nDepending on the system, the compressed file might inherit permissions from the destination directory.\n\nI might need to set specific permissions for the compressed files, but that's probably beyond the scope for now.\n\nI should also consider what happens if the source file is being written to while it's being compressed.\n\nGzip should read whatever is in the file at the time, but if the file is being updated concurrently, the compressed file might not reflect the final content.\n\nTo mitigate this, perhaps I can wait for a short period after the file creation event before starting the compression, to allow any ongoing writes to complete.\n\nBut this could introduce delays and is not foolproof.\n\nAlternatively, I could check if the file size hasn't changed for a certain period before proceeding with compression.\n\nThis would require tracking file sizes and their last change times, which adds complexity.\n\nFor now, I'll assume that files are dropped entirely into the source directory without being written incrementally.\n\nIf needed, I can revisit this in future iterations.\n\nI should also think about excluding certain file types, like already compressed files or specific extensions.\n\nBut for now, I'll compress all regular files.\n\nI need to make sure that the script can handle files of various sizes, from small text files to large binary files.\n\nGzip should handle both efficiently.\n\nI should also consider memory usage during compression.\n\nGzip compression is usually memory-efficient, but for very large files, it might still consume significant resources.\n\nI need to monitor the script's performance in such scenarios.\n\nNow, let's think about implementing the script.\n\nFirst, I need to ensure that all required modules are imported at the beginning.\n\nHere's a list of modules I'll need:\n\n- `sys` for command line arguments\n\n- `os` for directory and file operations\n\n- `gzip` for compression\n\n- `shutil` for copying file objects\n\n- `watchdog.observers` and `watchdog.events` for monitoring directory changes\n\n- `logging` for logging activities and errors\n\n- `time` for the main loop's sleep\n\nI should also handle the case where `watchdog` is not installed and provide instructions to install it.\n\nIn the script, I can include a try-except block for imports and\u63d0\u793a\u7528\u6237\u5b89\u88c5\u7f3a\u5931\u7684\u6a21\u5757\u3002\n\n\u63a5\u4e0b\u6765\uff0c\u6211\u9700\u8981\u8bbe\u7f6e\u65e5\u5fd7\u8bb0\u5f55\uff0c\u5c06\u65e5\u5fd7\u5199\u5165\u4e00\u4e2a\u6587\u4ef6\uff0c\u4f8b\u5982`compress.log`\uff0c\u5e76\u8bbe\u7f6e\u65e5\u5fd7\u7ea7\u522b\u4e3a`INFO`\u3002\n\n\u6211\u8fd8\u9700\u8981\u9a8c\u8bc1\u6e90\u76ee\u5f55\u548c\u76ee\u6807\u76ee\u5f55\u662f\u5426\u5b58\u5728\uff0c\u5e76\u4e14\u53ef\u5199\u3002\n\n\u5982\u679c\u76ee\u5f55\u4e0d\u5b58\u5728\u6216\u4e0d\u53ef\u5199\uff0c\u5e94\u8be5\u8bb0\u5f55\u9519\u8bef\u5e76\u9000\u51fa\u811a\u672c\u3002\n\n\u7136\u540e\uff0c\u521b\u5efa`CompressHandler`\u7c7b\uff0c\u7ee7\u627f\u81ea`watchdog.events.FileSystemEventHandler`\uff0c\u5e76\u91cd\u5199`on_created`\u65b9\u6cd5\u3002\n\n\u5728\u8fd9\u4e2a\u65b9\u6cd5\u4e2d\uff0c\u68c0\u67e5\u4e8b\u4ef6\u662f\u5426\u662f\u6587\u4ef6\u521b\u5efa\u4e8b\u4ef6\uff0c\u5ffd\u7565\u76ee\u5f55\u548c\u5176\u4ed6\u975e\u6587\u4ef6\u4e8b\u4ef6\u3002\n\n\u83b7\u53d6\u6e90\u6587\u4ef6\u8def\u5f84\uff0c\u6784\u5efa\u76ee\u6807\u6587\u4ef6\u8def\u5f84\uff08\u6dfb\u52a0`.gz`\u6269\u5c55\u540d\uff09\uff0c\u7136\u540e\u8c03\u7528`compress_file`\u51fd\u6570\u8fdb\u884c\u538b\u7f29\u3002\n\n\u5728`compress_file`\u51fd\u6570\u4e2d\uff0c\u4ee5\u4e8c\u8fdb\u5236\u8bfb\u6a21\u5f0f\u6253\u5f00\u6e90\u6587\u4ef6\uff0c\u4ee5\u4e8c\u8fdb\u5236\u5199\u6a21\u5f0f\u6253\u5f00\u76ee\u6807\u6587\u4ef6\uff0c\u5e76\u4f7f\u7528`gzip.open()`\u8fdb\u884c\u538b\u7f29\u3002\n\n\u4f7f\u7528`shutil.copyfileobj()`\u590d\u5236\u6587\u4ef6\u5185\u5bb9\u3002\n\n\u5728\u4e3b\u51fd\u6570\u4e2d\uff0c\u8bbe\u7f6e\u89c2\u5bdf\u5668\u6765\u76d1\u63a7\u6e90\u76ee\u5f55\uff0c\u5e76\u542f\u52a8\u89c2\u5bdf\u5668\u3002\n\n\u4f7f\u7528\u4e00\u4e2a\u65e0\u9650\u5faa\u73af\u4fdd\u6301\u811a\u672c\u8fd0\u884c\uff0c\u76f4\u5230\u7528\u6237\u901a\u8fc7Ctrl+C\u505c\u6b62\u5b83\u3002\n\n\u5728\u6355\u83b7`KeyboardInterrupt`\u5f02\u5e38\u65f6\uff0c\u505c\u6b62\u89c2\u5bdf\u5668\u5e76\u9000\u51fa\u3002\n\n\u6211\u9700\u8981\u786e\u4fdd\u89c2\u5bdf\u5668\u7ebf\u7a0b\u6b63\u786e\u505c\u6b62\uff0c\u907f\u514d\u8d44\u6e90\u6cc4\u6f0f\u3002\n\n\u6b64\u5916\uff0c\u6211\u5e94\u8be5\u5728\u811a\u672c\u5f00\u5934\u6dfb\u52a0\u6587\u6863\u5b57\u7b26\u4e32\uff0c\u8bf4\u660e\u811a\u672c\u7684\u529f\u80fd\u3001\u7528\u6cd5\u548c\u53c2\u6570\u3002\n\n\u6211\u8fd8\u53ef\u4ee5\u6dfb\u52a0\u547d\u4ee4\u884c\u53c2\u6570\u7684\u9a8c\u8bc1\uff0c\u786e\u4fdd\u63d0\u4f9b\u4e86\u6b63\u786e\u7684\u76ee\u5f55\u8def\u5f84\u3002\n\n\u5982\u679c\u547d\u4ee4\u884c\u53c2\u6570\u4e0d\u8db3\u6216\u76ee\u5f55\u65e0\u6548\uff0c\u5e94\u8be5\u663e\u793a\u7528\u6cd5\u8bf4\u660e\u5e76\u9000\u51fa\u3002\n\n\u6700\u540e\uff0c\u6211\u9700\u8981\u6d4b\u8bd5\u811a\u672c\uff0c\u521b\u5efa\u65b0\u6587\u4ef6\u5728\u6e90\u76ee\u5f55\u4e2d\uff0c\u786e\u8ba4\u5b83\u4eec\u88ab\u6b63\u786e\u538b\u7f29\u5e76\u79fb\u52a8\u5230\u76ee\u6807\u76ee\u5f55\u3002\n\n\u6211\u5e94\u8be5\u6d4b\u8bd5\u4e0d\u540c\u7c7b\u578b\u7684\u6587\u4ef6\uff0c\u786e\u4fddgzip\u6b63\u786e\u5904\u7406\u5b83\u4eec\u3002\n\n\u6211\u8fd8\u5e94\u8be5\u6d4b\u8bd5\u9519\u8bef\u573a\u666f\uff0c\u6bd4\u5982\u76ee\u6807\u76ee\u5f55\u4e0d\u53ef\u5199\uff0c\u6216\u6e90\u6587\u4ef6\u4e0d\u5b58\u5728\uff0c\u786e\u4fdd\u811a\u672c\u6b63\u786e\u8bb0\u5f55\u9519\u8bef\u5e76\u7ee7\u7eed\u8fd0\u884c\u3002\n\n\u603b\u4e4b\uff0c\u8fd9\u4e2a\u811a\u672c\u9700\u8981\u4ed4\u7ec6\u8bbe\u8ba1\u548c\u6d4b\u8bd5\uff0c\u4ee5\u786e\u4fdd\u53ef\u9760\u5730\u76d1\u89c6\u76ee\u5f55\u5e76\u538b\u7f29\u65b0\u6587\u4ef6\u3002\n\n**Final Solution**\n\nTo create a Python script that monitors a specified directory for new files and compresses them using gzip into another specified directory, follow the steps below. This solution uses the `watchdog` library to monitor directory changes and the `gzip` module for compression.\n\n## Solution Code\n\n```python\nimport sys\nimport os\nimport gzip\nimport shutil\nimport logging\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\nimport time\n\ndef compress_file(src_path, dest_path):\n    with open(src_path, 'rb') as f_in:\n        with gzip.open(dest_path, 'wb') as f_out:\n            shutil.copyfileobj(f_in, f_out)\n\nclass CompressHandler(FileSystemEventHandler):\n    def __init__(self, dest_dir):\n        super().__init__()\n        self.dest_dir = dest_dir\n\n    def on_created(self, event):\n        if event.is_directory:\n            return\n        src_path = event.src_path\n        if not os.path.isfile(src_path):\n            logging.info(f'Ignoring non-regular file: {src_path}')\n            return\n        base = os.path.basename(src_path)\n        dest_path = os.path.join(self.dest_dir, base + '.gz')\n        logging.info(f'New file detected: {src_path}')\n        try:\n            compress_file(src_path, dest_path)\n            logging.info(f'Compressed and saved to: {dest_path}')\n        except IOError as e:\n            logging.error(f'Error compressing {src_path}: {e}')\n\ndef main():\n    if len(sys.argv) != 3:\n        print('Usage: python monitor_and_compress.py /path/to/source /path/to/destination')\n        sys.exit(1)\n\n    source_dir = sys.argv[1]\n    dest_dir = sys.argv[2]\n\n    logging.basicConfig(filename='compress.log', level=logging.INFO)\n\n    if not os.path.isdir(source_dir):\n        logging.error(f'Source directory does not exist: {source_dir}')\n        sys.exit(1)\n    if not os.path.isdir(dest_dir):\n        logging.error(f'Destination directory does not exist: {dest_dir}')\n        sys.exit(1)\n\n    handler = CompressHandler(dest_dir)\n    observer = Observer()\n    observer.schedule(handler, source_dir, recursive=False)\n    observer.start()\n\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n    observer.join()\n\nif __name__ == '__main__':\n    main()\n```\n\n## Explanation\n\n1. **Imports**: Necessary modules are imported including `sys`, `os`, `gzip`, `shutil`, `logging`, `watchdog.observers`, `watchdog.events`, and `time`.\n\n2. **Compression Function (`compress_file`)**: This function opens a source file in binary read mode and compresses it using gzip, saving it to the specified destination path.\n\n3. **Event Handler Class (`CompressHandler`)**: Inheriting from `FileSystemEventHandler`, this class overrides the `on_created` method to handle new file events. It ignores directories and non-regular files, logs the detection of new files, compresses them, and handles any IOErrors that occur during compression.\n\n4. **Main Function**:\n   - **Argument Parsing**: The script expects two command-line arguments: source and destination directories.\n   - **Logging Setup**: Logging is configured to write to `compress.log` with `INFO` level.\n   - **Directory Validation**: The source and destination directories are checked for existence. If invalid, an error is logged, and the script exits.\n   - **Observer Setup**: An `Observer` is set up with the `CompressHandler` to monitor the source directory for new files.\n   - **Infinite Loop**: The script runs indefinitely, monitoring for new files until interrupted.\n   - **Graceful Exit**: Captures `KeyboardInterrupt` to stop the observer thread properly.\n\n5. **Execution**: The script monitors the specified source directory and compresses any new files using gzip, storing the compressed files in the specified destination directory. Logs are maintained for all activities and errors."
    }
]