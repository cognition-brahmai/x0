[
    {
        "role": "user",
        "content": "Implement a simple LRU (Least Recently Used) cache in Golang with the following features:\n   - Set and get methods for adding and retrieving data.\n   - A fixed size, specified during initialization.\n   - Automatic removal of the least recently used item when the cache is full."
    },
    {
        "role": "assistant",
        "content": "Implementing a Least Recently Used (LRU) cache in Golang is a great way to manage a cache with a fixed size, ensuring that the least recently used items are removed when the cache reaches its capacity. Below is a simple implementation that includes set and get methods for adding and retrieving data, respectively, and automatically removes the least recently used item when the cache is full.\n\n### Approach\n\n1. **Data Structures**:\n   - **Map**: To store the data for quick access (O(1) complexity).\n   - **Doubly Linked List**: To maintain the order of usage (most recent to least recent).\n\n2. **Operations**:\n   - **Get(key)**: Retrieve the value from the map and update the position in the linked list to reflect recent use.\n   - **Set(key, value)**: Add the key-value pair to the map and the linked list. If the cache is full, remove the least recently used item from both the map and the linked list.\n\n3. **Maintaining Order**:\n   - Each time a key is accessed (either through get or set), it is moved to the front of the linked list to indicate it's the most recently used.\n   - The least recently used item is always at the end of the linked list.\n\n### Solution Code\n\n```go\npackage main\n\nimport (\n\t\"container/list\"\n\t\"fmt\"\n)\n\ntype LRUCache struct {\n\tcapacity int\n\tcache    map[int]*list.Element\n\tlruList  *list.List\n}\n\n// Node represents the elements in the doubly linked list\ntype Node struct {\n\tkey   int\n\tvalue int\n}\n\n// NewLRUCache initializes a new LRUCache with the specified capacity\nfunc NewLRUCache(capacity int) *LRUCache {\n\treturn &LRUCache{\n\t\tcapacity: capacity,\n\t\tcache:    make(map[int]*list.Element),\n\t\tlruList:  list.New(),\n\t}\n}\n\n// Get retrieves the value for the given key if it exists, otherwise returns -1\nfunc (c *LRUCache) Get(key int) int {\n\tif elem, ok := c.cache[key]; ok {\n\t\tc.lruList.MoveToFront(elem)\n\t\treturn elem.Value.(*Node).value\n\t}\n\treturn -1\n}\n\n// Set inserts a key-value pair into the cache, evicting the least recently used item if necessary\nfunc (c *LRUCache) Set(key int, value int) {\n\tif elem, ok := c.cache[key]; ok {\n\t\tc.lruList.MoveToFront(elem)\n\t\telem.Value.(*Node).value = value\n\t} else {\n\t\tif c.lruList.Len() >= c.capacity {\n\t\t\tbackElem := c.lruList.Back()\n\t\t\tdelete(c.cache, backElem.Value.(*Node).key)\n\t\t\tc.lruList.Remove(backElem)\n\t\t}\n\t\tnewNode := &Node{key: key, value: value}\n\t\telem := c.lruList.PushFront(newNode)\n\t\tc.cache[key] = elem\n\t}\n}\n\nfunc main() {\n\tcache := NewLRUCache(2)\n\tcache.Set(1, 1)\n\tcache.Set(2, 2)\n\tfmt.Println(cache.Get(1)) // returns 1\n\tcache.Set(3, 3)           // evicts key 2\n\tfmt.Println(cache.Get(2)) // returns -1 (not found)\n\tcache.Set(4, 4)           // evicts key 1\n\tfmt.Println(cache.Get(1)) // returns -1 (not found)\n\tfmt.Println(cache.Get(3)) // returns 3\n\tfmt.Println(cache.Get(4)) // returns 4\n}\n```\n\n### Explanation\n\n1. **Data Structures**:\n   - **Map (`cache`)**: Maps keys to their corresponding elements in the linked list for O(1) access.\n   - **Doubly Linked List (`lruList`)**: Maintains the order of keys based on their usage.\n\n2. **Get Operation**:\n   - Checks if the key exists in the map.\n   - If found, moves the corresponding element to the front of the list (most recent) and returns its value.\n   - If not found, returns -1.\n\n3. **Set Operation**:\n   - If the key already exists, updates its value and moves it to the front.\n   - If the key does not exist, adds the new key-value pair to the front of the list and the map.\n   - If the cache is full, removes the least recently used item (at the end of the list) before adding the new item.\n\nThis implementation ensures that both get and set operations run in constant time, O(1), making it efficient for cache management."
    }
]