[
    {
        "role": "user",
        "content": "Prove the Central Limit Theorem, providing a step-by-step explanation."
    },
    {
        "role": "assistant",
        "content": "The Central Limit Theorem (CLT) is a fundamental concept in probability theory and statistics that states that the sum or average of a large number of independent and identically distributed (i.i.d.) random variables, each with finite mean and variance, will be approximately normally distributed, regardless of the shape of the original distribution. In this explanation, I'll outline a step-by-step proof of the CLT using characteristic functions, which is one of the standard methods.\n\n### Step 1: Statement of the Central Limit Theorem\n\nLet \\( X_1, X_2, \\ldots, X_n \\) be a sequence of i.i.d. random variables with mean \\( \\mu \\) and variance \\( \\sigma^2 \\), where \\( -\\infty < \\mu < \\infty \\) and \\( 0 < \\sigma^2 < \\infty \\). Define the sample mean \\( \\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i \\). Then, as \\( n \\) approaches infinity, the distribution of the standardized variable\n\n\\[\nZ_n = \\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}}\n\\]\n\nconverges in distribution to the standard normal distribution \\( N(0,1) \\). In other words,\n\n\\[\nZ_n \\xrightarrow{d} N(0,1) \\quad \\text{as} \\quad n \\to \\infty.\n\\]\n\n### Step 2: Characteristic Functions\n\nA characteristic function of a random variable \\( X \\) is defined as\n\n\\[\n\\phi_X(t) = E[e^{itX}] = \\int_{-\\infty}^{\\infty} e^{itx} f_X(x) \\, dx,\n\\]\n\nwhere \\( f_X(x) \\) is the probability density function of \\( X \\), and \\( i \\) is the imaginary unit. The characteristic function uniquely determines the distribution of \\( X \\), and the convergence of characteristic functions implies convergence in distribution under certain conditions.\n\n### Step 3: Characteristic Function of the Standardized Sum\n\nFirst, express \\( Z_n \\) in terms of the original variables:\n\n\\[\nZ_n = \\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}} = \\frac{\\sum_{i=1}^n (X_i - \\mu)}{\\sigma \\sqrt{n}}.\n\\]\n\nThe characteristic function of \\( Z_n \\) is\n\n\\[\n\\phi_{Z_n}(t) = E\\left[ e^{it Z_n} \\right] = E\\left[ e^{it \\frac{\\sum_{i=1}^n (X_i - \\mu)}{\\sigma \\sqrt{n}}} \\right].\n\\]\n\nSince the \\( X_i \\) are i.i.d., the characteristic function of the sum is the product of the individual characteristic functions:\n\n\\[\n\\phi_{Z_n}(t) = \\left( E\\left[ e^{it \\frac{X_1 - \\mu}{\\sigma \\sqrt{n}}} \\right] \\right)^n = \\left( \\phi_{X_1 - \\mu}\\left( \\frac{t}{\\sigma \\sqrt{n}} \\right) \\right)^n.\n\\]\n\n### Step 4: Expansion of the Characteristic Function\n\nRecall that the characteristic function of \\( X_1 - \\mu \\) is\n\n\\[\n\\phi_{X_1 - \\mu}(t) = E\\left[ e^{it(X_1 - \\mu)} \\right] = E\\left[ e^{itX_1} e^{-it\\mu} \\right] = e^{-it\\mu} \\phi_{X_1}(t).\n\\]\n\nHowever, since \\( E[X_1] = \\mu \\), we can use the Taylor expansion of \\( \\phi_{X_1}(t) \\) around \\( t = 0 \\):\n\n\\[\n\\phi_{X_1}(t) = 1 + it E[X_1] - \\frac{t^2}{2} E[X_1^2] + o(t^2) = 1 + it \\mu - \\frac{t^2}{2} (\\sigma^2 + \\mu^2) + o(t^2).\n\\]\n\nBut for \\( X_1 - \\mu \\), we have \\( E[X_1 - \\mu] = 0 \\) and \\( E[(X_1 - \\mu)^2] = \\sigma^2 \\), so\n\n\\[\n\\phi_{X_1 - \\mu}(t) = 1 - \\frac{t^2 \\sigma^2}{2} + o(t^2).\n\\]\n\n### Step 5: Substitution and Simplification\n\nSubstitute \\( t/\\sigma \\sqrt{n} \\) for \\( t \\) in the expansion:\n\n\\[\n\\phi_{X_1 - \\mu}\\left( \\frac{t}{\\sigma \\sqrt{n}} \\right) = 1 - \\frac{\\left( \\frac{t}{\\sigma \\sqrt{n}} \\right)^2 \\sigma^2}{2} + o\\left( \\left( \\frac{t}{\\sigma \\sqrt{n}} \\right)^2 \\right) = 1 - \\frac{t^2}{2n} + o\\left( \\frac{t^2}{n} \\right).\n\\]\n\nTherefore,\n\n\\[\n\\phi_{Z_n}(t) = \\left( 1 - \\frac{t^2}{2n} + o\\left( \\frac{t^2}{n} \\right) \\right)^n.\n\\]\n\n### Step 6: Limit of the Characteristic Function\n\nRecall that for any real number \\( a \\),\n\n\\[\n\\lim_{n \\to \\infty} \\left( 1 + \\frac{a}{n} \\right)^n = e^a.\n\\]\n\nSimilarly, in our case,\n\n\\[\n\\lim_{n \\to \\infty} \\left( 1 - \\frac{t^2}{2n} + o\\left( \\frac{t^2}{n} \\right) \\right)^n = e^{-t^2 / 2}.\n\\]\n\nThis is the characteristic function of the standard normal distribution \\( N(0,1) \\), whose characteristic function is \\( e^{-t^2 / 2} \\).\n\n### Step 7: Conclusion\n\nSince the characteristic function of \\( Z_n \\) converges pointwise to the characteristic function of the standard normal distribution, by the L\u00e9vy\u2019s continuity theorem, the distribution of \\( Z_n \\) converges in distribution to \\( N(0,1) \\). Therefore, we have proved the Central Limit Theorem.\n\n\\[\n\\boxed{Z_n \\xrightarrow{d} N(0,1) \\quad \\text{as} \\quad n \\to \\infty.}\n\\]\n\n### Additional Notes\n\n1. **Lindeberg-Feller CLT**: There are generalizations of the CLT that do not require the variables to be identically distributed, such as the Lindeberg-Feller CLT, which has weaker conditions.\n\n2. **Berry-Esseen Theorem**: This theorem provides a bound on the rate of convergence in the CLT, giving an estimate of how quickly the distribution of \\( Z_n \\) approaches the normal distribution.\n\n3. **Applications**: The CLT is widely used in statistics, econometrics, natural sciences, and engineering for making inferences about population parameters from sample statistics.\n\nThis proof using characteristic functions is one of several approaches to establishing the CLT, others including methods based on moment-generating functions, convolution, and Stein's method."
    }
]