[
    {
        "role": "user",
        "content": "Create a Python script that monitors a specified directory for changes (e.g., file creation, modification, or deletion) and automatically updates a corresponding Memcached cache with the latest file contents. The script should support command-line arguments for specifying the target directory and cache settings.\nPLAINFORMAT"
    },
    {
        "role": "assistant",
        "content": "Alright, I've got this task to create a Python script that watches a directory for any changes like new files being added, existing files being modified or deleted, and then updates a Memcached cache with the latest contents of these files. Also, it should accept command-line arguments for the directory to watch and some cache settings. Sounds interesting!\n\nFirst, I need to understand what tools and libraries I'll be using. For watching the directory for changes, Python has a library called `watchdog` which is great for monitoring file system events. For interacting with Memcached, there's the `pymemcache` library, which is a straightforward client for Memcached.\n\nSo, I'll need to install these libraries if they're not already available. I can do that using pip:\n\n```bash\npip install watchdog pymemcache\n```\n\nNext, I need to think about the structure of the script. It should accept command-line arguments for the directory to watch and possibly some Memcached settings like the server address and port. Python's `argparse` module is perfect for handling command-line arguments.\n\nLet me sketch out the basic structure:\n\n1. Import necessary modules: `argparse` for arguments, `watchdog` for monitoring, `pymemcache` for caching, and maybe `time` for delays.\n\n2. Set up argument parsing to accept the directory path and Memcached settings.\n\n3. Initialize the Memcached client with the provided settings.\n\n4. Set up a watchdog observer to monitor the specified directory for events.\n\n5. Define event handlers that will update the Memcached cache when files are created, modified, or deleted.\n\n6. Start the observer to begin monitoring.\n\nNow, let's think about how to handle each type of event:\n\n- **File created**: Read the new file and store its contents in Memcached with the file path as the key.\n\n- **File modified**: Read the updated file and update its contents in Memcached.\n\n- **File deleted**: Remove the corresponding entry from Memcached.\n\nI need to make sure that the script can handle different file types, but for simplicity, I'll assume that all files are plain text files that can be read using Python's built-in functions.\n\nError handling is also important. For example, if a file is being modified while it's being read, there might be inconsistencies. I should consider adding some delay or handling such cases gracefully.\n\nAlso, I need to think about performance. If there are a lot of files in the directory, loading all of them into Memcached at once might not be efficient. Maybe I should only cache files as they are accessed or changed.\n\nBut according to the task, it's to automatically update the cache with the latest file contents when changes are detected, so that seems manageable with `watchdog` events.\n\nLet me consider how to map file paths to Memcached keys. Since Memcached uses keys to store and retrieve values, I can use the file paths themselves as keys, possibly with some normalization to ensure they are valid keys.\n\nNow, let's think about the Memcached client. I need to connect to the Memcached server specified by the user. Default Memcached port is 11211, but it's good to allow the user to specify a different port if needed.\n\nI should also consider whether to handle multiple Memcached servers or just a single one for simplicity. For now, I'll assume a single server.\n\nLet me outline the steps in code:\n\n1. Parse command-line arguments for directory path, Memcached server, and port.\n\n2. Initialize Memcached client.\n\n3. Set up watchdog observer to monitor the directory.\n\n4. Define event handlers for different types of events:\n\na. On created: Read file and set its contents in Memcached with file path as key.\n\nb. On modified: Read updated file and set its contents in Memcached.\n\nc. On deleted: Delete the corresponding key from Memcached.\n\n5. Start the observer to begin monitoring.\n\nI need to make sure that the script runs continuously, keeping an eye on the directory for any changes.\n\nLet me think about how to handle the event handlers. `watchdog` uses event handlers that inherit from `FileSystemEventHandler`. I can override the methods for different events like `on_modified`, `on_created`, and `on_deleted`.\n\nI should also consider that sometimes files might be temporarily modified or created during operations like copying, so maybe adding a slight delay before processing the events could help, but that might complicate things.\n\nFor now, I'll proceed without delays and see if it works fine.\n\nLet me sketch a rough code structure:\n\n```python\nimport argparse\nimport sys\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\nfrom pymemcache.client.base import Client\n\nclass CacheUpdater(FileSystemEventHandler):\n    def __init__(self, memcached_client):\n        self.mc = memcached_client\n\n    def on_modified(self, event):\n        if event.is_directory:\n            return\n        self.update_cache(event.src_path)\n\n    def on_created(self, event):\n        if event.is_directory:\n            return\n        self.update_cache(event.src_path)\n\n    def on_deleted(self, event):\n        if event.is_directory:\n            return\n        self.mc.delete(event.src_path)\n\n    def update_cache(self, file_path):\n        try:\n            with open(file_path, 'r') as file:\n                content = file.read()\n                self.mc.set(file_path, content)\n        except Exception as e:\n            print(f\"Error processing {file_path}: {e}\", file=sys.stderr)\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Watch a directory and update Memcached cache.\")\n    parser.add_argument(\"directory\", help=\"Directory to watch\")\n    parser.add_argument(\"--memcached-host\", default=\"localhost\", help=\"Memcached server host\")\n    parser.add_argument(\"--memcached-port\", type=int, default=11211, help=\"Memcached server port\")\n    args = parser.parse_args()\n\n    memcached_client = Client((args.memcached_host, args.memcached_port))\n    event_handler = CacheUpdater(memcached_client)\n    observer = Observer()\n    observer.schedule(event_handler, args.directory, recursive=True)\n    observer.start()\n\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n    observer.join()\n\nif __name__ == \"__main__\":\n    main()\n```\n\nThis seems like a good starting point. I need to make sure to handle exceptions properly, especially when reading files or interacting with Memcached.\n\nI should also think about how to handle subdirectories. If the directory has subdirectories, and files are created or modified inside them, the script should still capture those events. Setting `recursive=True` in `observer.schedule` should take care of that.\n\nAnother thing to consider is that Memcached keys might have restrictions on their length or allowed characters. File paths could be long or contain characters not allowed in Memcached keys. I might need to encode or hash the file paths to make them suitable for Memcached keys.\n\nFor example, I could use `os.path.normpath` to normalize the file paths and then perhaps use a hash of the path as the key.\n\nLet me think about that. Memcached keys can be up to 250 bytes long and can contain binary data, but it's generally safer to use ASCII characters.\n\nUsing hashed versions of file paths could work, but it might make debugging harder since the keys won't be human-readable. For now, I'll stick with using the file paths directly, assuming they are valid strings.\n\nI should also consider that file paths are OS-dependent, using different path separators. I need to make sure that the paths are handled correctly across different operating systems.\n\nIn Python, `os.path` functions can help with that, but since I'm using the file paths as keys, I need to ensure they are consistent and unique.\n\nAnother point is that if files are being rewritten with the same content, I might not need to update the cache. But checking for changes would add complexity, so perhaps it's better to always update the cache when a modification is detected.\n\nI should also consider the performance impact of reading files on every modification. For large files, this could be slow. Maybe I can optimize it by reading only parts of the file or using file modification times to check if the file has actually changed.\n\nBut for simplicity, I'll proceed with reading the entire file every time it's modified.\n\nLet me think about how to test this script. I'll need a Memcached server running locally or on a specified host. I can install Memcached and run it on localhost:11211.\n\nThen, create a directory with some files, and use the script to watch that directory. Make changes to the files, create new files, delete files, and see if the Memcached cache updates accordingly.\n\nI can use the Memcached client to retrieve the values and verify if they match the file contents.\n\nAlso, I need to ensure that the script handles errors gracefully. For example, if the Memcached server is down, the script should handle the connection error appropriately without crashing.\n\nSimilarly, if there are issues reading files (e.g., permission denied), the script should log the error and continue running.\n\nI should implement logging instead of just printing errors to stderr. Python's `logging` module can be used for that.\n\nLet me update the sketch to include logging:\n\n```python\nimport argparse\nimport sys\nimport time\nimport logging\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\nfrom pymemcache.client.base import Client\nimport os\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\nlogger = logging.getLogger()\n\nclass CacheUpdater(FileSystemEventHandler):\n    def __init__(self, memcached_client):\n        self.mc = memcached_client\n\n    def on_modified(self, event):\n        if event.is_directory:\n            return\n        self.update_cache(event.src_path)\n\n    def on_created(self, event):\n        if event.is_directory:\n            return\n        self.update_cache(event.src_path)\n\n    def on_deleted(self, event):\n        if event.is_directory:\n            return\n        self.mc.delete(event.src_path)\n        logger.info(f\"Deleted: {event.src_path}\")\n\n    def update_cache(self, file_path):\n        try:\n            with open(file_path, 'r') as file:\n                content = file.read()\n                self.mc.set(file_path, content)\n                logger.info(f\"Updated: {file_path}\")\n        except Exception as e:\n            logger.error(f\"Error processing {file_path}: {e}\")\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Watch a directory and update Memcached cache.\")\n    parser.add_argument(\"directory\", help=\"Directory to watch\")\n    parser.add_argument(\"--memcached-host\", default=\"localhost\", help=\"Memcached server host\")\n    parser.add_argument(\"--memcached-port\", type=int, default=11211, help=\"Memcached server port\")\n    args = parser.parse_args()\n\n    memcached_client = Client((args.memcached_host, args.memcached_port))\n    event_handler = CacheUpdater(memcached_client)\n    observer = Observer()\n    observer.schedule(event_handler, args.directory, recursive=True)\n    observer.start()\n    logger.info(f\"Watching {args.directory} for changes...\")\n\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n    observer.join()\n\nif __name__ == \"__main__\":\n    main()\n```\n\nThis looks better. Now, I need to make sure that the script can handle different types of files and edge cases.\n\nFor example:\n\n- Empty files\n\n- Very large files\n\n- Files with special characters in their names\n\n- Files being modified rapidly in quick succession\n\nFor very large files, reading them entirely into memory might not be efficient. Perhaps for large files, I can read them in chunks, but that would complicate the script. For now, I'll assume that the files are of reasonable size.\n\nFor files with special characters in their names, I need to ensure that the file paths are handled correctly as Memcached keys.\n\nI should also consider that file paths are case-sensitive or case-insensitive depending on the file system, but Memcached keys are case-sensitive. So, I need to treat file paths in a case-sensitive manner.\n\nAnother consideration is that Memcached does not guarantee permanent storage; items can be evicted based on the cache replacement policy. So, the cache might not always have the latest contents if the cache fills up.\n\nBut according to the task, it's just to automatically update the cache with the latest file contents, so that should be fine.\n\nI should also think about how to stop the script gracefully. Currently, it runs indefinitely until interrupted by KeyboardInterrupt (Ctrl+C). Maybe I can add an option to specify a timeout or some other stopping condition, but for simplicity, I'll keep it as is.\n\nLet me think about security aspects. Since the script reads files from the specified directory and stores their contents in Memcached, I need to ensure that it doesn't accidentally read sensitive files or overwrite important cache entries.\n\nTo mitigate this, I can make sure that the script is run with appropriate permissions and that the directory being watched is intended for this purpose.\n\nAlso, Memcached is in-memory and typically used for caching, so the data stored there is transient and not persisted across restarts. Still, sensitive data should not be stored in Memcached without proper security measures.\n\nIn this script, since we're caching file contents, it's important to ensure that the files being cached do not contain sensitive information.\n\nAnother point is that if the Memcached server is not secured, anyone with access to the Memcached server can retrieve the cached file contents. So, it's important to secure the Memcached server appropriately.\n\nBut for the scope of this task, I'll assume that the Memcached server is secured appropriately.\n\nLet me think about how to normalize file paths for use as Memcached keys. On Windows, file paths use backslashes, while on Unix-based systems, they use forward slashes. Memcached keys should be consistent across different operating systems.\n\nI can standardize the file paths by converting them to use forward slashes or by using a canonical path representation.\n\nIn Python, `os.path.normpath` can normalize the path, but it preserves the OS-specific separators. Maybe I can replace backslashes with forward slashes in the path to make it consistent.\n\nLet me update the `update_cache` method to normalize the file path:\n\n```python\ndef update_cache(self, file_path):\n    normalized_path = file_path.replace(os.sep, \"/\")\n    try:\n        with open(file_path, 'r') as file:\n            content = file.read()\n            self.mc.set(normalized_path, content)\n            logger.info(f\"Updated: {normalized_path}\")\n    except Exception as e:\n        logger.error(f\"Error processing {file_path}: {e}\")\n```\n\nSimilarly, in the `on_deleted` method:\n\n```python\ndef on_deleted(self, event):\n    if event.is_directory:\n        return\n    normalized_path = event.src_path.replace(os.sep, \"/\")\n    self.mc.delete(normalized_path)\n    logger.info(f\"Deleted: {normalized_path}\")\n```\n\nThis should make the keys consistent across different operating systems.\n\nI should also consider encoding the keys if necessary, but for now, replacing the separators should suffice.\n\nLet me think about how to handle binary files. Currently, the script opens files in text mode (`'r'`), which may not be suitable for binary files. If there are binary files in the directory, attempting to read them as text could cause errors.\n\nTo handle both text and binary files, I can read all files in binary mode and store their contents as bytes in Memcached.\n\nThen, when retrieving, the user would need to handle the bytes appropriately.\n\nLet me adjust the code to handle files in binary mode:\n\n```python\ndef update_cache(self, file_path):\n    normalized_path = file_path.replace(os.sep, \"/\")\n    try:\n        with open(file_path, 'rb') as file:\n            content = file.read()\n            self.mc.set(normalized_path, content)\n            logger.info(f\"Updated: {normalized_path}\")\n    except Exception as e:\n        logger.error(f\"Error processing {file_path}: {e}\")\n```\n\nAnd for deletion, it remains the same.\n\nThis way, the script can handle any type of file.\n\nI should also update the README or comments in the script to inform users that files are stored in binary format in Memcached.\n\nNow, let's think about how to run this script. I need to have the `watchdog` and `pymemcache` libraries installed, and a Memcached server running.\n\nAssuming Memcached is installed and running on localhost:11211, I can run the script like this:\n\n```bash\npython script.py /path/to/watch --memcached-host=localhost --memcached-port=11211\n```\n\nThen, any changes in the specified directory should be reflected in the Memcached cache.\n\nTo verify, I can use a Memcached client to retrieve the file contents by their normalized paths.\n\nFor example, using the `pymemcache` client in another script:\n\n```python\nfrom pymemcache.client.base import Client\n\nclient = Client(('localhost', 11211))\ncontent = client.get('/path/to/file.txt')\nprint(content)\n```\n\nThis should print the contents of the file as bytes.\n\nAlternatively, if I know the file type, I can decode the bytes appropriately.\n\nIn the monitoring script, I can log any errors or updates, which will help in debugging.\n\nI should also consider adding more options for cache settings, like cache expiration times, but for now, I'll keep it simple.\n\nLet me think about how to handle the initial state of the directory. When the script starts, it might be useful to load the existing files into the cache.\n\nBut with a large number of files, this could take time and resources. Maybe I can add an option to initialize the cache with existing files.\n\nFor now, I'll focus on handling only the changes detected after the script starts.\n\nAnother consideration is that `watchdog` may not catch all events if the script is started after some files already exist. So, users might need to trigger a change (like touching a file) to load it into the cache.\n\nBut again, for simplicity, I'll leave the initial state handling out for now.\n\nLet me think about potential race conditions. For example, if a file is being written to in multiple stages, the script might capture incomplete writes.\n\nTo mitigate this, I could add a delay before processing the events, but that could complicate the script.\n\nAlternatively, I could implement a more robust file locking mechanism, but that's beyond the scope of this task.\n\nFor now, assuming that file writes are atomic or that the user ensures files are written completely before the script detects the modification.\n\nAnother point is that if the script is stopped and restarted, any changes made while it was stopped won't be captured unless the files are modified again after restart.\n\nBut since it's a cache, it's acceptable to have eventual consistency.\n\nI should also consider the implications of recursive monitoring. If there are many subdirectories with\u5927\u91cf files, the script may consume more resources.\n\nBut `watchdog` is designed to handle this efficiently, so it should be fine.\n\nLet me think about how to structure the code for better readability and maintainability. I can separate concerns into different functions or classes if needed.\n\nFor example, I can have a separate function to initialize the logger, or a class to handle Memcached operations.\n\nBut for a script of this size, the current structure seems acceptable.\n\nI should add comments to explain what each part of the code does, especially for someone who might not be familiar with `watchdog` or `pymemcache`.\n\nAlso, I should include a docstring at the beginning of the script explaining its purpose and how to use it.\n\nLet me draft a simple docstring:\n\n```python\n\"\"\"\nWatch a specified directory for changes (file creation, modification, deletion)\nand automatically update a corresponding Memcached cache with the latest file contents.\n\nUsage:\n    python script.py /path/to/watch --memcached-host=localhost --memcached-port=11211\n\"\"\"\n```\n\nI should also handle cases where the directory does not exist or the Memcached server is unreachable.\n\nIn such cases, the script should log an error and exit gracefully.\n\nLet me add checks for these scenarios:\n\n```python\ndef main():\n    parser = argparse.ArgumentParser(description=\"Watch a directory and update Memcached cache.\")\n    parser.add_argument(\"directory\", help=\"Directory to watch\")\n    parser.add_argument(\"--memcached-host\", default=\"localhost\", help=\"Memcached server host\")\n    parser.add_argument(\"--memcached-port\", type=int, default=11211, help=\"Memcached server port\")\n    args = parser.parse_args()\n\n    if not os.path.isdir(args.directory):\n        logger.error(f\"Directory {args.directory} does not exist.\")\n        sys.exit(1)\n\n    try:\n        memcached_client = Client((args.memcached_host, args.memcached_port))\n        # Test connection\n        memcached_client.get('test')\n    except Exception as e:\n        logger.error(f\"Unable to connect to Memcached server: {e}\")\n        sys.exit(1)\n\n    event_handler = CacheUpdater(memcached_client)\n    observer = Observer()\n    observer.schedule(event_handler, args.directory, recursive=True)\n    observer.start()\n    logger.info(f\"Watching {args.directory} for changes...\")\n\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n    observer.join()\n```\n\nThis way, the script checks if the directory exists and tries to connect to the Memcached server before starting the observer.\n\nIf either check fails, it logs an error and exits.\n\nI can also add more options in the future, like cache expiration times or different Memcached behaviors, but for now, this should suffice.\n\nLet me think about how to handle file renaming. Currently, the event handler has methods like `on_moved`, which is called when a file is renamed or moved.\n\nI need to handle this event to update the cache accordingly. If a file is renamed, its content might not have changed, but its key in Memcached should be updated to reflect the new path.\n\nSo, I should add an `on_moved` handler that deletes the old key and sets the new key with the file's contents.\n\nLet me update the `CacheUpdater` class to include `on_moved`:\n\n```python\nclass CacheUpdater(FileSystemEventHandler):\n    def __init__(self, memcached_client):\n        self.mc = memcached_client\n\n    def on_modified(self, event):\n        if event.is_directory:\n            return\n        self.update_cache(event.src_path)\n\n    def on_created(self, event):\n        if event.is_directory:\n            return\n        self.update_cache(event.src_path)\n\n    def on_deleted(self, event):\n        if event.is_directory:\n            return\n        normalized_path = event.src_path.replace(os.sep, \"/\")\n        self.mc.delete(normalized_path)\n        logger.info(f\"Deleted: {normalized_path}\")\n\n    def on_moved(self, event):\n        if event.is_directory:\n            return\n        old_path = event.src_path.replace(os.sep, \"/\")\n        new_path = event.dest_path.replace(os.sep, \"/\")\n        self.mc.delete(old_path)\n        self.update_cache(event.dest_path)\n        logger.info(f\"Moved: {old_path} -> {new_path}\")\n\n    def update_cache(self, file_path):\n        normalized_path = file_path.replace(os.sep, \"/\")\n        try:\n            with open(file_path, 'rb') as file:\n                content = file.read()\n                self.mc.set(normalized_path, content)\n                logger.info(f\"Updated: {normalized_path}\")\n        except Exception as e:\n            logger.error(f\"Error processing {file_path}: {e}\")\n```\n\nNow, when a file is moved or renamed, the old key is deleted, and the new key is set with the file's contents.\n\nThis should keep the cache consistent with the file system.\n\nI should also consider that moving a file across different directories might change its path, but since I'm using normalized paths as keys, it should handle that correctly.\n\nAnother edge case is if a file is being edited externally, causing multiple modification events in quick succession. The script should handle these events efficiently without overwhelming the Memcached server.\n\nPerhaps I can implement some form of debouncing or throttling to limit the rate of updates, but that would add complexity.\n\nFor now, I'll assume that the volume of events is manageable.\n\nLet me think about how to test this script thoroughly.\n\nFirst, set up a Memcached server:\n\nOn Ubuntu, install Memcached and its Python client:\n\n```bash\nsudo apt-get install memcached\npip install pymemcache\n```\n\nStart Memcached:\n\n```bash\nmemcached -d\n```\n\nCreate a directory for testing:\n\n```bash\nmkdir test_dir\ncd test_dir\necho \"Initial content\" > file1.txt\n```\n\nRun the script:\n\n```bash\npython script.py /path/to/test_dir --memcached-host=localhost --memcached-port=11211\n```\n\nNow, make some changes:\n\n- Modify `file1.txt` and save it.\n\n- Create a new file, `file2.txt`.\n\n- Delete `file1.txt`.\n\n- Move `file2.txt` to `file3.txt`.\n\nCheck Memcached for the corresponding keys and their contents.\n\nI can use another Python script to retrieve the cache entries:\n\n```python\nfrom pymemcache.client.base import Client\n\nclient = Client(('localhost', 11211))\n\nkeys = client.stats('items')\nfor key in keys:\n    value = client.get(key)\n    print(f\"{key}: {value}\")\n```\n\nBut actually, `pymemcache` does not provide a direct way to list all keys. So, I might need to keep track of the keys separately or use a different approach to verify the cache contents.\n\nAlternatively, I can use the Memcached telnet interface or other tools to inspect the cache.\n\nFor example, using telnet:\n\n```bash\ntelnet localhost 11211\n```\n\nThen, use the `stats items` command to see the cached items.\n\nBut for simplicity, I can just retrieve specific keys that I expect to be in the cache based on the file operations I perform.\n\nFor example, after creating `file2.txt`, I can retrieve `/path/to/test_dir/file2.txt` from Memcached and check its contents.\n\nI should also test with subdirectories to ensure that the script handles them correctly.\n\nCreate a subdirectory:\n\n```bash\nmkdir test_subdir\necho \"Subdir content\" > test_subdir/file4.txt\n```\n\nCheck if `test_subdir/file4.txt` is cached correctly.\n\nAlso, test renaming a file and verify that the old key is deleted and the new key is set.\n\nAdditionally, test with binary files, like images or executables, to ensure that their contents are stored correctly in Memcached.\n\nI should also test the script's error handling:\n\n- Try to watch a non-existent directory.\n\n- Try to connect to a Memcached server that is not running.\n\n- Try to read a file that is being used by another process.\n\nEnsure that the script logs appropriate errors and continues running where possible.\n\nAnother consideration is performance. If the directory has a large number of files, starting the script and handling multiple events simultaneously could be slow.\n\nBut since `watchdog` handles events asynchronously, and Memcached operations are fast, it should manage reasonably well.\n\nI should also think about how to deploy this script in a production environment, but for now, it's sufficient as a standalone script for development and testing purposes.\n\nIn summary, the script will monitor a specified directory for changes and keep a Memcached cache updated with the latest file contents. It uses `watchdog` for file system event monitoring and `pymemcache` for interacting with Memcached. The script includes logging for tracking events and errors and handles various file operations including creation, modification, deletion, and renaming.\n\n## Final Solution\nTo create a Python script that monitors a specified directory for changes and automatically updates a corresponding Memcached cache with the latest file contents, follow the steps below. This solution involves using the `watchdog` library for file system event monitoring and `pymemcache` for interacting with the Memcached server.\n\n### Solution Code\n\n```python\nimport argparse\nimport sys\nimport time\nimport logging\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\nfrom pymemcache.client.base import Client\nimport os\n\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\nlogger = logging.getLogger()\n\nclass CacheUpdater(FileSystemEventHandler):\n    def __init__(self, memcached_client):\n        self.mc = memcached_client\n\n    def on_modified(self, event):\n        if event.is_directory:\n            return\n        self.update_cache(event.src_path)\n\n    def on_created(self, event):\n        if event.is_directory:\n            return\n        self.update_cache(event.src_path)\n\n    def on_deleted(self, event):\n        if event.is_directory:\n            return\n        normalized_path = event.src_path.replace(os.sep, \"/\")\n        self.mc.delete(normalized_path)\n        logger.info(f\"Deleted: {normalized_path}\")\n\n    def on_moved(self, event):\n        if event.is_directory:\n            return\n        old_path = event.src_path.replace(os.sep, \"/\")\n        new_path = event.dest_path.replace(os.sep, \"/\")\n        self.mc.delete(old_path)\n        self.update_cache(event.dest_path)\n        logger.info(f\"Moved: {old_path} -> {new_path}\")\n\n    def update_cache(self, file_path):\n        normalized_path = file_path.replace(os.sep, \"/\")\n        try:\n            with open(file_path, 'rb') as file:\n                content = file.read()\n                self.mc.set(normalized_path, content)\n                logger.info(f\"Updated: {normalized_path}\")\n        except Exception as e:\n            logger.error(f\"Error processing {file_path}: {e}\")\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Watch a directory and update Memcached cache.\")\n    parser.add_argument(\"directory\", help=\"Directory to watch\")\n    parser.add_argument(\"--memcached-host\", default=\"localhost\", help=\"Memcached server host\")\n    parser.add_argument(\"--memcached-port\", type=int, default=11211, help=\"Memcached server port\")\n    args = parser.parse_args()\n\n    if not os.path.isdir(args.directory):\n        logger.error(f\"Directory {args.directory} does not exist.\")\n        sys.exit(1)\n\n    try:\n        memcached_client = Client((args.memcached_host, args.memcached_port))\n        # Test connection\n        memcached_client.get('test')\n    except Exception as e:\n        logger.error(f\"Unable to connect to Memcached server: {e}\")\n        sys.exit(1)\n\n    event_handler = CacheUpdater(memcached_client)\n    observer = Observer()\n    observer.schedule(event_handler, args.directory, recursive=True)\n    observer.start()\n    logger.info(f\"Watching {args.directory} for changes...\")\n\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n    observer.join()\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### Explanation\n\n1. **Dependencies**:\n    - `watchdog`: For monitoring directory changes.\n    - `pymemcache`: For interacting with the Memcached server.\n\n2. **Script Structure**:\n    - **Argument Parsing**: Uses `argparse` to accept directory path and Memcached server details.\n    - **Logging**: Set up to log information and errors during script execution.\n    - **Event Handling**: Defines handlers for file creation, modification, deletion, and movement.\n    - **Memcached Operations**: Updates or deletes cache entries based on file system events.\n\n3. **Key Features**:\n    - **Recursive Monitoring**: Watches the specified directory and all its subdirectories.\n    - **Normalized Paths**: Converts file paths to a consistent format for Memcached keys.\n    - **Binary File Support**: Reads files in binary mode to handle all file types.\n    - **Error Handling**: Logs errors and continues running even if issues occur with specific files.\n\n4. **Usage**:\n    - Ensure `watchdog` and `pymemcache` are installed.\n    - Run the script with the target directory and Memcached server details.\n    - Monitor logs for cache update activities.\n\nThis script provides a robust way to keep a Memcached cache synchronized with a directory's contents, suitable for caching scenarios requiring real-time updates."
    }
]