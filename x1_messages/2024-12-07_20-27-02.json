[
    {
        "role": "user",
        "content": "Implement a simple LRU (Least Recently Used) cache in C++ that supports insertion, deletion, and retrieval of key-value pairs. The cache should have a fixed size and automatically evict the least recently used item when it reaches capacity.\nPLAINFORMAT"
    },
    {
        "role": "assistant",
        "content": "Implementing a Least Recently Used (LRU) cache in C++ involves creating a data structure that can efficiently manage a fixed number of key-value pairs, automatically removing the least recently used item when the cache reaches its capacity. To achieve this, we can use a combination of a hash map and a doubly-linked list.\n\nHere's a step-by-step guide to implementing an LRU cache in C++:\n\n1. **Understand LRU Cache**: An LRU cache is a cache replacement policy where the least recently used item is removed to make space for new items when the cache reaches its capacity.\n\n2. **Data Structures**:\n   - **Doubly-Linked List**: To maintain the order of usage (most recent to least recent).\n   - **Hash Map**: For O(1) access to nodes in the linked list.\n\n3. **Operations**:\n   - **get(key)**: Retrieve the value associated with the key. If the key exists, update its position to the most recent.\n   - **put(key, value)**: Insert or update the key-value pair. If the cache is at capacity, remove the least recently used item before inserting the new item.\n\n4. **Implementation**:\n\n```cpp\n#include <iostream>\n#include <unordered_map>\n\nclass LRUCache {\nprivate:\n    struct Node {\n        int key;\n        int value;\n        Node* prev;\n        Node* next;\n        Node(int k, int v) : key(k), value(v), prev(nullptr), next(nullptr) {}\n    };\n\n    std::unordered_map<int, Node*> cache;\n    Node* head; // Most recent\n    Node* tail; // Least recent\n    int capacity;\n    int size;\n\n    void moveToFront(Node* node) {\n        if (node == head) return;\n        if (node == tail) {\n            tail = tail->prev;\n            tail->next = nullptr;\n        } else {\n            node->prev->next = node->next;\n            node->next->prev = node->prev;\n        }\n        node->next = head;\n        node->prev = nullptr;\n        head->prev = node;\n        head = node;\n    }\n\n    void removeNode(Node* node) {\n        if (node == head) {\n            head = head->next;\n            if (head) head->prev = nullptr;\n        } else if (node == tail) {\n            tail = tail->prev;\n            if (tail) tail->next = nullptr;\n        } else {\n            node->prev->next = node->next;\n            node->next->prev = node->prev;\n        }\n        delete node;\n        size--;\n    }\n\npublic:\n    LRUCache(int cap) : capacity(cap), size(0) {\n        head = nullptr;\n        tail = nullptr;\n    }\n\n    int get(int key) {\n        if (cache.find(key) == cache.end()) return -1;\n        Node* node = cache[key];\n        moveToFront(node);\n        return node->value;\n    }\n\n    void put(int key, int value) {\n        if (cache.find(key) != cache.end()) {\n            Node* existing = cache[key];\n            existing->value = value;\n            moveToFront(existing);\n        } else {\n            Node* newNode = new Node(key, value);\n            cache[key] = newNode;\n            if (size == 0) {\n                head = newNode;\n                tail = newNode;\n            } else {\n                newNode->next = head;\n                head->prev = newNode;\n                head = newNode;\n            }\n            size++;\n            if (size > capacity) {\n                // Remove the least recently used node (tail)\n                removeNode(tail);\n                cache.erase(tail->key);\n            }\n        }\n    }\n};\n\nint main() {\n    LRUCache cache(2);\n    cache.put(1, 1);\n    cache.put(2, 2);\n    std::cout << cache.get(1) << std::endl; // returns 1\n    cache.put(3, 3);                         // evicts key 2\n    std::cout << cache.get(2) << std::endl; // returns -1 (not found)\n    cache.put(4, 4);                         // evicts key 1\n    std::cout << cache.get(1) << std::endl; // returns -1 (not found)\n    std::cout << cache.get(3) << std::endl; // returns 3\n    std::cout << cache.get(4) << std::endl; // returns 4\n    return 0;\n}\n```\n\n5. **Explanation**:\n   - **Node Structure**: Represents each key-value pair with pointers to previous and next nodes.\n   - **moveToFront**: Moves a node to the head of the list (most recent).\n   - **removeNode**: Removes a node from the list and deletes it.\n   - **get**: Retrieves a value and moves the corresponding node to the front.\n   - **put**: Inserts or updates a key-value pair and manages the cache size.\n\nThis implementation ensures that both get and put operations are performed in O(1) time complexity, making it efficient for caching purposes."
    }
]