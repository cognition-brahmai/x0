[
    {
        "role": "user",
        "content": "Develop a Java program that simulates a multi-threaded file downloader, which downloads a large file in chunks concurrently and combines the chunks into a single output file. The program should accept command-line arguments for the URL of the file to download, the number of threads to use, and the output file path.\nPLAINFORMAT"
    },
    {
        "role": "assistant",
        "content": "Alright, I've got this task to create a Java program that can download a large file in pieces using multiple threads and then put those pieces together into one file. It should take three things from the command line: the URL of the file, how many threads to use, and where to save the file. Okay, let's break this down.\n\nFirst, I need to understand how file downloading works, especially with multiple threads. I know that when you download a file, you're essentially fetching data from a server over the internet. Normally, this is done sequentially, but with multiple threads, we can download different parts of the file at the same time, which should speed things up, especially for large files.\n\nSo, the key here is to split the file into chunks and assign each chunk to a separate thread for downloading. But I need to make sure that the server supports this kind of downloading, meaning it should support range requests. Most servers do, as it's a standard feature in HTTP.\n\nLet me think about the steps involved:\n\n1. **Get the file size:** Before downloading, I need to know the total size of the file so that I can split it into chunks.\n\n2. **Split the file into chunks:** Based on the number of threads provided, I'll divide the file size into equal-sized chunks, each to be downloaded by a separate thread.\n\n3. **Download chunks concurrently:** Each thread will request a specific range of the file from the server and save that part to a temporary file or directly to the output file at the correct position.\n\n4. **Combine the chunks:** Once all threads have finished downloading their respective chunks, I need to make sure that the file is correctly assembled. Since each thread is writing to its designated part of the file, the final file should be complete and intact.\n\nWait a minute, if each thread is writing to a specific part of the file, I need to ensure that there are no conflicts or overlaps in the writing positions. Maybe it's better to have each thread write to its own temporary file and then concatenate them all at the end. That might be safer, especially to handle any issues with file locking or writing positions.\n\nAlternatively, I could have a single output file and coordinate the threads to write to their specific positions in that file. But that might introduce synchronization issues, which could slow things down or even cause data corruption if not handled properly.\n\nUsing separate temporary files for each chunk and then combining them seems simpler and safer. So, I'll go with that approach.\n\nNow, let's think about how to implement this in Java.\n\nFirst, I need to handle command-line arguments. The program should accept three arguments:\n\n- The URL of the file to download.\n\n- The number of threads to use for downloading.\n\n- The path where the downloaded file should be saved.\n\nI should also add some error checking to make sure that the correct number of arguments is provided and that they are valid.\n\nNext, I need to make an initial request to the server to get the file size. I can do this by sending a HEAD request to the URL and checking the Content-Length header.\n\nIf the server supports range requests, I can then make GET requests for specific ranges of the file.\n\nIn Java, I can use the HttpURLConnection class to make HTTP requests.\n\nOnce I have the file size, I can calculate the size of each chunk by dividing the file size by the number of threads. If the file size isn't perfectly divisible by the number of threads, some chunks might be smaller than others.\n\nThen, for each chunk, I'll create a separate thread that downloads that specific range and saves it to a temporary file.\n\nI need to make sure that each thread downloads the correct range. To specify the range, I'll set the \"Range\" header in the HTTP request. For example, \"bytes=0-1023\" for the first 1024 bytes.\n\nEach thread will open the URL connection, set the range header, read the data from the input stream, and write it to its temporary file.\n\nAfter all threads have finished downloading, I'll concatenate all the temporary files in order into the final output file.\n\nFinally, I need to delete the temporary files to clean up.\n\nLet me outline the steps in code terms:\n\n1. Parse command-line arguments:\n\n- URL\n\n- Number of threads\n\n- Output file path\n\n2. Send a HEAD request to get the file size.\n\n3. Calculate chunk sizes based on the number of threads.\n\n4. Create a list of threads, each responsible for downloading a chunk.\n\n5. Start all threads.\n\n6. Wait for all threads to finish.\n\n7. Combine all temporary chunk files into the output file.\n\n8. Delete the temporary files.\n\nNow, let's think about potential issues and how to handle them.\n\n- **Server doesn't support range requests:** In this case, the server might ignore the Range header and send the entire file. I need to check the response headers to see if the server honored the range request. If not, I should fallback to single-threaded downloading.\n\n- **Network issues:** If a thread fails to download its chunk due to a network problem, the entire download should be considered failed, and I should clean up any partial files.\n\n- **File I/O errors:** If there are problems writing to the temporary files or the output file, I need to handle those exceptions gracefully.\n\n- **Thread management:** I need to make sure that all threads have finished before combining the files. I can use Thread.join() for this.\n\n- **Temporary file naming:** I need to generate unique names for each temporary file to avoid overwriting.\n\n- **Large files:** For very large files, I need to make sure that the program doesn't run out of memory. I should read and write data in blocks rather than loading entire chunks into memory.\n\nLet me consider using buffers for reading and writing data to minimize memory usage.\n\nAlso, I should think about thread safety. Since each thread is writing to its own temporary file, there shouldn't be any conflicts there. However, if I were to write to a single file, I'd need to synchronize access to the file, which could introduce performance bottlenecks.\n\nWait, I already decided to use separate temporary files for each chunk to avoid synchronization issues.\n\nAnother consideration is that if the number of threads is larger than the number of chunks (for example, if the file is smaller than the desired chunk size), I should adjust the number of threads accordingly to avoid unnecessary thread creation.\n\nAlso, I should validate the URL to make sure it's accessible and that the output path is writable.\n\nLet me think about the code structure.\n\nI can create a class, say, MultiThreadedDownloader, which will have a method to perform the download.\n\nInside this class, I can have a inner class that extends Thread, say, ChunkDownloader, which will handle the downloading of a single chunk.\n\nEach ChunkDownloader instance will have the URL, the range of bytes to download, and the path to the temporary file where it should write the data.\n\nIn the MultiThreadedDownloader class, I'll handle parsing arguments, getting the file size, calculating chunks, creating and starting threads, waiting for them to finish, combining files, and cleaning up.\n\nFor handling HTTP requests, I'll use HttpURLConnection.\n\nI should also consider adding timeouts to the connections to handle slow responses.\n\nLet me sketch a rough code outline.\n\n```\n\npublic class MultiThreadedDownloader {\n\n    public static void main(String[] args) {\n\n        // Parse command-line arguments\n\n        // Validate arguments\n\n        // Get file size\n\n        // Calculate chunk sizes\n\n        // Create list of threads\n\n        // Start threads\n\n        // Join threads\n\n        // Combine files\n\n        // Delete temp files\n\n    }\n\n    private static class ChunkDownloader extends Thread {\n\n        private String url;\n\n        private long startByte;\n        private long endByte;\n        private String outputFile;\n\n        public ChunkDownloader(String url, long startByte, long endByte, String outputFile) {\n\n            this.url = url;\n\n            this.startByte = startByte;\n\n            this.endByte = endByte;\n\n            this.outputFile = outputFile;\n\n        }\n\n        @Override\n        public void run() {\n\n            // Make HTTP request with Range header\n\n            // Read data and write to temporary file\n\n        }\n\n    }\n\n}\n\n```\n\nI need to handle exceptions properly, especially IOExceptions.\n\nAlso, I should consider using a ExecutorService for managing threads, which might be more efficient and easier to handle than creating multiple Thread instances.\n\nLet me see.\n\nI can use Executors.newFixedThreadPool() to create a thread pool with the specified number of threads.\n\nThen, I can submit Callable tasks for each chunk, and use Future to get the results or handle exceptions.\n\nThis might be better than creating multiple Thread instances manually.\n\nYes, that sounds like a better approach.\n\nSo, I'll revise the plan:\n\n- Use ExecutorService with a fixed thread pool.\n\n- Submit Callable tasks for each chunk.\n\n- Collect the results or handle exceptions using Future.\n\n- Wait for all tasks to complete using awaitTermination or similar.\n\n- Combine the chunks.\n\n- Clean up.\n\nThis should be more efficient and easier to manage.\n\nNow, regarding the temporary file names, I can generate them by appending the chunk number to the output file name, or use a unique identifier.\n\nFor example, if the output file is \"file.zip\", the temporary files could be \"file.zip.part1\", \"file.zip.part2\", and so on.\n\nOr, to avoid naming conflicts, I can use UUIDs for temporary file names.\n\nUsing UUIDs might be safer.\n\nFor combining the files, I can open the output file in append mode and write each chunk file in order.\n\nAlternatively, I can use NIO's FileChannel and position pointers to write each chunk to the correct position in the output file. This might be more efficient than using append mode.\n\nLet me look into that.\n\nYes, using RandomAccessFile and FileChannel, I can specify the position where to write each chunk, which would allow me to write directly to the correct positions in the output file without needing separate temporary files.\n\nThis could be more efficient in terms of disk I/O and avoids the need to delete temporary files afterward.\n\nBut, as I thought earlier, coordinating writes to specific positions might be tricky with multiple threads.\n\nHowever, if I assign each thread a specific position to write to, and ensure that no two threads are writing to overlapping positions, it should be safe.\n\nI need to make sure that each thread writes exactly the number of bytes it's supposed to, and to the correct position.\n\nLet me think about potential race conditions.\n\nIf two threads try to write to the file at the same time, even to different positions, it might cause issues, depending on the file system's handling of concurrent writes.\n\nTo be safe, perhaps it's better to have a single writer thread that collects data from other threads and writes to the file in order.\n\nBut that might defeat the purpose of multi-threaded downloading.\n\nAlternatively, I can have each download thread write to its own temporary file, and then have a separate set of threads responsible for copying those temporary files to the correct positions in the output file.\n\nBut that seems inefficient.\n\nMaybe using a ReentrantLock to synchronize writes to the file would be a good approach.\n\nEach thread would acquire the lock before writing to the file, write its chunk, and then release the lock.\n\nThis way, only one thread writes at a time, but the downloading can still be done in parallel.\n\nThis might introduce some overhead due to locking, but it's necessary to ensure data integrity.\n\nGiven that, perhaps using separate temporary files and then concatenating them is simpler and avoids the need for synchronization during writing.\n\nI think I'll stick with that approach.\n\nSo, each download thread will write its chunk to a separate temporary file, and after all downloads are complete, I'll concatenate these files in order into the final output file.\n\nThen, I'll delete the temporary files.\n\nNow, let's think about error handling.\n\nIf any of the download threads fail to download its chunk, perhaps due to a network issue, the entire download should be considered failed.\n\nIn that case, I need to clean up any partially downloaded files and report the error.\n\nSimilarly, if there's an issue writing to the output file, I need to handle that gracefully.\n\nI should also consider adding retries for failed downloads.\n\nFor example, if a chunk download fails, the thread could retry a certain number of times before giving up.\n\nThis can help handle transient network issues.\n\nLet me add that to the plan.\n\nEach download thread will attempt to download its chunk up to a specified number of retries before failing.\n\nNow, let's think about how to report progress or provide feedback to the user.\n\nSince this is a command-line program, I can print out status messages, such as the overall download progress or if any errors occur.\n\nI should also indicate when the download is complete.\n\nAdditionally, it might be useful to show the estimated time remaining or the download speed, but that might be too complex for this implementation.\n\nFor now, I'll keep it simple and just print start and end messages, and any error messages if something goes wrong.\n\nLet me also consider that for very large files or slow connections, the download might take a long time, so it's important that the program is stable and handles long-running tasks correctly.\n\nAnother consideration is that some servers might limit the rate of requests or the amount of data downloaded in a short period. I need to be respectful of that and perhaps implement some delay between requests if necessary.\n\nBut for now, I'll assume that the server can handle the requests appropriately.\n\nLet me also think about the file naming.\n\nIf the user specifies the output file path, I need to make sure that the directory exists and is writable.\n\nIf the file already exists, I should either overwrite it or prompt the user to confirm overwriting.\n\nFor simplicity, I'll assume that if the file exists, it's okay to overwrite it. But I'll print a message indicating that.\n\nRegarding temporary files, I'll create them in the same directory as the output file to keep things simple.\n\nNow, let's think about the code structure in more detail.\n\nI'll have the MultiThreadedDownloader class with a main method.\n\nIn the main method:\n\n1. Parse command-line arguments.\n\n2. Validate the arguments:\n\n- Check that there are exactly three arguments.\n\n- Validate the URL format.\n\n- Check if the output directory exists and is writable.\n\n- Ensure that the number of threads is a positive integer.\n\n3. Send a HEAD request to get the file size.\n\n4. If the server doesn't support range requests, fallback to single-threaded download.\n\n5. Calculate the chunk sizes based on the file size and number of threads.\n\n6. Create temporary file names for each chunk.\n\n7. Set up an ExecutorService with the specified number of threads.\n\n8. Submit a Callable task for each chunk to download.\n\n9. Collect the futures and wait for all tasks to complete.\n\n10. Handle any exceptions from the download tasks.\n\n11. Combine the temporary chunk files into the output file.\n\n12. Delete the temporary files.\n\n13. Print a completion message.\n\nFor theChunkDownloader class, I'll make it implement Callable<Void>, so it returns nothing but can throw exceptions.\n\nIn the call method:\n\n1. Set up the HTTP connection with the Range header for the specific chunk.\n\n2. Read the data from the input stream in blocks.\n\n3. Write the data to the temporary file.\n\n4. Handle retries in case of download failures.\n\n5. Throw an exception if all retries fail.\n\nI need to make sure that the temporary file is created correctly and that writes are done in a way that doesn't truncate the file or overwrite data.\n\nI should open the temporary file in write mode and ensure that it's created if it doesn't exist.\n\nAlso, I need to handle cases where the download is resuming from a previous attempt, but for now, I'll assume that each download is a fresh start.\n\nLet me also consider that some servers might not allow range requests for certain files, perhaps due to copyright restrictions or server configuration.\n\nIn such cases, I need to handle the response appropriately and fallback to single-threaded downloading.\n\nTo check if the server supports range requests, I can look for the \"Accept-Ranges\" header in the HEAD response. If it's set to \"bytes\", then range requests are supported.\n\nIf not, I'll set the number of threads to 1 and download the file sequentially.\n\nNow, let's think about the chunk size calculation.\n\nSuppose the file size is 1000 bytes and we have 3 threads.\n\nThen, each chunk would be roughly 333 bytes, but the last chunk might be larger to cover the remaining bytes.\n\nSo, chunk sizes might not be exactly equal, but that's okay as long as the entire file is covered.\n\nI need to calculate the start and end bytes for each chunk.\n\nFor example:\n\n- Thread 1: bytes=0-332\n\n- Thread 2: bytes=333-665\n\n- Thread 3: bytes=666-999\n\nI need to make sure that there's no overlap and no missing bytes.\n\nAlso, I need to handle cases where the file size is smaller than the chunk size or where the number of threads is larger than the file size.\n\nIn such cases, I'll adjust the number of threads to match the file size.\n\nWait, actually, if the file is smaller than the desired chunk size, I can still use the specified number of threads, but some threads might not have any data to download.\n\nIn that case, I should calculate the chunk size and assign chunks only up to the file size.\n\nBut to keep things simple, I'll assume that the file size is larger than the chunk size.\n\nIf the file is smaller, I'll just download it in a single chunk.\n\nNow, regarding the temporary files, I'll create them in the same directory as the output file.\n\nI'll name them using UUIDs to avoid naming conflicts.\n\nAfter all chunks are downloaded, I'll read each temporary file in order and append its contents to the output file.\n\nThen, delete the temporary files.\n\nI need to make sure that the chunks are combined in the correct order.\n\nTo ensure this, I'll name the temporary files with a prefix that includes the chunk number, so I can sort them accordingly when combining.\n\nWait, using UUIDs might make it hard to associate each temporary file with its chunk number.\n\nSo, perhaps it's better to name the temporary files with a prefix indicating the chunk number, like \"output.file.part1\", \"output.file.part2\", etc.\n\nThen, when combining, I can sort the files based on the chunk number.\n\nThis way, I can ensure that the chunks are combined in the correct order.\n\nAlternatively, I can keep track of the chunk numbers and their corresponding temporary file names in a list, and then iterate through the list in order when combining the files.\n\nThat might be more reliable than relying on file name sorting.\n\nI think keeping a list of chunk numbers and their temporary file names would be the best approach.\n\nNow, let's think about the code structure again.\n\nIn the MultiThreadedDownloader class:\n\n- A method to parse and validate command-line arguments.\n\n- A method to send a HEAD request and get the file size.\n\n- A method to calculate chunk sizes based on the file size and number of threads.\n\n- A method to create temporary file names for each chunk.\n\n- A method to create and submit download tasks to the ExecutorService.\n\n- A method to combine the temporary files into the output file.\n\n- A method to delete the temporary files.\n\n- The main method will orchestrate these steps.\n\nFor the ChunkDownloader class:\n\n- It will implement Callable<Void>.\n\n- It will have parameters for the URL, start byte, end byte, and temporary file path.\n\n- It will make a GET request with the Range header set to the specified bytes.\n\n- It will read the response input stream and write it to the temporary file in blocks.\n\n- It will handle retries in case of download failures.\n\nNow, let's think about the retry mechanism.\n\nI'll define a constant for the number of retries, say, 3.\n\nEach download task will attempt to download its chunk up to that number of times before failing.\n\nBetween retries, I'll introduce a delay, perhaps increasing with each retry, to give the server some time to recover.\n\nThis is a simple exponential backoff strategy.\n\nFor example:\n\n- Retry 1: no delay\n\n- Retry 2: 1 second delay\n\n- Retry 3: 2 seconds delay\n\nIf all retries fail, the task will throw an exception, which will be propagated to the main thread.\n\nIn the main thread, if any download task fails, the entire download should be considered failed, and I'll need to clean up any partially downloaded files.\n\nNow, let's think about how to handle the HTTP connections.\n\nI need to set the Range header for each chunk download.\n\nFor example:\n\n\"Range: bytes=0-1023\"\n\n\"Range: bytes=1024-2047\"\n\nAnd so on.\n\nI also need to handle the case where the server doesn't support range requests or where the Range header is not satisfied.\n\nIn such cases, the server might return a 200 OK response with the entire file, which is not what we want.\n\nTo handle this, I need to check the response code and the Content-Range header.\n\nIf the response code is 206 Partial Content, that means the range request was honored.\n\nIf it's 200 OK and the Content-Length matches the requested range, that's also acceptable.\n\nBut if it's 200 OK with a Content-Length that doesn't match the requested range, that means the server sent the entire file, and I need to handle it accordingly.\n\nIn that case, I should fallback to single-threaded downloading.\n\nWait, but if one thread gets the entire file, and others get nothing, that's not useful.\n\nSo, perhaps I need to check the response headers before starting the download.\n\nWait, maybe I should first send a HEAD request to check if range requests are supported, and if not, proceed with single-threaded downloading.\n\nThen, in the download tasks, I can assume that range requests are supported, since I already checked in the HEAD request.\n\nBut to be safe, I'll still check the response headers in the download tasks.\n\nIf a task receives a response that doesn't match the expected range, it can throw an exception or handle it appropriately.\n\nNow, let's think about the code for sending HTTP requests.\n\nIn Java, HttpURLConnection is suitable for this purpose.\n\nI need to set the request method to GET, set the Range header, and connect to the URL.\n\nThen, I'll check the response code and headers to ensure that the range request was honored.\n\nIf everything is okay, I'll read the input stream and write it to the temporary file.\n\nI need to handle cases where the content-encoding is applied, but for simplicity, I'll assume that the content is not encoded.\n\nNow, for writing to the temporary file, I'll use FileOutputStream.\n\nI'll open the file in write mode and write the bytes from the input stream in blocks.\n\nI should choose a suitable buffer size, perhaps 8KB or 16KB, to balance between performance and memory usage.\n\nLet me decide on a buffer size, say, 8192 bytes.\n\nNow, for combining the temporary files into the output file, I'll open the output file in write mode and append each chunk file in order.\n\nI'll read each chunk file using a FileInputStream and write its contents to the output file using a FileOutputStream.\n\nAgain, I'll use a buffer to read and write the data in blocks.\n\nAfter combining, I'll delete the temporary files using File.delete().\n\nI need to handle cases where the output file already exists.\n\nI'll check if the file exists before starting the download, and if it does, I'll overwrite it.\n\nBut I'll print a message indicating that the existing file will be overwritten.\n\nNow, let's think about error handling in more detail.\n\n- If the URL is invalid or unreachable, I'll catch IOExceptions and report an error.\n\n- If the output path is invalid or not writable, I'll check that before starting and report an error.\n\n- If a download thread fails to download its chunk after retries, I'll propagate the exception to the main thread and abort the download.\n\n- If there's an issue combining the files or deleting the temporary files, I'll handle those exceptions and report errors accordingly.\n\nI need to make sure that the program doesn't leave partial files or temporary files behind in case of errors.\n\nSo, I'll use finally blocks to ensure that temporary files are deleted, even if errors occur.\n\nNow, let's think about how to test this program.\n\nI'll need a large file to download that supports range requests.\n\nI can use a file from a public CDN or a large open-source project's release.\n\nI'll test the program with different numbers of threads to see if it downloads correctly and faster with more threads.\n\nI'll also test with invalid URLs, invalid number of threads, and invalid output paths to ensure that error handling works correctly.\n\nAdditionally, I'll test with servers that don't support range requests to verify the fallback to single-threaded downloading.\n\nNow, let's outline the steps in code.\n\nFirst, parse and validate arguments:\n\n- Check if exactly three arguments are provided.\n\n- Validate the URL using URL class to ensure it's a valid URL.\n\n- Check if the output directory exists and is writable.\n\n- Validate that the number of threads is a positive integer.\n\nThen, send a HEAD request to get the file size:\n\n- Create a HttpURLConnection with HEAD method.\n\n- Get the Content-Length header to know the file size.\n\n- Check if the server supports range requests by looking at the Accept-Ranges header.\n\nIf range requests are not supported, set the number of threads to 1.\n\nCalculate chunk sizes:\n\n- Divide the file size by the number of threads.\n\n- Assign start and end bytes for each chunk.\n\nCreate temporary file names:\n\n- For each chunk, create a temporary file with a unique name in the output directory.\n\nSet up ExecutorService:\n\n- Create a fixed thread pool with the specified number of threads.\n\nSubmit download tasks:\n\n- For each chunk, create a ChunkDownloader task and submit it to the ExecutorService.\n\nWait for all tasks to complete:\n\n- Use Futures to collect results and handle any exceptions.\n\nCombine the temporary files:\n\n- Open the output file in write mode.\n\n- For each chunk file, in order, read its contents and write them to the output file.\n\nDelete the temporary files:\n\n- Iterate through the list of temporary files and delete them.\n\nPrint a completion message.\n\nNow, let's think about implementing the ChunkDownloader class.\n\nIt should implement Callable<Void> and have the following fields:\n\n- URL\n\n- Start byte\n\n- End byte\n\n- Temporary file path\n\n- Number of retries\n\n- Delay between retries\n\nIn the call method:\n\n- Set up the HTTP connection with the Range header.\n\n- Attempt to download the chunk up to the specified number of retries.\n\n- If successful, write the data to the temporary file.\n\n- If all retries fail, throw an exception.\n\nIn more detail:\n\n- Construct the Range header value as \"bytes=startByte-endByte\".\n\n- Set the request property \"Range\" to the constructed value.\n\n- Connect to the URL using HttpURLConnection.\n\n- Check the response code.\n\n- If it's 206 Partial Content or 200 OK with Content-Length matching the requested range, proceed.\n\n- Read the input stream in blocks and write to the temporary file.\n\n- If any IOException occurs, retry up to the specified number of times, with increasing delays between retries.\n\n- If all retries fail, throw an IOException with an appropriate message.\n\nNow, let's think about the code for combining the files.\n\nI need to ensure that the chunk files are combined in the correct order.\n\nSince I'm keeping a list of chunk files with their chunk numbers, I can sort them based on the chunk number before combining.\n\nAlternatively, if I name the temporary files with a prefix that includes the chunk number, I can sort them alphabetically.\n\nFor example:\n\n- output.file.part1\n\n- output.file.part2\n\n- output.file.part3\n\nAnd so on.\n\nThen, when combining, I can list all files with the prefix \"output.file.part\" and sort them numerically.\n\nBut to make it more reliable, I'll keep a list of chunk files in order and iterate through that list when combining.\n\nThis way, I can ensure that the chunks are combined in the correct sequence.\n\nNow, let's think about the code for deleting the temporary files.\n\nI'll iterate through the list of temporary files and call delete() on each one.\n\nIf a file cannot be deleted, I'll print a warning message but continue with the deletion of other files.\n\nAfter all deletions, I'll check if any temporary files remain and handle them accordingly.\n\nNow, let's consider writing a small example to test this logic.\n\nSuppose the file size is 2048 bytes and we have 2 threads.\n\nThen, each chunk would be 1024 bytes.\n\n- Chunk 1: bytes=0-1023\n\n- Chunk 2: bytes=1024-2047\n\nEach thread would download its respective chunk and save it to a temporary file.\n\nThen, the main thread would combine these two temporary files into the output file.\n\nFinally, it would delete the temporary files.\n\nSeems straightforward.\n\nNow, let's consider edge cases.\n\n- File size is smaller than the chunk size.\n\n- File size is not divisible by the number of threads.\n\n- Number of threads is larger than the file size.\n\n- Server doesn't support range requests.\n\n- Network errors during download.\n\n- File I/O errors.\n\nI need to handle all these cases appropriately.\n\nFor example, if the file size is smaller than the chunk size, I'll still download it in a single chunk using one thread.\n\nIf the number of threads is larger than the file size, I'll adjust the number of threads to match the file size.\n\nNow, let's think about how to implement the retries in the ChunkDownloader class.\n\nI'll have a loop that attempts to download the chunk up to the specified number of retries.\n\nIf an IOException occurs, it will wait for an increasing amount of time before retrying.\n\nAfter all retries fail, it will throw an IOException with a message indicating the failure.\n\nI can use a for loop with a counter for the number of retries.\n\nFor each retry, I'll try to download the chunk.\n\nIf successful, I'll break out of the loop.\n\nIf not, I'll wait for a certain delay and try again.\n\nThe delay can increase exponentially with each retry to give the server more time to recover.\n\nFor example:\n\n- Retry 1: no delay\n\n- Retry 2: 1 second delay\n\n- Retry 3: 2 seconds delay\n\nAnd so on.\n\nI'll use Thread.sleep() to introduce the delay between retries.\n\nBut I need to handle InterruptedException if the thread is interrupted during sleep.\n\nNow, let's think about how to handle the response from the server.\n\nAfter setting the Range header, I need to check if the server honored the range request.\n\nIf the response code is 206 Partial Content, that means the range request was successful.\n\nIf the response code is 200 OK, I need to check the Content-Length header to see if it matches the requested range.\n\nIf it matches, it's acceptable.\n\nIf it doesn't match, it means the server sent the entire file, and I need to handle it accordingly.\n\nIn that case, I should consider the download failed and retry or fallback to single-threaded downloading.\n\nBut to avoid downloading the entire file multiple times, perhaps it's better to fallback to single-threaded downloading only if range requests are not supported, as detected in the HEAD request.\n\nIn the HEAD request, if the server responds with Accept-Ranges: bytes, then it supports range requests.\n\nIf not, it doesn't support range requests, and I should set the number of threads to 1.\n\nThen, in the download tasks, I can assume that range requests are supported, since the HEAD request already indicated support.\n\nThis way, I can simplify the logic in the download tasks.\n\nBut to be extra cautious, I'll still check the response code and headers in the download tasks.\n\nIf a task receives a response that doesn't match the expected range, it can throw an exception, and the main thread can handle it accordingly.\n\nNow, let's think about implementing the fallback to single-threaded downloading.\n\nIn the main method, after sending the HEAD request, if the server doesn't support range requests, I'll set the number of threads to 1 and proceed with a single download task for the entire file.\n\nIn this case, I won't set the Range header, and the server will send the entire file.\n\nThen, I'll have only one temporary file, which will be the output file.\n\nNo need for combining files in this case.\n\nThis simplifies things for the single-threaded case.\n\nNow, let's think about the code structure again.\n\nI'll have the MultiThreadedDownloader class with a main method.\n\nInside the main method:\n\n- Parse and validate arguments.\n\n- Send HEAD request to get file size and check for range support.\n\n- If range support is not available, set number of threads to 1.\n\n- Calculate chunk sizes based on file size and number of threads.\n\n- Create temporary file names for each chunk.\n\n- Set up ExecutorService with the specified number of threads.\n\n- Submit a list of Callable tasks for each chunk.\n\n- Wait for all tasks to complete.\n\n- Combine temporary files into the output file.\n\n- Delete temporary files.\n\n- Print completion message.\n\nIn the ChunkDownloader class:\n\n- Implement Callable<Void>.\n\n- Set up HTTP connection with Range header.\n\n- Attempt to download the chunk with retries.\n\n- Write the downloaded data to the temporary file.\n\n- Throw IOException if all retries fail.\n\nNow, let's think about how to handle the output file.\n\nIn the multi-threaded case, I'll have multiple temporary files that need to be combined into the output file.\n\nIn the single-threaded case, I'll have only one temporary file, which can be renamed to the output file.\n\nBut to keep the code consistent, perhaps in the single-threaded case, I'll still have one temporary file and then move it to the output file.\n\nThis way, the combining and deleting steps remain the same.\n\nNow, let's think about how to implement the combining of files.\n\nI'll open the output file in write mode.\n\nThen, for each temporary file in order, I'll read its contents and write them to the output file.\n\nFinally, I'll close the output file.\n\nAfter that, I'll delete the temporary files.\n\nI need to make sure that if any error occurs during combining or deleting, I handle it appropriately and inform the user.\n\nNow, let's think about how to handle exceptions in the download tasks.\n\nEach download task should wrap its downloading logic in a try-catch block, handle retries, and finally, if all retries fail, throw an IOException.\n\nIn the main method, when waiting for all tasks to complete, I'll use Future.get() to retrieve the results.\n\nIf any task throws an exception, Future.get() will throw an ExecutionException wrapping the original exception.\n\nI need to catch ExecutionException in the main method and handle it by cleaning up any partial files and reporting the error.\n\nNow, let's think about how to implement the retries in the ChunkDownloader class.\n\nHere's a rough outline:\n\nfor (int attempt = 1; attempt <= MAX_RETRIES; attempt++) {\n\ntry {\n\n// Set up HTTP connection\n\n// Download the chunk\n\n// Write to temporary file\n\n// If successful, break out of the loop\n\n} catch (IOException e) {\n\nif (attempt == MAX_RETRIES) {\n\nthrow new IOException(\"Failed to download chunk after \" + MAX_RETRIES + \" attempts.\", e);\n\n}\n\n// Wait before retrying\n\ntry {\n\nThread.sleep(calculateDelay(attempt));\n\n} catch (InterruptedException ie) {\n\n// Restore the interrupted status\n\nThread.currentThread().interrupt();\n\nthrow new IOException(\"Download interrupted during retry wait.\", ie);\n\n}\n\n}\n\n}\n\nThe calculateDelay method can implement an exponential backoff strategy.\n\nFor example:\n\nprivate long calculateDelay(int attempt) {\n\nreturn (long) (Math.pow(2, attempt - 1) * BASE_DELAY_MILLIS);\n\n}\n\nWhere BASE_DELAY_MILLIS is a constant, say, 1000 milliseconds (1 second).\n\nSo, retries will have delays of 1s, 2s, 4s, etc.\n\nNow, let's think about the code for sending the HTTP request and handling the response.\n\nI'll need to set the Range header and connect to the URL.\n\nThen, check the response code and headers.\n\nHere's a rough outline:\n\nURL url = new URL(this.url);\n\nHttpURLConnection connection = (HttpURLConnection) url.openConnection();\n\nconnection.setRequestMethod(\"GET\");\n\nconnection.setRequestProperty(\"Range\", \"bytes=\" + this.startByte + \"-\" + this.endByte);\n\nconnection.connect();\n\nint responseCode = connection.getResponseCode();\n\nif (responseCode == 206 || (responseCode == 200 && connection.getContentLength() == this.endByte - this.startByte + 1)) {\n\n// Range request honored, proceed to download\n\n} else {\n\nthrow new IOException(\"Server didn't honor range request for chunk \" + this.startByte + \"-\" + this.endByte);\n\n}\n\nThen, read the input stream and write to the temporary file.\n\nI need to handle cases where the Content-Length doesn't match the expected length.\n\nBut, if I've already checked the response code and Content-Length, perhaps I can assume that the server is sending the correct data.\n\nNow, let's think about buffering the input and output streams.\n\nI'll use BufferedInputStream for the input stream and BufferedOutputStream for the output stream.\n\nThis will improve performance by reducing the number of I/O operations.\n\nI'll choose a buffer size, say, 8192 bytes.\n\nNow, for writing to the temporary file, I'll open a FileOutputStream and wrap it in a BufferedOutputStream.\n\nSimilarly, for reading from the input stream, I'll get the connection's input stream and wrap it in a BufferedInputStream.\n\nThen, I'll read from the input stream and write to the output stream in blocks of the buffer size.\n\nI need to handle cases where the input stream has fewer bytes than expected.\n\nNow, let's think about the temporary file naming.\n\nI'll create temporary files with names like \"output.file.part001\", \"output.file.part002\", etc.\n\nThis way, I can sort them numerically when combining.\n\nAlternatively, I can keep a list of temporary files in the order of their chunks.\n\nTo make it more robust, I'll keep a list of temporary files with their chunk numbers, and when combining, iterate through the list in order.\n\nNow, let's think about how to implement the combining of files.\n\nI'll open the output file in write mode.\n\nThen, for each temporary file in order, I'll read its contents and write them to the output file.\n\nFinally, I'll close the output file.\n\nI need to make sure that there are no overlaps or missing parts.\n\nTo handle large files efficiently, I'll use a buffer to read and write in blocks, similar to the download process.\n\nNow, let's think about how to implement the deletion of temporary files.\n\nI'll iterate through the list of temporary files and call delete() on each one.\n\nIf a file cannot be deleted, I'll print a warning message but continue with the deletion of other files.\n\nAfter all deletions, I'll check if any temporary files still exist and handle them accordingly.\n\nNow, let's think about how to handle exceptions in the main method.\n\nIf any download task fails, I'll catch the ExecutionException, print an error message, and clean up any partial files.\n\nSimilarly, if there's an error combining the files or deleting the temporary files, I'll handle those exceptions and inform the user.\n\nNow, let's think about writing the code step by step.\n\nFirst, parse and validate command-line arguments.\n\npublic static void main(String[] args) {\n\nif (args.length != 3) {\n\nSystem.err.println(\"Usage: java MultiThreadedDownloader <URL> <num_threads> <output_file>\");\n\nSystem.exit(1);\n\n}\n\nString url = args[0];\n\nint numThreads;\n\ntry {\n\nnumThreads = Integer.parseInt(args[1]);\n\nif (numThreads < 1) {\n\nthrow new IllegalArgumentException(\"Number of threads must be at least 1.\");\n\n}\n\n} catch (NumberFormatException e) {\n\nSystem.err.println(\"Invalid number of threads: \" + args[1]);\n\nSystem.exit(1);\n\n}\n\nString outputFilePath = args[2];\n\n// Validate URL\n\ntry {\n\nnew URL(url);\n\n} catch (MalformedURLException e) {\n\nSystem.err.println(\"Invalid URL: \" + url);\n\nSystem.exit(1);\n\n}\n\n// Check output directory\n\nFile outputFile = new File(outputFilePath);\n\nFile outputDir = outputFile.getParentFile();\n\nif (outputDir != null && !outputDir.exists()) {\n\nSystem.err.println(\"Output directory does not exist: \" + outputDir.getAbsolutePath());\n\nSystem.exit(1);\n\n}\n\nif (outputFile.exists()) {\n\nSystem.out.println(\"Output file already exists and will be overwritten: \" + outputFile.getAbsolutePath());\n\n}\n\n// Proceed with download\n\n}\n\nNext, send a HEAD request to get the file size and check for range support.\n\ntry {\n\nURL urlObj = new URL(url);\n\nHttpURLConnection connection = (HttpURLConnection) urlObj.openConnection();\n\nconnection.setRequestMethod(\"HEAD\");\n\nint responseCode = connection.getResponseCode();\n\nif (responseCode == 200) {\n\nlong fileSize = connection.getContentLengthLong();\n\nString acceptRanges = connection.getHeaderField(\"Accept-Ranges\");\n\nif (\"bytes\".equals(acceptRanges)) {\n\nSystem.out.println(\"File size: \" + fileSize + \" bytes\");\n\n} else {\n\nSystem.out.println(\"Server does not support range requests. Falling back to single-threaded download.\");\n\nnumThreads = 1;\n\n}\n\n} else {\n\nSystem.err.println(\"Failed to get file size. Server responded with code: \" + responseCode);\n\nSystem.exit(1);\n\n}\n\n} catch (IOException e) {\n\nSystem.err.println(\"Error sending HEAD request: \" + e.getMessage());\n\nSystem.exit(1);\n\n}\n\nThen, calculate chunk sizes.\n\nlong chunkSize = fileSize / numThreads;\n\nlong lastChunkSize = fileSize - (numThreads - 1) * chunkSize;\n\nNow, create temporary file names.\n\nList<TemporaryFile> tempFiles = new ArrayList<>();\n\nfor (int i = 0; i < numThreads; i++) {\n\nlong start = i * chunkSize;\n\nlong end = (i == numThreads - 1) ? fileSize - 1 : (i + 1) * chunkSize - 1;\n\nFile tempFile = createTempFile(outputFile);\n\ntempFiles.add(new TemporaryFile(i, start, end, tempFile));\n\n}\n\nWhere createTempFile() creates a temporary file in the same directory as the output file with a unique name.\n\nNow, set up ExecutorService.\n\nExecutorService executor = Executors.newFixedThreadPool(numThreads);\n\nThen, submit download tasks.\n\nList<Future<?>> futures = new ArrayList<>();\n\nfor (TemporaryFile temp : tempFiles) {\n\nCallable<Void> task = new ChunkDownloader(url, temp.getStart(), temp.getEnd(), temp.getFile());\n\nFuture<?> future = executor.submit(task);\n\nfutures.add(future);\n\n}\n\nWait for all tasks to complete.\n\nfor (Future<?> future : futures) {\n\ntry {\n\nfuture.get();\n\n} catch (ExecutionException e) {\n\nSystem.err.println(\"Download failed: \" + e.getCause().getMessage());\n\ncleanup(tempFiles);\n\nSystem.exit(1);\n\n} catch (InterruptedException e) {\n\nSystem.err.println(\"Download interrupted.\");\ncleanup(tempFiles);\n\nSystem.exit(1);\n}\n}\n\nCombine temporary files into the output file.\n\ntry (FileOutputStream fos = new FileOutputStream(outputFile)) {\n\nfor (TemporaryFile temp : tempFiles) {\n\ntry (FileInputStream fis = new FileInputStream(temp.getFile())) {\n\nbyte[] buffer = new byte[8192];\n\nint bytesRead;\n\nwhile ((bytesRead = fis.read(buffer)) != -1) {\n\nfos.write(buffer, 0, bytesRead);\n}\n\n}\n\n}\n\n} catch (IOException e) {\n\nSystem.err.println(\"Error combining files: \" + e.getMessage());\n\ncleanup(tempFiles);\n\nSystem.exit(1);\n\n}\n\nDelete temporary files.\n\ncleanup(tempFiles);\n\nPrint completion message.\n\nSystem.out.println(\"Download completed successfully.\");\n\nNow, implement the cleanup method.\n\nprivate static void cleanup(List<TemporaryFile> tempFiles) {\n\nfor (TemporaryFile temp : tempFiles) {\n\nif (temp.getFile().exists()) {\n\ntemp.getFile().delete();\n\n}\n\n}\n\n}\n\nDefine the TemporaryFile class.\n\nprivate static class TemporaryFile {\n\nprivate int chunkNumber;\n\nprivate long start;\n\nprivate long end;\n\nprivate File file;\n\npublic TemporaryFile(int chunkNumber, long start, long end, File file) {\n\nthis.chunkNumber = chunkNumber;\n\nthis.start = start;\n\nthis.end = end;\n\nthis.file = file;\n\n}\n\n// Getters\n\n}\n\nImplement the ChunkDownloader class.\n\nprivate static class ChunkDownloader implements Callable<Void> {\n\nprivate String url;\n\nprivate long startByte;\n\nprivate long endByte;\n\nprivate File outputFile;\n\npublic ChunkDownloader(String url, long startByte, long endByte, File outputFile) {\n\nthis.url = url;\n\nthis.startByte = startByte;\n\nthis.endByte = endByte;\n\nthis.outputFile = outputFile;\n\n}\n\n@Override\n\npublic Void call() throws Exception {\n\nint MAX_RETRIES = 3;\n\nint attempt = 1;\n\nwhile (attempt <= MAX_RETRIES) {\n\ntry {\n\ndownloadChunk();\n\nreturn null;\n\n} catch (IOException e) {\n\nif (attempt == MAX_RETRIES) {\n\nthrow new IOException(\"Failed to download chunk after \" + MAX_RETRIES + \" attempts.\", e);\n\n}\n\ntry {\n\nThread.sleep(calculateDelay(attempt));\n\n} catch (InterruptedException ie) {\n\nThread.currentThread().interrupt();\n\nthrow new IOException(\"Download interrupted during retry wait.\", ie);\n\n}\n\nattempt++;\n\n}\n\n}\n\n}\n\nprivate void downloadChunk() throws IOException {\n\nURL urlObj = new URL(url);\n\nHttpURLConnection connection = (HttpURLConnection) urlObj.openConnection();\n\nconnection.setRequestMethod(\"GET\");\n\nconnection.setRequestProperty(\"Range\", \"bytes=\" + startByte + \"-\" + endByte);\n\nconnection.connect();\n\nint responseCode = connection.getResponseCode();\n\nif (responseCode == 206 || (responseCode == 200 && connection.getContentLength() == (int)(endByte - startByte + 1))) {\n\ntry (BufferedInputStream bis = new BufferedInputStream(connection.getInputStream());\n\nBufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(outputFile))) {\n\nbyte[] buffer = new byte[8192];\n\nint bytesRead;\n\nwhile ((bytesRead = bis.read(buffer)) != -1) {\n\nbos.write(buffer, 0, bytesRead);\n\n}\n\n}\n\n} else {\n\nthrow new IOException(\"Server didn't honor range request for chunk \" + startByte + \"-\" + endByte);\n\n}\n\n}\n\nprivate long calculateDelay(int attempt) {\n\nreturn (long) (Math.pow(2, attempt - 1) * 1000); // Exponential backoff: 1s, 2s, 4s, etc.\n\n}\n\n}\n\nThis is a rough outline of the code. There are a few things to consider:\n\n- Error handling can be improved by providing more detailed messages.\n\n- For very large files, using NIO channels or other optimizations might be necessary.\n\n- Consider adding progress reporting for each chunk or overall download progress.\n\n- Handle cases where the file size is zero or the number of threads is larger than the file size.\n\n- Ensure that the temporary files are properly deleted even if the program is interrupted.\n\n- Add comments to the code for better readability.\n\n- Consider using try-with-resources for proper resource management.\n\n- Make sure that the program doesn't leave partial files if the download is interrupted or fails.\n\nThis should give you a good starting point for implementing the multi-threaded file downloader in Java.\n\n## Final Solution\nTo create a multi-threaded file downloader in Java, follow these steps:\n\n### Approach\n\n1. **Accept Command-Line Arguments:** The program accepts the URL of the file to download, the number of threads to use, and the output file path.\n2. **Check Server Support for Range Requests:** Send a HEAD request to determine if the server supports range requests and to get the file size.\n3. **Split the File into Chunks:** Divide the file into equal-sized chunks based on the number of threads.\n4. **Download Chunks Concurrently:** Use multiple threads to download each chunk in parallel.\n5. **Combine Chunks:** Merge the downloaded chunks into a single output file.\n6. **Clean Up:** Delete the temporary chunk files.\n\n### Solution Code\n\n```java\nimport java.io.*;\nimport java.net.HttpURLConnection;\nimport java.net.URL;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.concurrent.*;\n\nclass MultiThreadedDownloader {\n\n    private static final int BUFFER_SIZE = 8192;\n    private static final int MAX_RETRIES = 3;\n\n    public static void main(String[] args) {\n        if (args.length != 3) {\n            System.err.println(\"Usage: java MultiThreadedDownloader <URL> <num_threads> <output_file>\");\n            System.exit(1);\n        }\n\n        String url = args[0];\n        int numThreads;\n        try {\n            numThreads = Integer.parseInt(args[1]);\n            if (numThreads < 1) {\n                throw new IllegalArgumentException(\"Number of threads must be at least 1.\");\n            }\n        } catch (NumberFormatException e) {\n            System.err.println(\"Invalid number of threads: \" + args[1]);\n            System.exit(1);\n        }\n\n        String outputFilePath = args[2];\n        File outputFile = new File(outputFilePath);\n        File outputDir = outputFile.getParentFile();\n        if (outputDir != null && !outputDir.exists()) {\n            System.err.println(\"Output directory does not exist: \" + outputDir.getAbsolutePath());\n            System.exit(1);\n        }\n        if (outputFile.exists()) {\n            System.out.println(\"Output file already exists and will be overwritten: \" + outputFile.getAbsolutePath());\n        }\n\n        try {\n            long fileSize = get fileSize(url);\n            if (fileSize == -1) {\n                System.err.println(\"Failed to retrieve file size.\");\n                System.exit(1);\n            }\n\n            boolean rangeSupported = isRangeSupported(url);\n            if (!rangeSupported) {\n                System.out.println(\"Server does not support range requests. Falling back to single-threaded download.\");\n                numThreads = 1;\n            }\n\n            List<TemporaryFile> tempFiles = createTemporaryFiles(outputFile, numThreads, fileSize);\n\n            ExecutorService executor = Executors.newFixedThreadPool(numThreads);\n            List<Future<?>> futures = new ArrayList<>();\n\n            for (TemporaryFile temp : tempFiles) {\n                Callable<Void> task = new ChunkDownloader(url, temp.getStart(), temp.getEnd(), temp.getFile());\n                Future<?> future = executor.submit(task);\n                futures.add(future);\n            }\n\n            for (Future<?> future : futures) {\n                future.get();\n            }\n\n            combineFiles(outputFile, tempFiles);\n            cleanup(tempFiles);\n\n            System.out.println(\"Download completed successfully.\");\n        } catch (Exception e) {\n            System.err.println(\"Download failed: \" + e.getMessage());\n            System.exit(1);\n        }\n    }\n\n    private static long getFileSize(String url) throws IOException {\n        HttpURLConnection connection = (HttpURLConnection) new URL(url).openConnection();\n        connection.setRequestMethod(\"HEAD\");\n        connection.connect();\n        return connection.getContentLengthLong();\n    }\n\n    private static boolean isRangeSupported(String url) throws IOException {\n        HttpURLConnection connection = (HttpURLConnection) new URL(url).openConnection();\n        connection.setRequestMethod(\"HEAD\");\n        connection.connect();\n        return \"bytes\".equals(connection.getHeaderField(\"Accept-Ranges\"));\n    }\n\n    private static List<TemporaryFile> createTemporaryFiles(File outputFile, int numThreads, long fileSize) {\n        List<TemporaryFile> tempFiles = new ArrayList<>();\n        long chunkSize = fileSize / numThreads;\n        long lastChunkSize = fileSize - (numThreads - 1) * chunkSize;\n\n        for (int i = 0; i < numThreads; i++) {\n            long start = i * chunkSize;\n            long end = (i == numThreads - 1) ? fileSize - 1 : (i + 1) * chunkSize - 1;\n            File tempFile = getTempFile(outputFile);\n            tempFiles.add(new TemporaryFile(i, start, end, tempFile));\n        }\n        return tempFiles;\n    }\n\n    private static File getTempFile(File outputFile) {\n        try {\n            return File.createTempFile(\"part\", null, outputFile.getParentFile());\n        } catch (IOException e) {\n            throw new RuntimeException(\"Could not create temp file\", e);\n        }\n    }\n\n    private static void combineFiles(File outputFile, List<TemporaryFile> tempFiles) throws IOException {\n        try (FileOutputStream fos = new FileOutputStream(outputFile)) {\n            for (TemporaryFile temp : tempFiles) {\n                try (FileInputStream fis = new FileInputStream(temp.getFile())) {\n                    byte[] buffer = new byte[BUFFER_SIZE];\n                    int bytesRead;\n                    while ((bytesRead = fis.read(buffer)) != -1) {\n                        fos.write(buffer, 0, bytesRead);\n                    }\n                }\n            }\n        }\n    }\n\n    private static void cleanup(List<TemporaryFile> tempFiles) {\n        for (TemporaryFile temp : tempFiles) {\n            if (temp.getFile().exists()) {\n                temp.getFile().delete();\n            }\n        }\n    }\n}\n\nclass TemporaryFile {\n    private int chunkNumber;\n    private long start;\n    private long end;\n    private File file;\n\n    public TemporaryFile(int chunkNumber, long start, long end, File file) {\n        this.chunkNumber = chunkNumber;\n        this.start = start;\n        this.end = end;\n        this.file = file;\n    }\n\n    public int getChunkNumber() {\n        return chunkNumber;\n    }\n\n    public long getStart() {\n        return start;\n    }\n\n    public long getEnd() {\n        return end;\n    }\n\n    public File getFile() {\n        return file;\n    }\n}\n\nclass ChunkDownloader implements Callable<Void> {\n    private String url;\n    private long startByte;\n    private long endByte;\n    private File outputFile;\n\n    public ChunkDownloader(String url, long startByte, long endByte, File outputFile) {\n        this.url = url;\n        this.startByte = startByte;\n        this.endByte = endByte;\n        this.outputFile = outputFile;\n    }\n\n    @Override\n    public Void call() throws Exception {\n        int attempt = 1;\n        while (attempt <= MultiThreadedDownloader.MAX_RETRIES) {\n            try {\n                downloadChunk();\n                return null;\n            } catch (IOException e) {\n                if (attempt == MultiThreadedDownloader.MAX_RETRIES) {\n                    throw new IOException(\"Failed to download chunk after \" + MultiThreadedDownloader.MAX_RETRIES + \" attempts.\", e);\n                }\n                try {\n                    Thread.sleep(calculateDelay(attempt));\n                } catch (InterruptedException ie) {\n                    Thread.currentThread().interrupt();\n                    throw new IOException(\"Download interrupted during retry wait.\", ie);\n                }\n                attempt++;\n            }\n        }\n        return null;\n    }\n\n    private void downloadChunk() throws IOException {\n        HttpURLConnection connection = (HttpURLConnection) new URL(url).openConnection();\n        connection.setRequestMethod(\"GET\");\n        connection.setRequestProperty(\"Range\", \"bytes=\" + startByte + \"-\" + endByte);\n        connection.connect();\n\n        int responseCode = connection.getResponseCode();\n        if (responseCode == 206 || (responseCode == 200 && connection.getContentLength() == (int)(endByte - startByte + 1))) {\n            try (BufferedInputStream bis = new BufferedInputStream(connection.getInputStream());\n                 BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(outputFile))) {\n                byte[] buffer = new byte[MultiThreadedDownloader.BUFFER_SIZE];\n                int bytesRead;\n                while ((bytesRead = bis.read(buffer)) != -1) {\n                    bos.write(buffer, 0, bytesRead);\n                }\n            }\n        } else {\n            throw new IOException(\"Server didn't honor range request for chunk \" + startByte + \"-\" + endByte);\n        }\n    }\n\n    private long calculateDelay(int attempt) {\n        return (long) (Math.pow(2, attempt - 1) * 1000); // Exponential backoff: 1s, 2s, 4s, etc.\n    }\n}\n```\n\n### Explanation\n\n1. **Argument Parsing and Validation:**\n   - Ensure correct number of arguments are provided.\n   - Validate URL and output file path.\n\n2. **File Size and Range Support:**\n   - Use HEAD request to get file size.\n   - Check if server supports range requests.\n\n3. **Chunk Creation and Download:**\n   - Split the file into chunks based on the number of threads.\n   - Use multiple threads to download each chunk concurrently.\n\n4. **Combining and Cleaning:**\n   - Combine downloaded chunks into the final output file.\n   - Delete temporary chunk files.\n\nThis approach ensures efficient and parallel downloading of large files, leveraging multiple threads to speed up the process."
    }
]