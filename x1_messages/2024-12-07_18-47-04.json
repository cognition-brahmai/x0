[
    {
        "role": "user",
        "content": "Implement a simple LRU (Least Recently Used) cache in C++ that supports insertion, deletion, and retrieval of key-value pairs. The cache should have a fixed size and automatically evict the least recently used item when it reaches capacity."
    },
    {
        "role": "assistant",
        "content": "Sure! Implementing an LRU cache in C++ can be efficiently done using a combination of a hash map and a doubly linked list. The hash map provides fast access to the nodes, while the doubly linked list maintains the order of usage.\n\nHere's a step-by-step guide to implementing an LRU cache:\n\n1. **Define the Node Structure**: Each node in the doubly linked list will store the key and value, along with pointers to the next and previous nodes.\n\n2. **Implement the Doubly Linked List**: This will help in maintaining the order of usage. The recently used items will be near the front, and the least recently used will be at the end.\n\n3. **Use a Hash Map**: This will map keys to their corresponding nodes in the doubly linked list for O(1) access time.\n\n4. **Implement Cache Operations**:\n   - `get(key)`: Retrieve the value if the key exists and move the accessed node to the front.\n   - `put(key, value)`: Insert or update the key-value pair and move the node to the front. If the cache is full, remove the least recently used item from the end.\n\nHere's a sample implementation:\n\n```cpp\n#include <iostream>\n#include <unordered_map>\n\nclass LRUCache {\nprivate:\n    struct Node {\n        int key;\n        int value;\n        Node* prev;\n        Node* next;\n        Node(int k, int v) : key(k), value(v), prev(nullptr), next(nullptr) {}\n    };\n\n    std::unordered_map<int, Node*> cache;\n    Node* head; // Dummy head node\n    Node* tail; // Dummy tail node\n    int capacity;\n    int size;\n\n    void moveToHead(Node* node) {\n        removeNode(node);\n        addToHead(node);\n    }\n\n    void addToHead(Node* node) {\n        node->next = head->next;\n        node->prev = head;\n        head->next->prev = node;\n        head->next = node;\n    }\n\n    void removeNode(Node* node) {\n        node->prev->next = node->next;\n        node->next->prev = node->prev;\n    }\n\n    void removeTail() {\n        Node* toRemove = tail->prev;\n        removeNode(toRemove);\n        cache.erase(toRemove->key);\n        delete toRemove;\n        size--;\n    }\n\npublic:\n    LRUCache(int cap) : capacity(cap), size(0) {\n        head = new Node(0, 0);\n        tail = new Node(0, 0);\n        head->next = tail;\n        tail->prev = head;\n    }\n\n    int get(int key) {\n        if (cache.find(key) != cache.end()) {\n            Node* node = cache[key];\n            moveToHead(node);\n            return node->value;\n        }\n        return -1; // Or some indicator that the key doesn't exist\n    }\n\n    void put(int key, int value) {\n        if (cache.find(key) != cache.end()) {\n            Node* node = cache[key];\n            node->value = value;\n            moveToHead(node);\n        } else {\n            if (size >= capacity) {\n                removeTail();\n            }\n            Node* newNode = new Node(key, value);\n            cache[key] = newNode;\n            addToHead(newNode);\n            size++;\n        }\n    }\n\n    ~LRUCache() {\n        for (auto& pair : cache) {\n            delete pair.second;\n        }\n        delete head;\n        delete tail;\n    }\n};\n\nint main() {\n    LRUCache cache(2);\n    cache.put(1, 1);\n    cache.put(2, 2);\n    std::cout << cache.get(1) << std::endl; // returns 1\n    cache.put(3, 3);                         // evicts key 2\n    std::cout << cache.get(2) << std::endl; // returns -1 (not found)\n    cache.put(4, 4);                         // evicts key 1\n    std::cout << cache.get(1) << std::endl; // returns -1 (not found)\n    std::cout << cache.get(3) << std::endl; // returns 3\n    std::cout << cache.get(4) << std::endl; // returns 4\n    return 0;\n}\n```\n\n### Explanation:\n\n1. **Node Structure**: Each node holds the key and value, and pointers to the next and previous nodes.\n\n2. **Doubly Linked List**: Managed with dummy head and tail nodes to simplify additions and removals.\n\n3. **Hash Map**: Maps keys to their corresponding nodes for O(1) access.\n\n4. **get Operation**: Retrieves the value if the key exists and moves the node to the head (most recently used).\n\n5. **put Operation**: Inserts or updates the key-value pair and moves the node to the head. If the cache is full, it removes the least recently used item from the tail.\n\nThis implementation ensures that all operations (`get` and `put`) are performed in O(1) time complexity."
    }
]