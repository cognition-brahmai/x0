[
    {
        "role": "user",
        "content": "Create a Golang microservice that processes images uploaded by users, resizes them to different resolutions, and stores the resized images in an Amazon S3 bucket. The service should also expose an endpoint to retrieve the resized images by their unique identifier.\nPLAINFORMAT"
    },
    {
        "role": "assistant",
        "content": "Alright, I've got this task to create a Golang microservice that handles image uploads, resizes them, and stores them in an Amazon S3 bucket. Also, I need to make sure there's a way to retrieve these resized images using a unique ID. Sounds like a pretty common feature for apps that deal with user-generated content, especially social media or e-commerce platforms.\n\nFirst things first, I need to understand the requirements in detail. So, the microservice should:\n\n1. Accept image uploads from users.\n\n2. Resize these images to different resolutions.\n\n3. Store the resized images in an Amazon S3 bucket.\n\n4. Provide an endpoint to retrieve these images using a unique identifier.\n\nOkay, that's the crux of it. Now, thinking about the tech stack. Since it's specified to be in Golang, that's the programming language I'll be using. Golang is great for microservices because of its efficiency and concurrency model, which will be helpful when handling multiple image processing tasks at once.\n\nFor handling HTTP requests and setting up the endpoints, I'll probably use the standard net/http package, possibly with a router like Gorilla Mux for better URL routing.\n\nNow, image processing: I need to resize images to different resolutions. Go has several image processing libraries, but one of the most popular and efficient is the standard image package, combined with additional libraries like \"github.com/disintegration/imaging\" which provides more functionalities like resizing, cropping, etc.\n\nFor storing the images in Amazon S3, I'll use the official AWS SDK for Go. It's well-documented and widely used, so it should handle all the S3 operations seamlessly.\n\nLet me think about the flow of the service:\n\n1. User uploads an image via an HTTP POST request to a specific endpoint, say `/upload`.\n\n2. The service receives the image, processes it (resizes to different resolutions).\n\n3. It then uploads these resized images to an S3 bucket.\n\n4. Each resized image is given a unique identifier, which is associated with its S3 location.\n\n5. The service responds to the user with the unique identifier for each resolution.\n\n6. There should be another endpoint, maybe `/retrieve/{id}`, where users can input the unique identifier to download the specific resized image.\n\nAlright, that makes sense. Now, let's think about the unique identifier. It should be unique for each resized image. Maybe I can generate a UUID for each upload, and then append the resolution size to it to create unique identifiers for each resized version.\n\nFor example, if a user uploads an image and it's resized to 100x100, 200x200, and 400x400, each of these would have IDs like:\n\n- original_uuid-_100x100\n\n- original_uuid-_200x200\n\n- original_uuid-_400x400\n\nThis way, it's easy to track which resolution corresponds to which original upload.\n\nAlso, I need to consider error handling. What if the image upload fails? What if the resizing process errors out for some reason? What if there are issues with uploading to S3? I need to make sure that the service handles these gracefully and informs the user appropriately.\n\nSecurity is also a concern. I need to make sure that only authorized users can upload and retrieve images. Maybe implement some form of authentication, like API keys or JWT tokens. Also, ensure that the images are scanned for malware or inappropriate content, but that might be out of scope for this microservice.\n\nPerformance is key here, especially since image processing can be computationally intensive. I need to make sure that the service can handle multiple uploads concurrently without bogging down the server. Go's goroutines and channels should help manage concurrency effectively.\n\nLet me also think about the dependencies. I need to list down all the packages I'll be using:\n\n- standard net/http for setting up the server\n\n- github.com/gorilla/mux for routing\n\n- github.com/disintegration/imaging for image processing\n\n- github.com/aws/aws-sdk-go for interacting with S3\n\nI should also consider using a library for generating unique IDs, like github.com/nu7hatch/gouuid or simply use Go's standard UUID functions.\n\nConfiguration management is important too. I need to configure settings like S3 bucket name, AWS credentials, image resolutions to generate, etc. I can use environment variables for this, or maybe a config file.\n\nLogging will be essential for debugging and monitoring. Go has a standard logging package, but I might want to use something more feature-rich like Logrus, which provides more flexibility and severity levels.\n\nLet me sketch a rough outline of the project structure:\n\n- main.go: entry point of the service\n\n- handlers/: package containing all HTTP request handlers\n\n- utils/: utility functions, like image processing, UUID generation, etc.\n\n- config.go: configuration management\n\n- models/: data structures used in the service\n\n- middleware/: any middleware for request handling, like authentication\n\nOkay, that seems reasonable.\n\nNow, let's think about the steps in code:\n\n1. Set up the HTTP server using net/http and Gorilla Mux for routing.\n\n2. Define the upload endpoint (/upload) which accepts POST requests with image files.\n\n3. In the upload handler:\n\na. Read the uploaded image file.\n\nb. Generate a unique identifier for the upload.\n\nc. Resize the image to predefined resolutions.\n\nd. Upload each resized image to S3 with the unique identifier in the object key.\n\ne. Respond to the user with the unique identifiers for each resolution.\n\n4. Define the retrieve endpoint (/retrieve/{id}) which accepts GET requests with the unique identifier as a path parameter.\n\na. Extract the identifier from the URL.\n\nb. Construct the S3 object key using the identifier.\n\nc. Retrieve the image from S3.\n\nd. Serve the image back to the user.\n\n5. Implement error handling at each step, providing meaningful error responses.\n\n6. Optionally, implement authentication middleware to secure the endpoints.\n\nAlright, that's a high-level plan. Now, I need to dive deeper into each component.\n\nStarting with the upload endpoint:\n\n- It should accept image files in common formats like JPEG, PNG, GIF, etc.\n\n- I need to validate that the uploaded file is indeed an image.\n\n- I can use the image.DecodeConfig function from the standard image package to check the image format.\n\n- If it's not a valid image, return an error to the user.\n\n- Once validated, read the image file into memory.\n\n- Generate a unique identifier for this upload. Maybe use Go's uuid.NewUUID() function.\n\n- Define the resolutions to resize to, say [100, 200, 400] pixels for width, maintaining aspect ratio.\n\n- For each resolution, resize the image using the imaging library.\n\n- Upload each resized image to S3 with keys like \"<uuid>_<width>x<height>.<extension>\".\n\n- Respond with JSON containing the unique identifiers for each resolution.\n\nFor the retrieve endpoint:\n\n- It should take a unique identifier as a path parameter.\n\n- Construct the S3 object key using this identifier.\n\n- Retrieve the image from S3.\n\n- If the image exists, serve it with the appropriate Content-Type header.\n\n- If the image doesn't exist, return a 404 error.\n\nI also need to think about how to handle different image formats and ensure that the file extensions are correctly handled.\n\nAdditionally, for S3, I need to set up the bucket, configure permissions, and ensure that the AWS SDK is properly authenticated.\n\nI should also consider setting metadata on the S3 objects, like the image resolution or the original upload ID, to make retrieval and management easier.\n\nLet me think about the data structures I'll need.\n\nIn models/, I can define structs for the API responses.\n\nFor example, the upload response could be:\n\ntype UploadResponse struct {\n\nOriginalUUID string `json:\"original_uuid\"`\n\nResizedImages []ResizedImage `json:\"resized_images\"`\n\n}\n\ntype ResizedImage struct {\n\nResolution string `json:\"resolution\"`\n\nURL string `json:\"url\"`\n\n}\n\nSimilarly, for the retrieve endpoint, I can simply serve the image bytes with the correct Content-Type.\n\nNow, regarding the S3 setup:\n\n- I need to create an S3 bucket in a suitable AWS region.\n\n- Configure the bucket for static website hosting, if needed, or set up appropriate CORS rules if the images are to be accessed directly from the web.\n\n- Set up IAM roles and credentials for the microservice to access S3.\n\n- Ensure that the S3 bucket has versioning enabled, if needed, for backup purposes.\n\n- Consider setting up lifecycle policies to manage old images automatically.\n\nIn the code, I need to initialize the S3 client using the AWS SDK, using credentials either from environment variables or from an IAM role if running on EC2.\n\nI should also configure the S3 client with the correct region and bucket name.\n\nNow, thinking about the image resizing:\n\n- I need to maintain the aspect ratio while resizing.\n\n- So, if I specify the width, the height should adjust accordingly.\n\n- I can use the imaging library's Resize function, specifying the desired width and calculating the height based on the original aspect ratio.\n\n- I should also consider adding some quality settings for the resized images, especially for JPEGs, to balance between file size and image quality.\n\n- Maybe provide options to set the quality level as a configuration parameter.\n\nAlright, moving on to the unique identifiers.\n\nI need to generate a unique ID for each upload. Using UUIDs is a good approach because they are universally unique and unlikely to collide.\n\nFor each resized version, I can append the resolution to the UUID, as I thought earlier.\n\nFor example, if the UUID is \"12345\", then the resized images would be:\n\n- 12345_100x100.jpg\n\n- 12345_200x200.jpg\n\n- 12345_400x400.jpg\n\nThis way, it's easy to identify which resolution corresponds to which original upload.\n\nNow, for the retrieve endpoint, I need to construct the S3 object key from the unique identifier and serve the image.\n\nI should validate that the requested identifier exists in S3 before trying to retrieve it. If it doesn't, return a 404.\n\nAlso, I need to set the correct Content-Type header based on the image format.\n\nI can use the Go AWS SDK's S3 Manager to download the object and serve it directly to the HTTP response writer.\n\nNow, about error handling.\n\nAt each step, I need to check for errors and return appropriate HTTP status codes and error messages.\n\nFor example:\n\n- If the uploaded file is not an image, return a 400 Bad Request with a message like \"Invalid image file\".\n\n- If there's an error resizing the image, return a 500 Internal Server Error with a message like \"Failed to process image\".\n\n- If there's an issue uploading to S3, return a 500 with \"Failed to store image\".\n\n- If the retrieve endpoint is requested with an invalid or non-existent identifier, return a 404 Not Found.\n\nI should also log these errors for debugging purposes.\n\nLogging: I can use Go's standard log package, but as I mentioned earlier, Logrus provides more features. I can consider using Logrus for better logging capabilities.\n\nNow, about concurrency.\n\nSince image processing can be time-consuming, especially for large images or multiple resolutions, I need to handle multiple uploads concurrently without blocking the HTTP server.\n\nGo's goroutines will be perfect for this. I can offload the image processing and uploading to separate goroutines, while the main HTTP handler responds to the user immediately with the unique identifiers.\n\nWait, but if I do that, there's a chance that the user gets the response before the processing is complete. Maybe that's acceptable, and I can return the identifiers immediately, with a message that the images are being processed and will be available soon.\n\nAlternatively, I can make the user wait until the processing is complete, but that might lead to slow response times.\n\nI think the first approach is better: accept the upload, start processing in the background, and respond immediately with the identifiers.\n\nThen, the user can poll the retrieve endpoint to check if the images are ready.\n\nTo handle this, I can use Go's wait groups or channels to manage the goroutines.\n\nNow, let's think about the configuration.\n\nI need to configure:\n\n- S3 bucket name\n\n- AWS region\n\n- AWS access key and secret key (ideally through environment variables or IAM roles)\n\n- Resized image resolutions\n\n- Maybe image quality settings\n\nI can define a config struct in config.go and load the values from environment variables using os.Getenv.\n\nI should also provide default values in case some environment variables are missing.\n\nNow, about the project structure.\n\nHere's a proposed structure:\n\n- main.go\n\n- handlers/\n\n- upload.go\n\n- retrieve.go\n\n- utils/\n\n- image_processing.go\n\n- uuid.go\n\n- s3_utils.go\n\n- config.go\n\n- models/\n\n- upload_response.go\n\n- retrieve_response.go\n\n- middleware/\n\n- auth.go\n\n- go.mod\n\n- go.sum\n\nI can organize the code into these packages and files.\n\nIn main.go, I'll set up the HTTP server and routes.\n\nIn handlers/, I'll have separate files for each endpoint's handler functions.\n\nIn utils/, I'll have utility functions for image processing, UUID generation, S3 operations, etc.\n\nIn models/, I'll define the data structures used in API responses.\n\nIn middleware/, I'll have any middleware functions, like authentication.\n\nNow, let's think about implementing the upload endpoint.\n\nIn handlers/upload.go:\n\n- Define the uploadHandler function, which handles POST requests to /upload.\n\n- Read the uploaded file from the request.\n\n- Validate that it's an image.\n\n- Generate a unique identifier.\n\n- Resize the image to different resolutions.\n\n- Upload each resized image to S3.\n\n- Respond with the unique identifiers and URLs.\n\nWait, should I generate presigned URLs for the S3 objects, or should I serve the images directly from the retrieve endpoint?\n\nGenerating presigned URLs would allow direct access to the S3 objects, which might be faster and offload traffic from my microservice. However, it also means that the images are publicly accessible, which might not be desirable for certain use cases.\n\nAlternatively, serving images through the retrieve endpoint allows me to control access and apply any transformations or optimizations before serving.\n\nGiven that, I think generating presigned URLs for the resized images would be efficient, but I need to consider the security implications.\n\nMaybe I can configure the S3 bucket to be private and generate temporary presigned URLs that expire after a certain time, say 5 minutes.\n\nThis way, the images are not publicly accessible forever, but users can download them within a reasonable time frame.\n\nIn that case, in the uploadHandler, after uploading to S3, I can generate presigned URLs for each resized image and include them in the response.\n\nIn the retrieveHandler, if I decide to implement it, I can serve the images directly, applying any access controls or transformations.\n\nBut for now, generating presigned URLs seems sufficient.\n\nNow, let's think about the code for generating presigned URLs.\n\nUsing the AWS SDK for Go, I can use the GeneratePresignedURL function of the S3 client to create a temporary URL that users can use to download the image.\n\nI need to set the expiration time for these URLs, and possibly other parameters like response headers.\n\nNow, regarding the image processing part.\n\nIn utils/image_processing.go, I'll define functions to resize images to specified resolutions.\n\nI'll need to read the uploaded image, resize it, and then convert it back to bytes for uploading to S3.\n\nUsing the imaging library, I can do something like:\n\nimg, format, err := image.Decode(imageFile)\n\nif err != nil {\n\nreturn err\n\n}\n\nresizedImg := imaging.Resize(img, width, height, imaging.Lanczos)\n\nvar resizedBytes bytes.Buffer\n\nerr = imaging.Encode(&resizedBytes, resizedImg, format)\n\nif err != nil {\n\nreturn err\n\n}\n\nThen, upload resizedBytes to S3.\n\nI need to make sure that the image format is preserved, so I can extract the format from the original image and use the same when encoding the resized image.\n\nAlso, for images with transparency (like PNG), I need to handle the background color appropriately.\n\nNow, about handling different image formats.\n\nI need to ensure that the image processing library supports all common image formats.\n\nThe standard image package in Go supports JPEG, PNG, GIF, etc., and the imaging library should handle these as well.\n\nIf there are any format-specific issues, I need to handle them accordingly.\n\nNow, thinking about the retrieve endpoint.\n\nIf I generate presigned URLs, do I still need a retrieve endpoint?\n\nWell, if I want to have more control over access or want to apply additional transformations, having a retrieve endpoint makes sense.\n\nOtherwise, presigned URLs might suffice.\n\nFor now, I'll implement both: generate presigned URLs for immediate access and have a retrieve endpoint for cases where direct S3 access isn't desired.\n\nIn the retrieveHandler, I'll:\n\n- Extract the unique identifier from the URL.\n\n- Construct the S3 object key using the identifier.\n\n- Retrieve the image from S3.\n\n- Set the appropriate Content-Type header based on the image format.\n\n- Write the image bytes to the HTTP response.\n\nThis way, users can choose to download the image directly from S3 via the presigned URL or through the retrieve endpoint.\n\nNow, about error handling in the retrieve endpoint.\n\n- If the object doesn't exist in S3, return a 404.\n\n- If there's an error retrieving the object, return a 500.\n\n- Also, log the error for debugging.\n\nNow, regarding authentication.\n\nI need to think about how to secure the upload and retrieve endpoints.\n\nMaybe require an API key in the request headers for both endpoints.\n\nI can implement a middleware function that checks for the API key and verifies it against a list of allowed keys.\n\nIn the middleware/auth.go, I can define an authMiddleware function that wraps the handlers and performs the API key check.\n\nThen, in the main router setup, I can apply this middleware to the upload and retrieve endpoints.\n\nFor simplicity, I'll assume that the API keys are stored in environment variables or a config file.\n\nNow, let's think about testing.\n\nI need to write tests for the main functionalities:\n\n- Test the upload endpoint with valid and invalid image files.\n\n- Verify that the resized images are correctly uploaded to S3.\n\n- Test the retrieve endpoint with valid and invalid identifiers.\n\n- Ensure that the correct images are served from S3.\n\nI can write unit tests for the utility functions, like image resizing and S3 operations.\n\nFor the HTTP endpoints, I can write integration tests using tools like TestMain in Go or external testing frameworks like Gore.\n\nI should also consider writing tests that simulate concurrent uploads to ensure that the service handles concurrency correctly.\n\nNow, about deploying the microservice.\n\nI need to consider where to host this service.\n\nOptions include:\n\n- AWS EC2: easy to set up, but manages own instances.\n\n- AWS Lambda with API Gateway: serverless, scalable, pay-per-use.\n\n- Docker container on ECS or EKS.\n\nGiven that image processing can be resource-intensive and unpredictable in terms of load, AWS Lambda might not be the best choice due to potential timeout issues for large images.\n\nTherefore, using EC2 or a container service like ECS or EKS might be more suitable.\n\nI can also consider using Amazon API Gateway with Lambda, but again, Lambda might have limitations for heavy image processing.\n\nAlternatively, I can offload the image processing to a background task using a message queue like SQS, but that complicates the architecture.\n\nFor now, I'll assume that the microservice is running on an EC2 instance or a container in ECS.\n\nI need to make sure that the instance has enough CPU and memory to handle the image processing tasks.\n\nAlso, ensure that the AWS SDK is configured correctly with the necessary permissions to access S3.\n\nNow, let's think about monitoring and logging.\n\nI need to set up logging to capture important events and errors.\n\nUsing Logrus, I can configure different logging levels and output the logs to CloudWatch or a centralized logging system.\n\nI can also implement metrics tracking, perhaps using Go's expvar package or integrating with Prometheus for more advanced monitoring.\n\nThis would allow me to monitor the number of uploads, processing times, error rates, etc.\n\nNow, summarizing the steps:\n\n1. Set up the HTTP server with Gorilla Mux for routing.\n\n2. Implement the upload endpoint:\n\na. Read and validate the uploaded image.\n\nb. Generate a unique identifier.\n\nc. Resize the image to predefined resolutions.\n\nd. Upload each resized image to S3.\n\ne. Generate presigned URLs for each resized image.\n\nf. Respond with the unique identifiers and URLs.\n\n3. Implement the retrieve endpoint:\n\na. Extract the unique identifier from the URL.\n\nb. Retrieve the image from S3.\n\nc. Serve the image with the correct Content-Type.\n\n4. Implement error handling and logging.\n\n5. Optionally, implement authentication middleware using API keys.\n\n6. Configure the S3 bucket and AWS credentials.\n\n7. Test the service with valid and invalid inputs.\n\n8. Deploy the service on an appropriate platform, like EC2 or ECS.\n\n9. Set up monitoring and logging to track the service's health and performance.\n\nThis seems like a comprehensive plan. Now, I can start implementing each component step by step.\n\n## Final Solution\nTo create a Golang microservice that processes images uploaded by users, resizes them to different resolutions, and stores the resized images in an Amazon S3 bucket, while also exposing an endpoint to retrieve the resized images by their unique identifier, follow the steps and code snippets below.\n\n### Project Structure\n\n```\n.\n\u251c\u2500\u2500 main.go\n\u251c\u2500\u2500 handlers\n\u2502   \u251c\u2500\u2500 upload.go\n\u2502   \u2514\u2500\u2500 retrieve.go\n\u251c\u2500\u2500 utils\n\u2502   \u251c\u2500\u2500 image_processing.go\n\u2502   \u251c\u2500\u2500 uuid.go\n\u2502   \u2514\u2500\u2500 s3_utils.go\n\u251c\u2500\u2500 config.go\n\u251c\u2500\u2500 models\n\u2502   \u251c\u2500\u2500 upload_response.go\n\u2502   \u2514\u2500\u2500 retrieve_response.go\n\u251c\u2500\u2500 middleware\n\u2502   \u2514\u2500\u2500 auth.go\n\u251c\u2500\u2500 go.mod\n\u2514\u2500\u2500 go.sum\n```\n\n### Dependencies\n\nEnsure you have the following dependencies in your `go.mod` file:\n\n```go\nmodule your_module_name\n\ngo 1.18\n\nrequire (\n\tgithub.com/aws/aws-sdk-go v1.42.20\n\tgithub.com/disintegration/imaging v1.2.2\n\tgithub.com/gorilla/mux v1.8.0\n\tgithub.com/satori/go.uuid v1.2.0\n)\n```\n\n### Configuration (config.go)\n\nDefine configuration parameters:\n\n```go\npackage main\n\nimport (\n\t\"os\"\n\n\t\"github.com/satori/go.uuid\"\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/aws/session\"\n\t\"github.com/aws/aws-sdk-go/service/s3\"\n\t\"github.com/aws/aws-sdk-go/service/s3/s3manager\"\n)\n\ntype Config struct {\n\tS3Bucket     string\n\tS3Region     string\n\tResolutions  []int\n\tAPIKey       string\n}\n\nvar cfg Config\n\nfunc LoadConfig() {\n\tcfg.S3Bucket = os.Getenv(\"S3_BUCKET\")\n\tif cfg.S3Bucket == \"\" {\n\t\tpanic(\"S3_BUCKET environment variable is not set\")\n\t}\n\n\tcfg.S3Region = os.Getenv(\"S3_REGION\")\n\tif cfg.S3Region == \"\" {\n\t\tpanic(\"S3_REGION environment variable is not set\")\n\t}\n\n\tresStr := os.Getenv(\"RESOLUTIONS\")\n\tif resStr != \"\" {\n\t\tresolutions := strings.Split(resStr, \",\")\n\t\tfor _, res := range resolutions {\n\t\t\tvalue, err := strconv.Atoi(res)\n\t\t\tif err != nil {\n\t\t\t\tpanic(\"Invalid resolution value\")\n\t\t\t}\n\t\t\tcfg.Resolutions = append(cfg.Resolutions, value)\n\t\t}\n\t} else {\n\t\tcfg.Resolutions = []int{100, 200, 400}\n\t}\n\n\tcfg.APIKey = os.Getenv(\"API_KEY\")\n\tif cfg.APIKey == \"\" {\n\t\tpanic(\"API_KEY environment variable is not set\")\n\t}\n}\n```\n\n### Models\n\nDefine response structures in `models/`.\n\n**upload_response.go**\n\n```go\npackage models\n\nimport \"github.com/aws/aws-sdk-go/service/s3/s3manager\"\n\ntype UploadResponse struct {\n\tOriginalUUID string            `json:\"original_uuid\"`\n\tResizedImages []ResizedImage `json:\"resized_images\"`\n}\n\ntype ResizedImage struct {\n\tResolution string `json:\"resolution\"`\n\tURL        string `json:\"url\"`\n}\n```\n\n### Utilities\n\nImplement utility functions in `utils/`.\n\n**uuid.go**\n\n```go\npackage utils\n\nimport \"github.com/satori/go.uuid\"\n\nfunc GenerateUUID() string {\n\treturn uuid.NewV4().String()\n}\n```\n\n**image_processing.go**\n\n```go\npackage utils\n\nimport (\n\t\"image\"\n\t_ \"image/jpeg\"\n\t_ \"image/png\"\n\t\"io/ioutil\"\n\t\"os\"\n\n\t\"github.com/disintegration/imaging\"\n)\n\nfunc ResizeImage(fileBytes []byte, width int) ([]byte, error) {\n\timg, format, err := image.Decode(bytes.NewReader(fileBytes))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tresizedImg := imaging.Resize(img, width, 0, imaging.Lanczos)\n\n\tvar resizedBytes bytes.Buffer\n\terr = imaging.Encode(&resizedBytes, resizedImg, format)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn resizedBytes.Bytes(), nil\n}\n```\n\n**s3_utils.go**\n\n```go\npackage utils\n\nimport (\n\t\"fmt\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/aws/session\"\n\t\"github.com/aws/aws-sdk-go/service/s3\"\n\t\"github.com/aws/aws-sdk-go/service/s3/s3manager\"\n)\n\nvar sess *session.Session\nvar s3Client *s3.S3\nvar s3Uploader *s3manager.Uploader\n\nfunc init() {\n\tsess = session.Must(session.NewSession(&aws.Config{\n\t\tRegion: aws.String(cfg.S3Region)},\n\t))\n\n\ts3Client = s3.New(sess)\n\ts3Uploader = s3manager.NewUploader(sess)\n}\n\nfunc UploadToS3(bucket, key string, fileBytes []byte) error {\n\t_, err := s3Uploader.Upload(&s3manager.UploadInput{\n\t\tBucket: aws.String(bucket),\n\t\tKey:    aws.String(key),\n\t\tBody:   bytes.NewReader(fileBytes),\n\t})\n\treturn err\n}\n\nfunc GeneratePresignedURL(bucket, key string, expires time.Duration) (string, error) {\n\treq, _ := s3Client.GetObjectRequest(&s3.GetObjectInput{\n\t\tBucket: aws.String(bucket),\n\t\tKey:    aws.String(key),\n\t})\n\turl, err := req.Presign(expires)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn url, nil\n}\n```\n\n### Handlers\n\nImplement request handlers in `handlers/`.\n\n**upload.go**\n\n```go\npackage handlers\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"os\"\n\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/service/s3\"\n\t\"github.com/gorilla/mux\"\n\t\"github.com/your_module_name/models\"\n\t\"github.com/your_module_name/utils\"\n)\n\nfunc UploadHandler(w http.ResponseWriter, r *http.Request) {\n\t// Check for API key\n\tapiKey := r.Header.Get(\"X-API-Key\")\n\tif apiKey != cfg.APIKey {\n\t\thttp.Error(w, \"Unauthorized\", http.StatusUnauthorized)\n\t\treturn\n\t}\n\n\t// Check if the request contains a file\n\tfile, handler, err := r.FormFile(\"file\")\n\tif err != nil {\n\t\thttp.Error(w, \"Missing file\", http.StatusBadRequest)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\t// Read the file\n\tfileBytes, err := ioutil.ReadAll(file)\n\tif err != nil {\n\t\thttp.Error(w, \"Failed to read file\", http.StatusInternalServerError)\n\t\treturn\n\t}\n\n\t// Validate if it's an image\n\timg, _, err := image.Decode(bytes.NewReader(fileBytes))\n\tif err != nil {\n\t\thttp.Error(w, \"Invalid image file\", http.StatusBadRequest)\n\t\treturn\n\t}\n\tif img == nil {\n\t\thttp.Error(w, \"Invalid image file\", http.StatusBadRequest)\n\t\treturn\n\t}\n\n\t// Generate unique identifier\n\tuuid := utils.GenerateUUID()\n\n\tvar resizedImages []models.ResizedImage\n\tfor _, width := range cfg.Resolutions {\n\t\tresizedBytes, err := utils.ResizeImage(fileBytes, width)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"Failed to resize image\", http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\t// Construct S3 key\n\t\tresolution := fmt.Sprintf(\"%dx%d\", width, width)\n\t\tkey := fmt.Sprintf(\"%s_%s\", uuid, resolution)\n\n\t\t// Upload to S3\n\t\terr = utils.UploadToS3(cfg.S3Bucket, key, resizedBytes)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"Failed to upload to S3\", http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\t// Generate presigned URL\n\t\turl, err := utils.GeneratePresignedURL(cfg.S3Bucket, key, 15*time.Minute)\n\t\tif err != nil {\n\t\t\thttp.Error(w, \"Failed to generate presigned URL\", http.StatusInternalServerError)\n\t\t\treturn\n\t\t}\n\n\t\tresizedImages = append(resizedImages, models.ResizedImage{\n\t\t\tResolution: resolution,\n\t\t\tURL:        url,\n\t\t})\n\t}\n\n\tresponse := models.UploadResponse{\n\t\tOriginalUUID: uuid,\n\t\tResizedImages: resizedImages,\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\tjson.NewEncoder(w).Encode(response)\n}\n```\n\n**retrieve.go**\n\n```go\npackage handlers\n\nimport (\n\t\"net/http\"\n\t\"github.com/gorilla/mux\"\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/service/s3\"\n\t\"github.com/aws/aws-sdk-go/service/s3/s3manager\"\n\t\"github.com/your_module_name/utils\"\n)\n\nfunc RetrieveHandler(w http.ResponseWriter, r *http.Request) {\n\t// Check for API key\n\tapiKey := r.Header.Get(\"X-API-Key\")\n\tif apiKey != cfg.APIKey {\n\t\thttp.Error(w, \"Unauthorized\", http.StatusUnauthorized)\n\t\treturn\n\t}\n\n\t// Extract identifier from URL\n\tid := mux.Vars(r)[\"id\"]\n\n\t// Construct S3 key\n\tkey := id\n\n\t// Retrieve the image from S3\n\tdownloader := s3manager.NewDownloader(sess)\n\tfileBytes := aws.NewWriteAtBuffer([]byte{})\n\t_, err := downloader.Download(fileBytes, &s3.GetObjectInput{\n\t\tBucket: aws.String(cfg.S3Bucket),\n\t\tKey:    aws.String(key),\n\t})\n\tif err != nil {\n\t\thttp.Error(w, \"Image not found\", http.StatusNotFound)\n\t\treturn\n\t}\n\n\t// Set the content type based on the file extension\n\textension := strings.Split(key, \".\")[1]\n\tcontentType := http.DetectContentType(fileBytes.Bytes())\n\tw.Header().Set(\"Content-Type\", contentType)\n\n\t// Write the file to the response\n\tw.Write(fileBytes.Bytes())\n}\n```\n\n### Middleware\n\nImplement authentication middleware in `middleware/auth.go`.\n\n```go\npackage middleware\n\nimport (\n\t\"net/http\"\n\t\"github.com/gorilla/mux\"\n\t\"github.com/your_module_name/config\"\n)\n\nfunc AuthMiddleware(next http.HandlerFunc) http.HandlerFunc {\n\treturn func(w http.ResponseWriter, r *http.Request) {\n\t\tapiKey := r.Header.Get(\"X-API-Key\")\n\t\tif apiKey != config.Cfg.APIKey {\n\t\t\thttp.Error(w, \"Unauthorized\", http.StatusUnauthorized)\n\t\t\treturn\n\t\t}\n\t\tnext.ServeHTTP(w, r)\n\t}\n}\n```\n\n### Main Server (main.go)\n\nSet up the HTTP server and routes.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"github.com/gorilla/mux\"\n\t\"github.com/your_module_name/config\"\n\t\"github.com/your_module_name/handlers\"\n\t\"github.com/your_module_name/middleware\"\n)\n\nfunc main() {\n\tconfig.LoadConfig()\n\n\tr := mux.NewRouter()\n\n\t// Apply authentication middleware\n\tr.Use(middleware.AuthMiddleware)\n\n\t// Define routes\n\tr.HandleFunc(\"/upload\", handlers.UploadHandler).Methods(\"POST\")\n\tr.HandleFunc(\"/retrieve/{id}\", handlers.RetrieveHandler).Methods(\"GET\")\n\n\tfmt.Println(\"Starting server on :8080\")\n\thttp.ListenAndServe(\":8080\", r)\n}\n```\n\n### Summary\n\n1. **Configuration**: Load environment variables and set up AWS S3 client.\n2. **Utilities**: Handle UUID generation, image resizing, and S3 operations.\n3. **Handlers**: Implement handlers for uploading and retrieving images.\n4. **Middleware**: Ensure requests are authenticated using API keys.\n5. **Main Server**: Set up routes and start the HTTP server.\n\nThis microservice handles image uploads, resizes them to specified resolutions, stores them in S3, and provides a way to retrieve them using unique identifiers. Make sure to handle errors gracefully and consider additional security measures based on your use case."
    }
]