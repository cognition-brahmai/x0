[
    {
        "role": "user",
        "content": "Write a python script that utilizes the requests library to fetch data from a public API, processes the data according to specific criteria (e.g., filtering, sorting, or aggregation), and generates a report in PDF format using the ReportLab library.\nPLAINFORMAT"
    },
    {
        "role": "assistant",
        "content": "Sure! I can help you with that. To create a Python script that fetches data from a public API, processes it, and generates a PDF report, we'll need to follow these steps:\n\n1. **Fetch Data from API**: Use the `requests` library to get data from a public API.\n2. **Process Data**: Filter, sort, or aggregate the data as needed.\n3. **Generate PDF Report**: Use the `ReportLab` library to create a PDF file based on the processed data.\n\nFirst, make sure you have the necessary libraries installed. You can install them using pip if you haven't already:\n\n```bash\npip install requests reportlab\n```\n\nFor this example, let's use the JSONPlaceholder API, which provides fake REST APIs for testing and prototyping. We'll fetch a list of posts and generate a PDF report containing the titles and bodies of these posts.\n\nHere's a step-by-step guide with code snippets:\n\n### Step 1: Fetch Data from API\n\nWe'll use the `requests` library to get data from the API.\n\n```python\nimport requests\n\ndef fetch_data(url):\n    response = requests.get(url)\n    if response.status_code == 200:\n        return response.json()\n    else:\n        raise Exception(f\"Failed to fetch data: {response.status_code}\")\n\n# URL of the public API\napi_url = 'https://jsonplaceholder.typicode.com/posts'\ndata = fetch_data(api_url)\nprint(\"Data fetched successfully.\")\n```\n\n### Step 2: Process Data\n\nLet's say we want to filter posts by a specific user ID and sort them by post ID.\n\n```python\ndef process_data(data, user_id):\n    # Filter posts by user ID\n    filtered_data = [post for post in data if post['userId'] == user_id]\n    \n    # Sort posts by post ID\n    sorted_data = sorted(filtered_data, key=lambda x: x['id'])\n    \n    return sorted_data\n\n# Specify the user ID to filter by\nuser_id = 1\nprocessed_data = process_data(data, user_id)\nprint(\"Data processed successfully.\")\n```\n\n### Step 3: Generate PDF Report\n\nWe'll use the `ReportLab` library to create a PDF report containing the titles and bodies of the posts.\n\n```python\nfrom reportlab.lib.pagesizes import letter\nfrom reportlab.pdfgen import canvas\n\ndef generate_pdf(data, filename):\n    c = canvas.Canvas(filename, pagesize=letter)\n    width, height = letter\n    margin = 50\n    line_height = 15\n    current_y = height - margin\n    \n    for post in data:\n        title = post['title']\n        body = post['body']\n        \n        # Write title\n        c.setFont(\"Helvetica-Bold\", 12)\n        c.drawString(margin, current_y, title)\n        current_y -= line_height * 2  # Leave some space after title\n        \n        # Write body\n        c.setFont(\"Helvetica\", 10)\n        lines = wrap_text(body, width - 2 * margin, c)\n        for line in lines:\n            c.drawString(margin, current_y, line)\n            current_y -= line_height\n            if current_y < margin:\n                c.showPage()\n                current_y = height - margin\n        current_y -= line_height * 2  # Space after body\n        \n    c.save()\n    print(f\"PDF report generated: {filename}\")\n\ndef wrap_text(text, width, canvas, font=\"Helvetica\", size=10):\n    canvas.setFont(font, size)\n    text_object = canvas.beginText()\n    text_object.setTextOrigin(0, 0)\n    text_object.setFont(font, size)\n    for line in text.split('\\n'):\n        text_object.textLine(line)\n    text_lines = text_object.textLines\n    wrapped_lines = []\n    for line in text_lines:\n        words = line.split()\n        current_line = ''\n        for word in words:\n            test_line = current_line + word + ' '\n            if canvas.stringWidth(test_line, font, size) <= width:\n                current_line = test_line\n            else:\n                wrapped_lines.append(current_line)\n                current_line = word + ' '\n        wrapped_lines.append(current_line)\n    return wrapped_lines\n\n# Generate PDF report\npdf_filename = 'posts_report.pdf'\ngenerate_pdf(processed_data, pdf_filename)\n```\n\n### Explanation\n\n1. **Fetching Data**: We use the `requests.get` method to fetch data from the specified API URL. If the request is successful (status code 200), we return the JSON data.\n2. **Processing Data**: We filter the posts by a specific `user_id` and sort them by their `id`.\n3. **Generating PDF**: We create a PDF using `reportlab`. We set up the canvas, define margins and font sizes, and iterate through the processed data to add titles and bodies to the PDF. The `wrap_text` function helps in wrapping text to fit within the specified width.\n\nThis script will generate a PDF report named `posts_report.pdf` containing the titles and bodies of posts from the specified user ID, fetched from the JSONPlaceholder API."
    }
]