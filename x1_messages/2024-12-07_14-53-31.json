[
    {
        "role": "user",
        "content": "Implement a simple LRU (Least Recently Used) cache in Python with the following features:\n   - Set a maximum capacity for the cache.\n   - Add and retrieve items from the cache.\n   - Automatically remove the least recently used item when the cache reaches its capacity.\nPLAINFORMAT"
    },
    {
        "role": "assistant",
        "content": "Sure, I can help you with that! Implementing an LRU cache in Python is a great way to manage a fixed-size cache efficiently. The LRU cache is a common caching strategy where the least recently used items are discarded first when the cache reaches its capacity.\n\nIn Python, you can implement an LRU cache using a combination of a dictionary and a doubly linked list. The dictionary will provide O(1) access time for lookups, and the doubly linked list will help in maintaining the order of usage, allowing you to efficiently move recently used items to the front and remove the least recently used items from the end.\n\nHere's a step-by-step guide to implementing a simple LRU cache:\n\n1. **Define the Node Class**: This class will represent each element in the doubly linked list. Each node will have pointers to the previous and next nodes, as well as keys and values.\n\n2. **Initialize the Cache**: Set up the cache with a maximum capacity. Create a dictionary to store the keys and their corresponding nodes. Also, set up a doubly linked list to keep track of the order of usage.\n\n3. **Add Items to the Cache**: When adding a new item, check if the key already exists in the cache. If it does, update its value and move it to the front of the list (since it's now the most recently used). If the key doesn't exist, create a new node and add it to the front of the list. If the cache is at capacity, remove the least recently used item from the end of the list and delete it from the dictionary.\n\n4. **Retrieve Items from the Cache**: When retrieving an item, check if the key exists in the dictionary. If it does, return its value and move the corresponding node to the front of the list (since it's now the most recently used). If the key doesn't exist, return None or an appropriate value indicating that the key is not found.\n\nHere's a sample implementation of the LRU cache:\n\n```python\nclass Node:\n    def __init__(self, key, value):\n        self.key = key\n        self.value = value\n        self.prev = None\n        self.next = None\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = {}\n        self.head = Node(0, 0)\n        self.tail = Node(0, 0)\n        self.head.next = self.tail\n        self.tail.prev = self.head\n\n    def _remove(self, node):\n        prev_node = node.prev\n        next_node = node.next\n        prev_node.next = next_node\n        next_node.prev = prev_node\n\n    def _add(self, node):\n        prev_node = self.tail.prev\n        prev_node.next = node\n        node.prev = prev_node\n        node.next = self.tail\n        self.tail.prev = node\n\n    def get(self, key: int) -> int:\n        if key in self.cache:\n            node = self.cache[key]\n            self._remove(node)\n            self._add(node)\n            return node.value\n        return -1\n\n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            self._remove(self.cache[key])\n        node = Node(key, value)\n        self.cache[key] = node\n        self._add(node)\n        if len(self.cache) > self.capacity:\n            lru_node = self.head.next\n            self._remove(lru_node)\n            del self.cache[lru_node.key]\n```\n\n**Explanation**:\n\n- **Node Class**: Represents each element in the doubly linked list with keys, values, and pointers to previous and next nodes.\n\n- **LRUCache Class**:\n  - **Initialization**: Sets up the cache with a maximum capacity, an empty dictionary for storage, and a doubly linked list to maintain order.\n  - **_remove Method**: Helper method to remove a node from the linked list.\n  - **_add Method**: Helper method to add a node to the front of the linked list.\n  - **get Method**: Retrieves a value by key, moves the corresponding node to the front, and returns the value. If the key doesn't exist, returns -1.\n  - **put Method**: Adds or updates a key-value pair. If the key exists, it's updated and moved to the front. If the cache is full, the least recently used item is removed.\n\nThis implementation ensures that both get and put operations have O(1) time complexity, making it efficient for caching purposes.\n\n**Usage Example**:\n\n```python\ncache = LRUCache(2)\ncache.put(1, 1)\ncache.put(2, 2)\nprint(cache.get(1))       # returns 1\ncache.put(3, 3)           # evicts key 2\nprint(cache.get(2))       # returns -1 (not found)\ncache.put(4, 4)           # evicts key 1\nprint(cache.get(1))       # returns -1 (not found)\nprint(cache.get(3))       # returns 3\nprint(cache.get(4))       # returns 4\n```\n\nThis example demonstrates how the LRU cache manages its capacity by evicting the least recently used items when necessary.\n\nI hope this helps! Let me know if you have any questions or need further clarification."
    }
]