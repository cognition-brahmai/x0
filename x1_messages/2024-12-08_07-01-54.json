[
    {
        "role": "user",
        "content": "Create a Python web scraper that extracts job listings from a popular job board website, filters them based on user-defined criteria (e.g., location, keywords), and sends email notifications about matching jobs using an SMTP server.\nPLAINFORMAT"
    },
    {
        "role": "assistant",
        "content": "I can help you with that! Creating a web scraper to extract job listings and set up email notifications involves several steps. We'll use Python along with some libraries like `requests`, `BeautifulSoup` for web scraping, and `smtplib` for sending emails.\n\nFirst, make sure you have the necessary libraries installed. You can install them using pip if you haven't already:\n\n```bash\npip install requests beautifulsoup4\n```\n\n### Step 1: Web Scraping\n\nWe'll start by scraping job listings from a job board website. For this example, let's assume we're using a website like \"examplejobs.com\". You'll need to inspect the website's structure to identify how job listings are presented.\n\nHere's a basic example of how to scrape job titles and links:\n\n```python\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef scrape_jobs(url):\n    response = requests.get(url)\n    if response.status_code != 200:\n        print(\"Failed to retrieve the webpage.\")\n        return []\n    \n    soup = BeautifulSoup(response.text, 'html.parser')\n    jobs = []\n    \n    # Adjust the selectors based on the actual website structure\n    job_listings = soup.find_all('div', class_='job-listing')\n    for listing in job_listings:\n        title = listing.find('h2').text.strip()\n        link = listing.find('a')['href']\n        jobs.append({'title': title, 'link': link})\n    \n    return jobs\n\n# Example usage\nurl = 'https://examplejobs.com'\njobs = scrape_jobs(url)\nfor job in jobs:\n    print(job['title'], job['link'])\n```\n\n### Step 2: Filtering Jobs\n\nNext, we'll filter these jobs based on user-defined criteria such as location and keywords.\n\n```python\ndef filter_jobs(jobs, location=None, keywords=None):\n    filtered_jobs = jobs\n    if location:\n        # Assume location is mentioned in the job title or description\n        filtered_jobs = [job for job in filtered_jobs if location.lower() in job['title'].lower() or location.lower() in job.get('description', '').lower()]\n    if keywords:\n        keyword_list = keywords.lower().split()\n        filtered_jobs = [job for job in filtered_jobs if all(keyword in job['title'].lower() or keyword in job.get('description', '').lower() for keyword in keyword_list)]\n    return filtered_jobs\n\n# Example usage\nlocation = 'New York'\nkeywords = 'python developer'\nfiltered_jobs = filter_jobs(jobs, location, keywords)\nfor job in filtered_jobs:\n    print(job['title'], job['link'])\n```\n\n### Step 3: Sending Email Notifications\n\nFinally, we'll set up email notifications using an SMTP server. You'll need to provide your email credentials and the recipient's email address.\n\n```python\nimport smtplib\nfrom email.mime.text import MIMEText\nfrom email.mime.multipart import MIMEMultipart\n\ndef send_email(smtp_server, smtp_port, smtp_user, smtp_password, to_email, jobs):\n    msg = MIMEMultipart()\n    msg['From'] = smtp_user\n    msg['To'] = to_email\n    msg['Subject'] = 'New Job Listings'\n    \n    body = 'Here are the new job listings that match your criteria:\\n\\n'\n    for job in jobs:\n        body += f\"{job['title']}\\n{job['link']}\\n\\n\"\n    \n    msg.attach(MIMEText(body, 'plain'))\n    \n    server = smtplib.SMTP(smtp_server, smtp_port)\n    server.starttls()\n    server.login(smtp_user, smtp_password)\n    text = msg.as_string()\n    server.sendmail(smtp_user, to_email, text)\n    server.quit()\n\n# Example usage\nsmtp_server = 'smtp.example.com'\nsmtp_port = 587\nsmtp_user = 'your_email@example.com'\nsmtp_password = 'your_password'\nto_email = 'recipient@example.com'\nsend_email(smtp_server, smtp_port, smtp_user, smtp_password, to_email, filtered_jobs)\n```\n\n### Putting It All Together\n\nCombine all the steps into a single script and consider adding error handling and logging for robustness.\n\n```python\nimport requests\nfrom bs4 import BeautifulSoup\nimport smtplib\nfrom email.mime.text import MIMEText\nfrom email.mime.multipart import MIMEMultipart\n\ndef scrape_jobs(url):\n    response = requests.get(url)\n    if response.status_code != 200:\n        print(\"Failed to retrieve the webpage.\")\n        return []\n    \n    soup = BeautifulSoup(response.text, 'html.parser')\n    jobs = []\n    \n    # Adjust the selectors based on the actual website structure\n    job_listings = soup.find_all('div', class_='job-listing')\n    for listing in job_listings:\n        title = listing.find('h2').text.strip()\n        link = listing.find('a')['href']\n        jobs.append({'title': title, 'link': link})\n    \n    return jobs\n\ndef filter_jobs(jobs, location=None, keywords=None):\n    filtered_jobs = jobs\n    if location:\n        filtered_jobs = [job for job in filtered_jobs if location.lower() in job['title'].lower() or location.lower() in job.get('description', '').lower()]\n    if keywords:\n        keyword_list = keywords.lower().split()\n        filtered_jobs = [job for job in filtered_jobs if all(keyword in job['title'].lower() or keyword in job.get('description', '').lower() for keyword in keyword_list)]\n    return filtered_jobs\n\ndef send_email(smtp_server, smtp_port, smtp_user, smtp_password, to_email, jobs):\n    msg = MIMEMultipart()\n    msg['From'] = smtp_user\n    msg['To'] = to_email\n    msg['Subject'] = 'New Job Listings'\n    \n    body = 'Here are the new job listings that match your criteria:\\n\\n'\n    for job in jobs:\n        body += f\"{job['title']}\\n{job['link']}\\n\\n\"\n    \n    msg.attach(MIMEText(body, 'plain'))\n    \n    server = smtplib.SMTP(smtp_server, smtp_port)\n    server.starttls()\n    server.login(smtp_user, smtp_password)\n    text = msg.as_string()\n    server.sendmail(smtp_user, to_email, text)\n    server.quit()\n\nif __name__ == \"__main__\":\n    url = 'https://examplejobs.com'\n    jobs = scrape_jobs(url)\n    \n    location = 'New York'\n    keywords = 'python developer'\n    filtered_jobs = filter_jobs(jobs, location, keywords)\n    \n    if filtered_jobs:\n        smtp_server = 'smtp.example.com'\n        smtp_port = 587\n        smtp_user = 'your_email@example.com'\n        smtp_password = 'your_password'\n        to_email = 'recipient@example.com'\n        send_email(smtp_server, smtp_port, smtp_user, smtp_password, to_email, filtered_jobs)\n    else:\n        print(\"No matching jobs found.\")\n```\n\n### Notes\n\n1. **Website Structure**: The selectors used in `BeautifulSoup` (`'div', class_='job-listing'`, etc.) need to be adjusted based on the actual structure of the job board website you're scraping.\n  \n2. **Email Credentials**: Be cautious with your email credentials. Consider using environment variables or a configuration file to store sensitive information.\n  \n3. **Legal and Ethical Considerations**: Ensure that web scraping complies with the target website's `robots.txt` rules and terms of service. Some websites do not allow scraping, and doing so may be illegal or unethical.\n  \n4. **Error Handling**: Add appropriate error handling to manage exceptions, such as failed web requests or email sending issues.\n\nThis script provides a basic framework. You can expand it by adding more filtering options, handling job descriptions, or scheduling the script to run at regular intervals using a task scheduler like cron on Linux or Task Scheduler on Windows."
    }
]