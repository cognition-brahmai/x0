[
    {
        "role": "user",
        "content": "Develop a web scraper in JavaScript or TypeScript using Node.js that extracts information about the top 100 movies from IMDb's website, stores the data in a MongoDB database, and provides an API to query the stored data."
    },
    {
        "role": "assistant",
        "content": "I'm going to tackle this project step by step. So, the goal is to create a web scraper that grabs the top 100 movies from IMDb, saves that data into a MongoDB database, and then sets up an API so we can query that data. I'll be using JavaScript or TypeScript with Node.js for this task.\n\nFirst things first, I need to set up my development environment. Since I'm comfortable with Node.js, I'll go with that. I think I'll use TypeScript because it adds static types to JavaScript, which can make the code easier to maintain, especially for a slightly larger project like this.\n\nSo, I'll start by creating a new directory for my project and initializing it with npm.\n\n```\nmkdir imdb-scraper\ncd imdb-scraper\nnpm init -y\n```\n\nNext, I need to install the necessary dependencies. For scraping the website, I'll use Puppeteer, which is a headless Chrome browser controlled programmatically. It's great for scraping because it can handle JavaScript-rendered pages seamlessly.\n\nFor MongoDB, I'll use the official MongoDB Node.js driver to connect and interact with the database.\n\nAlso, I'll need Express to set up the API.\n\nSo, let's install these:\n\n```\nnpm install puppeteer mongodb express\n```\n\nSince I'm using TypeScript, I need to install the type definitions for these packages:\n\n```\nnpm install @types/puppeteer @types/mongodb @types/express typescript ts-node --save-dev\n```\n\nNow, I need to set up TypeScript. I'll create a `tsconfig.json` file:\n\n```\nnpx tsc --init\n```\n\nI'll make sure to set the \"target\" to \"es6\" and \"module\" to \"commonjs\" in `tsconfig.json` to ensure compatibility with Node.js.\n\nNext, I'll create the basic structure of my project. I'll have the following folders:\n\n- `scraper`: Contains the web scraping logic.\n\n- `db`: Handles database operations.\n\n- `api`: Sets up the Express API.\n\n- `models`: Defines the data models.\n\nLet's create these folders and add some initial files.\n\nIn the `scraper` folder, I'll have a `scrape.ts` file.\n\nIn the `db` folder, I'll have a `db.ts` file to handle database connections and operations.\n\nIn the `api` folder, I'll have an `index.ts` file to set up the Express server.\n\nIn the `models` folder, I'll define an interface for the movie data.\n\nLet's start by defining the movie model in `models/Movie.ts`:\n\n```typescript\nexport interface Movie {\n  title: string;\n  year: number;\n  rating: number;\n  // Add more fields as needed\n}\n```\n\nNow, let's set up the database connection in `db/db.ts`:\n\n```typescript\nimport { MongoClient } from 'mongodb';\n\nconst url = 'mongodb://localhost:27017';\nconst client = new MongoClient(url);\n\nexport async function connectToDatabase() {\n  await client.connect();\n  console.log('Connected to database');\n  return client.db('imdb');\n}\n```\n\nMake sure MongoDB is running locally on the default port (27017). If not, adjust the URL accordingly.\n\nNext, I'll work on the scraper in `scraper/scrape.ts`. The plan is to use Puppeteer to navigate to IMDb's top 100 movies page, extract the movie titles, years, ratings, etc., and then store that data in MongoDB.\n\nFirst, I need to know the URL of IMDb's top 100 movies page. I believe it's something like `https://www.imdb.com/chart/top`.\n\nI'll need to inspect the page to see how the movie data is structured in HTML so I can target the right elements with Puppeteer.\n\nFor now, I'll assume that each movie entry has a title, year, and rating, and they are listed in a specific HTML structure.\n\nHere's a rough outline of what the scraper might look like:\n\n```typescript\nimport puppeteer from 'puppeteer';\nimport { Movie } from '../models/Movie';\nimport { connectToDatabase } from '../db/db';\n\nexport async function scrapeTop100Movies() {\n  const browser = await puppeteer.launch();\n  const page = await browser.newPage();\n  await page.goto('https://www.imdb.com/chart/top');\n\n  // Extract movie data\n  const movies: Movie[] = await page.evaluate(() => {\n    const movieElements = document.querySelectorAll('.chart-full-name');\n    return Array.from(movieElements).map(element => {\n      const title = element.querySelector('.titleColumn a')!.textContent!.trim();\n      const year = parseInt(element.querySelector('.secondaryInfo')!.textContent!.replace(/[^0-9]/g, ''));\n      const rating = parseFloat(element.querySelector('.imdbRating')!.textContent!.trim());\n      return { title, year, rating };\n    });\n  });\n\n  // Save to database\n  const db = await connectToDatabase();\n  const moviesCollection = db.collection('movies');\n  await moviesCollection.insertMany(movies);\n\n  await browser.close();\n}\n```\n\nThis is a simplified version. I need to verify the actual HTML structure of the IMDb top 100 page to ensure I'm selecting the correct elements.\n\nI should also handle cases where some elements might not be present or where the HTML structure might change.\n\nAdditionally, I need to make sure that the scraper runs only once to fetch the top 100 movies and stores them in the database. Maybe I can add a check to see if the movies are already in the database before scraping again.\n\nNow, moving on to the API part. In the `api` folder, I'll set up an Express server that allows querying the movie data from the database.\n\nIn `api/index.ts`:\n\n```typescript\nimport express from 'express';\nimport { connectToDatabase } from '../db/db';\n\nconst app = express();\nconst port = 3000;\n\napp.get('/movies', async (req, res) => {\n  const db = await connectToDatabase();\n  const moviesCollection = db.collection('movies');\n  const movies = await moviesCollection.find().toArray();\n  res.json(movies);\n});\n\napp.listen(port, () => {\n  console.log(`API listening at http://localhost:${port}`);\n});\n```\n\nThis is a very basic API that returns all movies in the database. I can expand it to include filtering, sorting, and pagination as needed.\n\nNow, to run the scraper and the API, I need to set up some scripts in `package.json`:\n\n```json\n\"scripts\": {\n  \"scrape\": \"ts-node scraper/scrape.ts\",\n  \"start\": \"ts-node api/index.ts\"\n}\n```\n\nSo, I can run `npm run scrape` to fetch the movies and `npm start` to start the API server.\n\nBefore running the scraper, I need to make sure that MongoDB is running and that the database and collection are set up correctly.\n\nAlso, I should handle any errors that might occur during scraping or database operations to make the application more robust.\n\nMoreover, I need to respect IMDb's terms of service and robots.txt file regarding web scraping. It's important to scrape responsibly and not overload their servers.\n\nI should also consider adding some delays or handling CAPTCHAs if IMDb decides to block the scraper.\n\nAdditionally, I can add more fields to the movie data, such as genre, director, actors, etc., by inspecting the page and adjusting the scraper accordingly.\n\nOnce the scraper is running and the data is stored in MongoDB, I can test the API by making a GET request to `http://localhost:3000/movies` and verifying that it returns the list of movies.\n\nI might also want to add validation to ensure that the data being saved to the database matches the expected format.\n\nOverall, this seems like a feasible plan. I just need to flesh out the details, especially the scraping part, by inspecting the actual IMDb page and adjusting the selectors accordingly.\n\n## Final Solution\nTo create a web scraper in TypeScript using Node.js that extracts information about the top 100 movies from IMDb's website, stores the data in a MongoDB database, and provides an API to query the stored data, follow these steps:\n\n### Prerequisites\n1. **Node.js** installed.\n2. **MongoDB** running locally or accessible via a URI.\n3. Basic knowledge of TypeScript, Node.js, Express, and MongoDB.\n\n### Project Structure\n```\nimdb-scraper/\n\u251c\u2500\u2500 api/\n\u2502   \u2514\u2500\u2500 index.ts\n\u251c\u2500\u2500 db/\n\u2502   \u2514\u2500\u2500 db.ts\n\u251c\u2500\u2500 models/\n\u2502   \u2514\u2500\u2500 Movie.ts\n\u251c\u2500\u2500 scraper/\n\u2502   \u2514\u2500\u2500 scrape.ts\n\u251c\u2500\u2500 tsconfig.json\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 tsconfig.json\n\u2514\u2500\u2500 README.md\n```\n\n### Setup\n\n1. **Initialize the project:**\n    ```bash\n    mkdir imdb-scraper\n    cd imdb-scraper\n    npm init -y\n    ```\n\n2. **Install dependencies:**\n    ```bash\n    npm install puppeteer mongodb express\n    npm install @types/puppeteer @types/mongodb @types/express typescript ts-node --save-dev\n    ```\n\n3. **Set up TypeScript:**\n    ```bash\n    npx tsc --init\n    ```\n    - Update `tsconfig.json`:\n      ```json\n      {\n        \"compilerOptions\": {\n          \"target\": \"es6\",\n          \"module\": \"commonjs\",\n          \"outDir\": \"./dist\",\n          \"strict\": true,\n          \"esModuleInterop\": true\n        },\n        \"include\": [\"src\"]\n      }\n      ```\n\n4. **Create project directories and files:**\n    ```bash\n    mkdir api db models scraper\n    ```\n\n### Implementing the Solution\n\n#### 1. Define the Movie Model\n- `models/Movie.ts`:\n    ```typescript\n    export interface Movie {\n      title: string;\n      year: number;\n      rating: number;\n      // Add more fields as needed\n    }\n    ```\n\n#### 2. Set up Database Connection\n- `db/db.ts`:\n    ```typescript\n    import { MongoClient } from 'mongodb';\n\n    const url = 'mongodb://localhost:27017';\n    const client = new MongoClient(url);\n\n    export async function connectToDatabase() {\n      await client.connect();\n      console.log('Connected to database');\n      return client.db('imdb');\n    }\n    ```\n\n#### 3. Implement the Web Scraper\n- `scraper/scrape.ts`:\n    ```typescript\n    import puppeteer from 'puppeteer';\n    import { Movie } from '../models/Movie';\n    import { connectToDatabase } from '../db/db';\n\n    export async function scrapeTop100Movies() {\n      const browser = await puppeteer.launch();\n      const page = await browser.newPage();\n      await page.goto('https://www.imdb.com/chart/top');\n\n      // Extract movie data\n      const movies: Movie[] = await page.evaluate(() => {\n        const movieElements = document.querySelectorAll('.chart-full-name');\n        return Array.from(movieElements).map(element => {\n          const title = element.querySelector('.titleColumn a')!.textContent!.trim();\n          const year = parseInt(element.querySelector('.secondaryInfo')!.textContent!.replace(/[^0-9]/g, ''));\n          const rating = parseFloat(element.querySelector('.imdbRating')!.textContent!.trim());\n          return { title, year, rating };\n        });\n      });\n\n      // Save to database\n      const db = await connectToDatabase();\n      const moviesCollection = db.collection('movies');\n      await moviesCollection.deleteMany({}); // Clear existing data\n      await moviesCollection.insertMany(movies);\n\n      await browser.close();\n    }\n    ```\n\n#### 4. Set up the API\n- `api/index.ts`:\n    ```typescript\n    import express from 'express';\n    import { connectToDatabase } from '../db/db';\n\n    const app = express();\n    const port = 3000;\n\n    app.get('/movies', async (req, res) => {\n      const db = await connectToDatabase();\n      const moviesCollection = db.collection('movies');\n      const movies = await moviesCollection.find().toArray();\n      res.json(movies);\n    });\n\n    app.listen(port, () => {\n      console.log(`API listening at http://localhost:${port}`);\n    });\n    ```\n\n#### 5. Add Scripts to `package.json`\n    ```json\n    \"scripts\": {\n      \"scrape\": \"ts-node scraper/scrape.ts\",\n      \"start\": \"ts-node api/index.ts\"\n    }\n    ```\n\n### Running the Application\n\n1. **Scrape the data:**\n    ```bash\n    npm run scrape\n    ```\n\n2. **Start the API server:**\n    ```bash\n    npm start\n    ```\n\n3. **Query the API:**\n    - Visit `http://localhost:3000/movies` in your browser or use a tool like Postman.\n\n### Notes\n\n- **Respect IMDb's terms of service and robots.txt.** Ensure that web scraping is permitted and done responsibly.\n- **Error handling:** Add try-catch blocks in the scraper and API to handle potential errors.\n- **Expand functionality:** Consider adding more fields from IMDb pages and enhancing the API with filtering and sorting options."
    }
]