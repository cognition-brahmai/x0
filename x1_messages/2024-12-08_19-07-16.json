[
    {
        "role": "user",
        "content": "Create a Python script that uses PyTorch to create a simple neural network with one hidden layer and train it on the XOR problem."
    },
    {
        "role": "assistant",
        "content": "Sure! I can help you with that. Let's create a simple neural network using PyTorch to solve the XOR problem. The XOR problem is a classic example that cannot be solved by a linear classifier, so it's a great way to see how neural networks can handle non-linearly separable data.\n\nFirst, make sure you have PyTorch installed. If not, you can install it using pip:\n\n```bash\npip install torch\n```\n\nNow, let's write the Python script step by step.\n\n## Step 1: Import necessary libraries\n\nWe need to import PyTorch and some utility functions.\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n```\n\n## Step 2: Define the neural network architecture\n\nWe'll create a simple neural network with one input layer, one hidden layer, and one output layer. For the XOR problem, the input and output dimensions are both 2.\n\n```python\nclass XORNet(nn.Module):\n    def __init__(self):\n        super(XORNet, self).__init__()\n        self.hidden = nn.Linear(2, 2)  # 2 inputs to 2 hidden nodes\n        self.output = nn.Linear(2, 1)  # 2 hidden nodes to 1 output\n        self.sigmoid = nn.Sigmoid()    # Activation function\n\n    def forward(self, x):\n        x = self.hidden(x)\n        x = self.sigmoid(x)\n        x = self.output(x)\n        x = self.sigmoid(x)\n        return x\n```\n\n## Step 3: Prepare the XOR dataset\n\nThe XOR dataset consists of four input-output pairs.\n\n```python\nX = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\nY = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n```\n\n## Step 4: Initialize the network, loss function, and optimizer\n\nWe'll use binary cross-entropy loss since this is a binary classification problem, and stochastic gradient descent as the optimizer.\n\n```python\nmodel = XORNet()\ncriterion = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.5)\n```\n\n## Step 5: Train the network\n\nWe'll train the network for a number of epochs, forward pass the inputs, compute the loss, backpropagate, and update the weights.\n\n```python\nnum_epochs = 10000\n\nfor epoch in range(num_epochs):\n    # Forward pass\n    outputs = model(X)\n    loss = criterion(outputs, Y)\n    \n    # Backward pass and optimization\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    # Print loss every 1000 epochs\n    if (epoch+1) % 1000 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n```\n\n## Step 6: Test the network\n\nAfter training, let's see how well the network performs on the XOR dataset.\n\n```python\nwith torch.no_grad():\n    test_outputs = model(X)\n    predicted = (test_outputs > 0.5).float()\n    accuracy = (predicted == Y).float().mean()\n    print(f'Accuracy: {accuracy.item()*100:.2f}%')\n```\n\n## Complete Script\n\nHere's the complete Python script:\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Define the neural network\nclass XORNet(nn.Module):\n    def __init__(self):\n        super(XORNet, self).__init__()\n        self.hidden = nn.Linear(2, 2)\n        self.output = nn.Linear(2, 1)\n        self.sigmoid = nn.Sigmoid()\n    \n    def forward(self, x):\n        x = self.hidden(x)\n        x = self.sigmoid(x)\n        x = self.output(x)\n        x = self.sigmoid(x)\n        return x\n\n# Prepare the XOR dataset\nX = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\nY = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n\n# Initialize the network, loss, and optimizer\nmodel = XORNet()\ncriterion = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.5)\n\n# Train the network\nnum_epochs = 10000\nfor epoch in range(num_epochs):\n    outputs = model(X)\n    loss = criterion(outputs, Y)\n    \n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    if (epoch+1) % 1000 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n# Test the network\nwith torch.no_grad():\n    test_outputs = model(X)\n    predicted = (test_outputs > 0.5).float()\n    accuracy = (predicted == Y).float().mean()\n    print(f'Accuracy: {accuracy.item()*100:.2f}%')\n```\n\nThis script defines a simple neural network with one hidden layer and trains it on the XOR problem using PyTorch. After training for 10,000 epochs, it prints the accuracy of the model on the training data."
    }
]