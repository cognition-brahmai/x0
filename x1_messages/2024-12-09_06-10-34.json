[
    {
        "role": "user",
        "content": "Write a Python script that accepts a string of text and counts the frequency of each word in the text. Ignore case sensitivity and punctuation marks.\nPLAINFORMAT"
    },
    {
        "role": "assistant",
        "content": "Alright, I've got this task to write a Python script that counts how often each word appears in a piece of text. I need to make sure that it doesn't matter if the words are in different cases, like \"Hello\" and \"hello\" should be counted as the same word. Also, I have to ignore punctuation marks.\n\nFirst, I need to think about how to handle the input text. Since the script should accept any string of text, I'll probably want to use the `input()` function to get the text from the user. But for testing purposes, it might be helpful to hardcode a string in the script as well.\n\nNext, I need to process the text to normalize it. Since the task says to ignore case sensitivity, I should convert the entire text to lowercase. That way, \"Hello\" and \"hello\" both become \"hello\" and can be counted together.\n\nNow, dealing with punctuation. Punctuation marks can attach to words and affect how they're counted. For example, \"hello,\" and \"hello\" should be considered the same word. So, I need a way to remove punctuation from the words. One way to do this is to use the `string` module in Python, which has a `punctuation` constant that contains all punctuation marks. I can use this to replace punctuation with spaces or remove them altogether.\n\nAfter normalizing the text, I need to split it into words. In Python, the `split()` method can be used on strings to break them into a list of words, typically using spaces as delimiters.\n\nOnce I have a list of words, I can start counting the frequency of each word. A good way to do this is by using a dictionary, where each key is a unique word and the value is the count of how many times that word appears in the list.\n\nI should also consider that words might have different forms, like plurals or verb tenses, but for this task, I think we're just counting exact matches.\n\nLet me outline the steps I need to take:\n\n1. Get the input text from the user.\n\n2. Convert the text to lowercase to handle case insensitivity.\n\n3. Remove or handle punctuation marks so they don't affect word counts.\n\n4. Split the text into a list of words.\n\n5. Use a dictionary to count the frequency of each word.\n\n6. Print or display the word counts to the user.\n\nI should also think about edge cases, like empty strings, strings with only punctuation, or strings with multiple spaces between words.\n\nLet me think about how to handle punctuation more carefully. If I have a word like \"hello,\" it should be treated the same as \"hello\". So, I need to strip punctuation from the ends of words. Python's `str.strip()` method can be used to remove characters from the beginning and end of a string. I can pass it a string of punctuation marks to remove.\n\nAlternatively, I can use the `re` module, which provides support for regular expressions, to replace all punctuation with spaces or remove them altogether. This might be more efficient and cleaner.\n\nAnother thing to consider is that contractions or hyphenated words might be treated as single words. For example, \"can't\" could be considered one word, or \"well-known\" as a single word. Depending on the requirements, I might need to decide how to handle these cases. For simplicity, I'll treat them as single words.\n\nNow, let's think about implementing this step by step.\n\nFirst, getting the input text. I can use the `input()` function:\n\ntext = input(\"Enter some text: \")\n\nNext, convert it to lowercase:\n\ntext = text.lower()\n\nThen, handle punctuation. I can use the `re` module to replace all non-alphabetic characters with spaces:\n\nimport re\n\ntext = re.sub(r'[^a-z\\s]', ' ', text)\n\nThis regular expression `[^a-z\\s]` matches any character that is not a lowercase letter or whitespace and replaces it with a space.\n\nAfter that, split the text into words:\n\nwords = text.split()\n\nNow, count the frequency of each word using a dictionary:\n\nword_counts = {}\n\nfor word in words:\n\nif word in word_counts:\n\nword_counts[word] += 1\n\nelse:\n\nword_counts[word] = 1\n\nFinally, print the word counts:\n\nfor word, count in word_counts.items():\n\nprint(f\"{word}: {count}\")\n\nThis should give me a list of words and their frequencies.\n\nLet me test this logic with an example. Suppose the input text is:\n\n\"Hello, world! Hello world. This is a test. Hello, hello, hello!\"\n\nFirst, convert to lowercase:\n\n\"hello, world! hello world. this is a test. hello, hello, hello!\"\n\nThen, remove punctuation:\n\n\"hello world hello world this is a test hello hello hello\"\n\nSplit into words:\n\n[\"hello\", \"world\", \"hello\", \"world\", \"this\", \"is\", \"a\", \"test\", \"hello\", \"hello\", \"hello\"]\n\nCount the frequencies:\n\nhello: 5\n\nworld: 2\n\nthis: 1\n\nis: 1\n\na: 1\n\ntest: 1\n\nThat seems correct.\n\nBut wait, in the original text, \"hello,\" appears with a comma, but I've removed the comma. Make sure that the regex is correctly handling punctuation attached to words.\n\nLet me check the regex `re.sub(r'[^a-z\\s]', ' ', text)`. This should replace any character that is not a lowercase letter or whitespace with a space. So, in \"hello,\", the comma should be replaced with a space, resulting in \"hello \". Similarly, in \"world!\", \"!\" is replaced with a space, resulting in \"world \". This seems fine.\n\nHowever, multiple spaces will be created in some cases, like between \"world\" and \"this\" in the example. But when splitting on spaces, `split()` should handle multiple spaces correctly and not include empty strings in the list.\n\nAnother consideration is to make sure that apostrophes in contractions are handled properly. For example, in \"don't\", the apostrophe should be kept so that \"don't\" is treated as one word. My current regex `[^a-z\\s]` would remove the apostrophe, resulting in \"dont\", which might not be desirable.\n\nTo handle this, I can adjust the regex to include apostrophes as allowed characters. Assuming I only want to keep apostrophes in contractions and remove other punctuation, I can modify the regex to `[^a-z\\s']`, which allows lowercase letters, whitespace, and apostrophes.\n\nSo, the updated regex would be:\n\ntext = re.sub(r'[^a-z\\s']', ' ', text)\n\nThis should handle contractions properly.\n\nLet me test this with the word \"don't\":\n\nOriginal: \"don't\"\n\nAfter lowercasing: \"don't\"\n\nAfter regex substitution: \"don't\" (apostrophe is kept)\n\nSplit into words: [\"don't\"]\n\nCounting: \"don't\": 1\n\nPerfect.\n\nAnother edge case: hyphenated words. For example, \"well-known\". Should I treat \"well-known\" as one word or as two words, \"well\" and \"known\"? In English, hyphenated words can function as single words, so I'll treat them as single words.\n\nMy current regex `[^a-z\\s']` would keep the hyphen, so \"well-known\" would be treated as one word, which is what I want.\n\nGood.\n\nNow, what about numbers? For example, \"I have 2 apples.\" Should \"2\" be considered a word? For this task, I'll assume that numbers are not words and should be ignored. So, I need to adjust the regex to exclude numbers.\n\nBut wait, the task says \"a string of text\", and typically, \"text\" refers to alphabetical characters. So, I'll proceed with counting only alphabetical words, ignoring numbers.\n\nTherefore, I'll keep the regex as `[^a-z\\s']`, which excludes numbers.\n\nAnother consideration is uppercase letters. I've already handled case insensitivity by converting everything to lowercase, so that should be fine.\n\nWhat about multiple apostrophes or other special characters? For example, \"it's doesn't\". After processing, it should become \"it's doesn't\", which splits into [\"it's\", \"doesn't\"].\n\nSeems correct.\n\nNow, let's think about the overall structure of the script. I should make sure it's clean and readable. Maybe add some comments to explain each step.\n\nAlso, for testing purposes, I can hardcode a string in the script instead of using `input()`. That way, I can easily run the script with the same text multiple times.\n\nAlternatively, I can make it more interactive by using a loop that allows the user to enter text multiple times.\n\nBut for simplicity, I'll just use `input()` once.\n\nLet me also think about formatting the output. Maybe sorting the words alphabetically before printing them, or displaying the words and counts in a nice format.\n\nFor now, I'll just print each word followed by its count on separate lines.\n\nIs there a more Pythonic way to count the words? Yes, Python's `collections` module has a `Counter` class that can be used to count hashable objects, including words in a list.\n\nSo, instead of using a dictionary, I can import `Counter` from `collections` and use it like this:\n\nfrom collections import Counter\n\nword_counts = Counter(words)\n\nThen, print the counts:\n\nfor word, count in word_counts.items():\n\nprint(f\"{word}: {count}\")\n\nThis is more concise and efficient.\n\nI can consider using `collections.Counter` in the final script.\n\nAlso, to handle the punctuation more efficiently, I can use the `string` module's `punctuation` constant, which contains all punctuation marks. Then, I can replace these characters with spaces.\n\nBut since I'm already using regex, which is more powerful, I'll stick with that.\n\nWait, maybe I should consider using the `split()` method combined with a loop to handle punctuation.\n\nFor example, I can split the text into words based on spaces, then strip punctuation from each word individually.\n\nThis might be a simpler approach.\n\nLet's consider that.\n\nFirst, convert the text to lowercase.\n\nThen, split the text into words using `split()`.\n\nThen, for each word, use `word.strip(string.punctuation)` to remove any punctuation from the ends of the word.\n\nThen, collect the cleaned words into a list and count their frequencies.\n\nThis approach avoids using regex and might be easier to understand.\n\nLet me try this.\n\nFirst, import `string`:\n\nimport string\n\nThen, after converting the text to lowercase, split it into words:\n\nwords = text.lower().split()\n\nThen, clean each word by stripping punctuation:\n\nclean_words = [word.strip(string.punctuation) for word in words]\n\nBut wait, `strip()` removes characters from the beginning and end of the string, but in words like \"don't\", the apostrophe is inside the word, and I want to keep it.\n\nHowever, using `strip(string.punctuation)` would remove only the punctuation from the ends, leaving internal apostrophes intact.\n\nSo, for \"don't\", `strip(string.punctuation)` would keep it as \"don't\".\n\nFor \"hello,\" it would remove the comma, resulting in \"hello\".\n\nPerfect.\n\nBut what about words with punctuation attached? For example, \"hello!\" would become \"hello\", which is what I want.\n\nAnother example: \"world's\". It should remain \"world's\".\n\nWait, but \"world's\" has an apostrophe, which is included in `string.punctuation`. However, I want to keep apostrophes in contractions and possessives.\n\nSo, perhaps I should exclude apostrophes from the set of punctuation to strip.\n\nLooking at `string.punctuation`, it includes characters like !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n\nSo, I can create a string of punctuation to remove by excluding the apostrophe:\n\npunctuation_to_remove = string.punctuation.replace(\"'\", '')\n\nThen, strip these characters from the ends of each word.\n\nSo, the code would look like this:\n\nimport string\n\ntext = \"Your input text here\"\n\ntext = text.lower()\n\npunctuation_to_remove = string.punctuation.replace(\"'\", '')\n\nclean_words = [word.strip(punctuation_to_remove) for word in text.split()]\n\n# Now, count the frequencies\n\nword_counts = {}\n\nfor word in clean_words:\n\nif word in word_counts:\n\nword_counts[word] += 1\n\nelse:\n\nword_counts[word] = 1\n\n# Or using Counter\n\nfrom collections import Counter\n\nword_counts = Counter(clean_words)\n\n# Then, print the counts\n\nfor word, count in word_counts.items():\n\nprint(f\"{word}: {count}\")\n\nThis seems like a solid approach.\n\nLet me test this with an example.\n\nTake the text: \"Hello, world! Hello world. It's a beautiful day, isn't it?\"\n\nFirst, convert to lowercase: \"hello, world! hello world. it's a beautiful day, isn't it?\"\n\nThen, split into words:\n\n[\"hello,\", \"world!\", \"hello\", \"world.\", \"it's\", \"a\", \"beautiful\", \"day,\", \"isn't\", \"it?\"]\n\nThen, strip punctuation excluding apostrophes:\n\nhello, -> hello\n\nworld! -> world\n\nhello -> hello\n\nworld. -> world\n\nit's -> it's\n\na -> a\n\nbeautiful -> beautiful\n\nday, -> day\n\nisn't -> isn't\n\nit? -> it\n\nSo, clean_words = [\"hello\", \"world\", \"hello\", \"world\", \"it's\", \"a\", \"beautiful\", \"day\", \"isn't\", \"it\"]\n\nThen, count the frequencies:\n\nhello: 2\n\nworld: 2\n\nit's: 1\n\na: 1\n\nbeautiful: 1\n\nday: 1\n\nisn't: 1\n\nit: 1\n\nThis looks correct.\n\nComparing this approach to the regex approach, this seems simpler and more straightforward, as it doesn't require importing the `re` module.\n\nTherefore, I'll proceed with this method.\n\nOne potential issue is that `strip()` only removes punctuation from the ends of words, not from the middle. But in English, punctuation in the middle of words is rare, and in cases like hyphenated words (e.g., \"well-known\"), the hyphen is allowed and should be kept.\n\nAnother consideration is that `strip()` only removes punctuation from the ends, not from the beginning or in between letters. So, for words like \"it's\", \"aren't\", etc., the apostrophes are internal and should be kept, which this approach handles correctly.\n\nNow, what about words that are only punctuation, like if someone enters a string of punctuation marks? For example, input text: \"!!! ***\"\n\nAfter lowercasing, splitting, and stripping punctuation (excluding apostrophes), the clean_words list would be empty, as there are no alphabetical words left. So, the word_counts dictionary would be empty, which is correct.\n\nAnother edge case: an empty string. If the input text is empty, the split will result in an empty list, and thus no words to count, which is fine.\n\nWhat if the text contains only punctuation and no words? For example, \".,;:!?\"\n\nAfter processing, clean_words will be an empty list, and thus no words to count.\n\nGood.\n\nWhat if the text contains numbers mixed with words? For example, \"room 101 is on the first floor.\"\n\nUsing this approach, \"101\" would be treated as a word containing digits, which is not an alphabetical word. So, it would be stripped of any surrounding punctuation, but since it's not alphabetical, it won't be included in the word counts.\n\nWait, but in this approach, numbers like \"101\" would be included in the word list because they don't contain punctuation. To exclude them, I need to make sure that only words consisting of alphabetical characters are counted.\n\nTo handle this, I can add an additional step to filter out words that don't consist solely of alphabetical characters.\n\nI can use the `str.isalpha()` method, which returns True if all characters in the string are alphabetic and there is at least one character, otherwise False.\n\nSo, after stripping punctuation, I can filter the list to include only words that are alphabetic:\n\nclean_words = [word.strip(punctuation_to_remove) for word in text.split()]\n\nalpha_words = [word for word in clean_words if word.isalpha()]\n\nThen, count the frequencies of alpha_words.\n\nThis ensures that only words composed entirely of letters are counted, excluding numbers and words with other characters.\n\nLet me test this.\n\nTake the text: \"room 101 is on the first floor.\"\n\nAfter lowercasing: \"room 101 is on the first floor.\"\n\nSplit into words: [\"room\", \"101\", \"is\", \"on\", \"the\", \"first\", \"floor.\"]\n\nStrip punctuation (excluding apostrophes): [\"room\", \"101\", \"is\", \"on\", \"the\", \"first\", \"floor\"]\n\nCheck if alphabetic:\n\n\"room\": True\n\n\"101\": False\n\n\"is\": True\n\n\"on\": True\n\n\"the\": True\n\n\"first\": True\n\n\"floor\": True\n\nSo, alpha_words = [\"room\", \"is\", \"on\", \"the\", \"first\", \"floor\"]\n\nThen, count the frequencies:\n\nroom: 1\n\nis: 1\n\non: 1\n\nthe: 1\n\nfirst: 1\n\nfloor: 1\n\nPerfect.\n\nThis handles numbers correctly by excluding them from the word counts.\n\nNow, let's think about words that contain apostrophes, like \"it's\" and \"isn't\". These should be considered single words, which they are, as long as apostrophes are not stripped.\n\nIn the earlier example, \"it's\" and \"isn't\" were correctly treated as single words.\n\nAnother consideration is words with hyphens, like \"well-known\". Depending on the context, some might want to split hyphenated words into separate words, but for now, I'll treat them as single words, as hyphens are considered part of the word.\n\nIn Python's `string.punctuation`, the hyphen '-' is included, but I'm excluding apostrophes and keeping hyphens as part of the words.\n\nWait, no. In `string.punctuation`, the hyphen '-' is included, but in `punctuation_to_remove`, I'm removing it because I'm excluding only apostrophes from removal.\n\nWait a minute. Let's check `string.punctuation` to see if it includes the hyphen.\n\nLooking at `string.punctuation`, it includes these characters: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n\nYes, it includes the hyphen '-'. So, in `punctuation_to_remove = string.punctuation.replace(\"'\", '')`, hyphens are included in `punctuation_to_remove`.\n\nTherefore, in `word.strip(punctuation_to_remove)`, hyphens at the ends of words would be stripped, but internal hyphens would be kept.\n\nBut in words like \"well-known\", the hyphens are internal, so they would be kept.\n\nHowever, if there are hyphens at the ends of words, like \"hello-\" or \"-world\", the hyphens would be stripped, resulting in \"hello\" and \"world\", which is probably what we want.\n\nSo, this seems acceptable.\n\nAnother potential issue is multiple spaces between words. For example, \"Hello   world\" with multiple spaces. The `split()` method handles this by splitting on any amount of whitespace and returning a list without empty strings.\n\nSo, \"Hello   world\" would split into [\"Hello\", \"world\"], which is correct.\n\nBut, considering that we're stripping punctuation, if there are punctuation marks and spaces, ensure that no empty strings are created.\n\nFor example, \"Hello, world! \" should split into [\"Hello,\", \"world!\"], then strip punctuation (excluding apostrophes) to [\"Hello\", \"world\"], which is correct.\n\nWait, in this case, there's a space at the end. Splitting \"Hello, world! \" would result in [\"Hello,\", \"world!\", \"\"], but `split()` by default removes empty strings at the end if there are trailing spaces.\n\nSo, it should be safe.\n\nAnother consideration is words that are separated by other types of whitespace, like tabs or newlines. The `split()` method handles these as well, splitting on any whitespace.\n\nNow, about the final output. Should I sort the words alphabetically before printing? It might make the output more readable.\n\nYes, sorting the words alphabetically could be a good idea.\n\nTo do this, I can sort the items of the word_counts dictionary before printing them.\n\nIn Python, dictionaries are ordered as of version 3.7, but to ensure sorted order, I can use `sorted()` on the items.\n\nFor example:\n\nfor word, count in sorted(word_counts.items()):\n\nprint(f\"{word}: {count}\")\n\nThis will print the words in alphabetical order.\n\nAlternatively, using `Counter`, I can use its `most_common()` method to sort by frequency, but since the task is just to count frequencies without specifying any particular order, alphabetical order is fine.\n\nNow, let's think about writing the complete script.\n\nI need to:\n\n1. Import necessary modules: `string` and `collections.Counter`.\n\n2. Get the input text from the user using `input()`.\n\n3. Convert the text to lowercase.\n\n4. Define `punctuation_to_remove` as `string.punctuation` without apostrophes.\n\n5. Split the text into words and strip the punctuation from each word.\n\n6. Filter out words that are not purely alphabetic.\n\n7. Count the frequency of each word using `Counter`.\n\n8. Sort the words alphabetically and print their counts.\n\nLet me write a draft of the code:\n\nimport string\n\nfrom collections import Counter\n\ntext = input(\"Enter some text: \")\n\ntext = text.lower()\n\npunctuation_to_remove = string.punctuation.replace(\"'\", '')\n\nwords = text.split()\n\nclean_words = [word.strip(punctuation_to_remove) for word in words]\n\nalpha_words = [word for word in clean_words if word.isalpha()]\n\nword_counts = Counter(alpha_words)\n\nfor word, count in sorted(word_counts.items()):\n\nprint(f\"{word}: {count}\")\n\nThis should work.\n\nLet me test this code with a sample input.\n\nSample input: \"Hello, world! Hello world. It's a beautiful day, isn't it?\"\n\nAfter processing:\n\n- Lowercase: \"hello, world! hello world. it's a beautiful day, isn't it?\"\n\n- Split: [\"hello,\", \"world!\", \"hello\", \"world.\", \"it's\", \"a\", \"beautiful\", \"day,\", \"isn't\", \"it?\"]\n\n- Strip punctuation (excluding apostrophes): [\"hello\", \"world\", \"hello\", \"world\", \"it's\", \"a\", \"beautiful\", \"day\", \"isn't\", \"it\"]\n\n- Filter alphabetic words: [\"hello\", \"world\", \"hello\", \"world\", \"it's\", \"a\", \"beautiful\", \"day\", \"isn't\", \"it\"]\n\nWait, \"it's\" contains an apostrophe, which is allowed, and it's considered alphabetic because it consists of letters and an apostrophe.\n\nBut \"isn't\" would also be allowed.\n\nWait, but `str.isalpha()` considers apostrophes as non-alphabetic characters. So, \"it's\" and \"isn't\" would return False.\n\nWait a second, I need to check `str.isalpha()` behavior with apostrophes.\n\nLet me test this in a Python shell.\n\n>>> \"it's\".isalpha()\n\nFalse\n\n>>> \"isn't\".isalpha()\n\nFalse\n\n>>> \"hello\".isalpha()\n\nTrue\n\nSo, words with apostrophes are not considered purely alphabetic.\n\nBut in this task, I want to include contractions like \"it's\" and \"isn't\" as words.\n\nTherefore, I need to adjust the filtering to allow words that contain apostrophes, as long as the rest of the characters are alphabetic.\n\nOne way to do this is to check that each character in the word is either a letter or an apostrophe.\n\nI can write a custom function to check this:\n\ndef is_alphabetic_with_apostrophes(word):\n\nreturn all(char.isalpha() or char == \"'\" for char in word)\n\nThen, use this function to filter the clean_words:\n\nalpha_words = [word for word in clean_words if is_alphabetic_with_apostrophes(word)]\n\nThis way, words like \"it's\" and \"isn't\" would be included, while words with other punctuation or numbers would be excluded.\n\nLet me test this function with some examples.\n\n\"it's\": all('i'.isalpha(), ''''.isalpha() or ''' == \"'\", 't'.isalpha(), ''''.isalpha() or ''' == \"'\", 's'.isalpha()) \u2192 True\n\n\"isn't\": all('i'.isalpha(), 's'.isalpha(), 'n'.isalpha(), ''''.isalpha() or ''' == \"'\", 't'.isalpha()) \u2192 True\n\n\"hello\": all letters \u2192 True\n\n\"101\": '1'.isalpha() is False \u2192 False\n\n\"well-known\": all letters and hyphen \u2192 False, because hyphen is not an apostrophe.\n\nWait, but in `string.punctuation`, hyphen is included, and I'm removing it if it's at the ends of words.\n\nBut in \"well-known\", the hyphen is internal, so it's kept.\n\nSo, \"well-known\" would be checked by `is_alphabetic_with_apostrophes`, and since '-' is not an apostrophe, it would return False.\n\nTherefore, \"well-known\" would be excluded from the word counts.\n\nIs that desirable? In English, \"well-known\" is a single word, and I think it should be included.\n\nSo, perhaps I need to adjust the filtering to allow hyphens as well.\n\nAlternatively, I can define a set of allowed characters, which include letters, apostrophes, and hyphens.\n\nLet me think about this.\n\nI can define a function that checks if each character in the word is either a letter, an apostrophe, or a hyphen.\n\ndef is_alphabetic_with_apostrophes_and_hyphens(word):\n\nreturn all(char.isalpha() or char in \"'-\" for char in word)\n\nThen, use this function to filter the clean_words:\n\nalpha_words = [word for word in clean_words if is_alphabetic_with_apostrophes_and_hyphens(word)]\n\nThis way, words with apostrophes and internal hyphens would be included.\n\nLet me test this function:\n\n\"it's\": all('i'.isalpha(), ''''.isalpha() or ''' in \"'-\", 't'.isalpha(), ''''.isalpha() or ''' in \"'-\", 's'.isalpha()) \u2192 True\n\n\"well-known\": all('w'.isalpha(), 'e'.isalpha(), 'l'.isalpha(), 'l'.isalpha(), '-'.isalpha() or '-' in \"'-\",'k'.isalpha(), 'n'.isalpha(), 'o'.isalpha(), 'w'.isalpha(), 'n'.isalpha()) \u2192 True\n\n\"101\": '1'.isalpha() or '1' in \"'-\" \u2192 False\n\n\"hello\": all letters \u2192 True\n\n\"don't\": all letters and apostrophe \u2192 True\n\n\"it's\": all letters and apostrophe \u2192 True\n\n\"isn't\": all letters and apostrophe \u2192 True\n\n\"world's\": all letters and apostrophe \u2192 True\n\n\"newly-built\": all letters and hyphen \u2192 True\n\nPerfect.\n\nThis seems like a robust way to include words with apostrophes and hyphens while excluding words with other punctuation or numbers.\n\nTherefore, I'll update the script to use this function.\n\nNow, summarizing the steps:\n\n1. Import necessary modules: `string` and `collections.Counter`.\n\n2. Define a function `is_alphabetic_with_apostrophes_and_hyphens` to check if a word consists only of letters, apostrophes, and hyphens.\n\n3. Get the input text from the user using `input()`.\n\n4. Convert the text to lowercase.\n\n5. Define `punctuation_to_remove` as `string.punctuation` without apostrophes.\n\n6. Split the text into words and strip the punctuation from each word.\n\n7. Filter out words that are not purely alphabetic, allowing apostrophes and hyphens.\n\n8. Count the frequency of each word using `Counter`.\n\n9. Sort the words alphabetically and print their counts.\n\nLet me write the updated code:\n\nimport string\n\nfrom collections import Counter\n\ndef is_alphabetic_with_apostrophes_and_hyphens(word):\n\nreturn all(char.isalpha() or char in \"'-\" for char in word)\n\ntext = input(\"Enter some text: \")\n\ntext = text.lower()\n\npunctuation_to_remove = string.punctuation.replace(\"'\", '')\n\nwords = text.split()\n\nclean_words = [word.strip(punctuation_to_remove) for word in words]\n\nalpha_words = [word for word in clean_words if is_alphabetic_with_apostrophes_and_hyphens(word)]\n\nword_counts = Counter(alpha_words)\n\nfor word, count in sorted(word_counts.items()):\n\nprint(f\"{word}: {count}\")\n\nThis should handle most cases correctly.\n\nLet me test this with a sample input:\n\nSample input: \"Hello, world! Hello world. It's a beautiful day, isn't it? Well-known words like mother-in-law are included, while words with @ symbols are not.\"\n\nAfter processing:\n\n- Lowercase: \"hello, world! hello world. it's a beautiful day, isn't it? well-known words like mother-in-law are included, while words with @ symbols are not.\"\n\n- Split: [\"hello,\", \"world!\", \"hello\", \"world.\", \"it's\", \"a\", \"beautiful\", \"day,\", \"isn't\", \"it?\", \"well-known\", \"words\", \"like\", \"mother-in-law\", \"are\", \"included,\", \"while\", \"words\", \"with\", \"@\", \"symbols\", \"are\", \"not.\"]\n\n- Strip punctuation (excluding apostrophes): [\"hello\", \"world\", \"hello\", \"world\", \"it's\", \"a\", \"beautiful\", \"day\", \"isn't\", \"it\", \"well-known\", \"words\", \"like\", \"mother-in-law\", \"are\", \"included\", \"while\", \"words\", \"with\", \"@\", \"symbols\", \"are\", \"not\"]\n\n- Filter alphabetic words allowing apostrophes and hyphens: [\"hello\", \"world\", \"hello\", \"world\", \"it's\", \"a\", \"beautiful\", \"day\", \"isn't\", \"it\", \"well-known\", \"words\", \"like\", \"mother-in-law\", \"are\", \"included\", \"while\", \"words\", \"with\", \"symbols\", \"are\", \"not\"]\n\n- Note that \"@\" is not alphabetic and not a word with apostrophes or hyphens, so it's excluded.\n\n- Count the frequencies:\n\nhello: 2\n\nworld: 2\n\nit's: 1\n\na: 1\n\nbeautiful: 1\n\nday: 1\n\nisn't: 1\n\nit: 1\n\nwell-known: 1\n\nwords: 2\n\nlike: 1\n\nmother-in-law: 1\n\nare: 2\n\nincluded: 1\n\nwhile: 1\n\nsymbols: 1\n\nnot: 1\n\n- Sorted alphabetically:\n\na: 1\n\nare: 2\n\nbeautiful: 1\n\nday: 1\n\nhello: 2\n\nincluded: 1\n\nit: 1\n\nit's: 1\n\nlike: 1\n\nmother-in-law: 1\n\nnot: 1\n\nworld: 2\n\nwell-known: 1\n\nwords: 2\n\nwhile: 1\n\nsymbols: 1\n\nThis looks correct.\n\nI think this script should work for the given task.\n\n## Final Solution\nTo solve this problem, we need to write a Python script that counts the frequency of each word in a given text, ignoring case sensitivity and punctuation marks.\n\n### Approach\n1. **Input Handling**: Accept input text from the user.\n2. **Text normalization**:\n   - Convert the text to lowercase to handle case insensitivity.\n   - Remove punctuation marks except for apostrophes and hyphens, which are retained to handle contractions and hyphenated words.\n3. **Word Extraction**:\n   - Split the text into words based on whitespace.\n   - Filter out words that are not purely alphabetic, allowing exceptions for apostrophes and hyphens.\n4. **Frequency Counting**: Use a dictionary to count the frequency of each word.\n5. **Output**: Display the word frequencies in alphabetical order.\n\n### Solution Code\n```python\nimport string\nfrom collections import Counter\n\ndef is_alphabetic_with_apostrophes_and_hyphens(word):\n    return all(char.isalpha() or char in \"'-\" for char in word)\n\ntext = input(\"Enter some text: \")\n\ntext = text.lower()\n\n# Define punctuation to remove, excluding apostrophes\npunctuation_to_remove = string.punctuation.replace(\"'\", '')\n\n# Split text into words and strip punctuation\nwords = text.split()\nclean_words = [word.strip(punctuation_to_remove) for word in words]\n\n# Filter words to include only alphabetic characters, apostrophes, and hyphens\nalpha_words = [word for word in clean_words if is_alphabetic_with_apostrophes_and_hyphens(word)]\n\n# Count the frequency of each word\nword_counts = Counter(alpha_words)\n\n# Print the word counts in alphabetical order\nfor word, count in sorted(word_counts.items()):\n    print(f\"{word}: {count}\")\n```\n\n### Explanation\n1. **Input Handling**: The script uses `input()` to accept a string of text from the user.\n2. **Text Normalization**:\n   - Converts the entire text to lowercase using `lower()` to ensure case insensitivity.\n   - Defines a set of punctuation marks to remove, excluding apostrophes.\n   - Strips defined punctuation from each word using `strip()`.\n3. **Word Extraction**:\n   - Splits the text into words using `split()`.\n   - Filters words to include only those consisting of alphabetic characters, apostrophes, and hyphens.\n4. **Frequency Counting**: Uses `Counter` from the `collections` module to count the frequency of each word.\n5. **Output**: Prints the word frequencies in alphabetical order using a sorted loop.\n\nThis approach ensures that the script accurately counts word frequencies while handling case insensitivity and punctuation appropriately."
    }
]