[
    {
        "role": "user",
        "content": "Implement a simple LRU (Least Recently Used) cache in Golang with the following features:\n   - Set maximum capacity for the cache.\n   - Add key-value pairs to the cache.\n   - Retrieve values from the cache using keys.\n   - Remove least recently used items when the cache reaches its maximum capacity."
    },
    {
        "role": "assistant",
        "content": "Sure, I can help you with that! Implementing an LRU cache in Golang is a great way to manage a fixed-size cache where items are evicted based on their usage. I'll guide you through the process step by step.\n\nFirst, let's understand what an LRU cache is. It's a cache replacement policy where the least recently used items are removed first when the cache reaches its maximum capacity. This means that the items that have been used more recently are more likely to be accessed again soon, so they should stay in the cache.\n\nIn Go, we can implement an LRU cache using a combination of a map for quick lookups and a doubly linked list to keep track of the order of usage. The map will store the keys and pointers to their corresponding nodes in the linked list, while the linked list will maintain the order of usage.\n\nHere's a basic outline of the steps we'll take:\n\n1. Define a structure for the cache, including the maximum capacity, a map for key to node mappings, and pointers to the head and tail of the linked list.\n\n2. Create a structure for the nodes in the linked list, each containing a key, a value, and pointers to the previous and next nodes.\n\n3. Implement a method to add a key-value pair to the cache. If the key already exists, update its value and move it to the front of the list. If the cache is at capacity, remove the least recently used item (the one at the end of the list) before adding the new item to the front.\n\n4. Implement a method to retrieve a value by key. If the key exists, return the value and move the corresponding node to the front of the list to mark it as recently used.\n\n5. Implement a method to remove a key-value pair from the cache if needed.\n\nLet's start by defining the cache structure and the node structure.\n\n## Final Solution\nTo implement a simple LRU (Least Recently Used) cache in Golang, we need to manage a fixed-size cache where items are evicted based on their usage. The least recently used items are removed first when the cache reaches its maximum capacity.\n\n### Approach\n1. **Data Structures**:\n   - Use a map to store keys and their corresponding pointers to nodes for O(1) access time.\n   - Use a doubly linked list to maintain the order of usage (most recently used at the front and least recently used at the end).\n\n2. **Operations**:\n   - **Add/Update**: If the key already exists, update its value and move it to the front. If the cache is full, remove the least recently used item (the one at the end of the list) before adding the new item to the front.\n   - **Get**: Retrieve the value for a given key and move the corresponding node to the front to mark it as recently used.\n   - **Remove**: Remove a key-value pair from the cache.\n\n### Solution Code\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n)\n\ntype LRUCache struct {\n\tcapacity int\n\tcache    map[int]*DLinkedNode\n\thead     *DLinkedNode\n\ttail     *DLinkedNode\n}\n\ntype DLinkedNode struct {\n\tkey   int\n\tvalue int\n\tprev  *DLinkedNode\n\tnext  *DLinkedNode\n}\n\n// Add a key-value pair to the cache\nfunc (cache *LRUCache) Set(key int, value int) {\n\tif node, exists := cache.cache[key]; exists {\n\t\tnode.value = value\n\t\tcache.moveToFront(node)\n\t} else {\n\t\tnewNode := &DLinkedNode{key: key, value: value}\n\t\tcache.cache[key] = newNode\n\t\tcache.addToFront(newNode)\n\t\tif len(cache.cache) > cache.capacity {\n\t\t\tremoved := cache.removeTail()\n\t\t\tdelete(cache.cache, removed.key)\n\t\t}\n\t}\n}\n\n// Retrieve the value for a given key\nfunc (cache *LRUCache) Get(key int) int {\n\tif node, exists := cache.cache[key]; exists {\n\t\tcache.moveToFront(node)\n\t\treturn node.value\n\t}\n\treturn -1 // or some default value indicating\u4e0d\u5b58\u5728\n}\n\n// Move a node to the front of the list\nfunc (cache *LRUCache) moveToFront(node *DLinkedNode) {\n\tif node == cache.head {\n\t\treturn\n\t}\n\tcache.removeNode(node)\n\tcache.addToFront(node)\n}\n\n// Remove a node from the list\nfunc (cache *LRUCache) removeNode(node *DLinkedNode) {\n\tif node.prev != nil {\n\t\tnode.prev.next = node.next\n\t} else {\n\t\tcache.head = node.next\n\t}\n\tif node.next != nil {\n\t\tnode.next.prev = node.prev\n\t} else {\n\t\tcache.tail = node.prev\n\t}\n}\n\n// Add a node to the front of the list\nfunc (cache *LRUCache) addToFront(node *DLinkedNode) {\n\tnode.prev = nil\n\tnode.next = cache.head\n\tif cache.head != nil {\n\t\tcache.head.prev = node\n\t}\n\tcache.head = node\n\tif cache.tail == nil {\n\t\tcache.tail = node\n\t}\n}\n\n// Remove the tail node from the list\nfunc (cache *LRUCache) removeTail() *DLinkedNode {\n\tnode := cache.tail\n\tcache.removeNode(node)\n\treturn node\n}\n\n// Initialize the LRUCache\nfunc NewLRUCache(capacity int) *LRUCache {\n\treturn &LRUCache{\n\t\tcapacity: capacity,\n\t\tcache:    make(map[int]*DLinkedNode),\n\t\thead:     nil,\n\t\ttail:     nil,\n\t}\n}\n\n// Example usage\nfunc main() {\n\tcache := NewLRUCache(2)\n\tcache.Set(1, 1)\n\tcache.Set(2, 2)\n\tfmt.Println(cache.Get(1)) // returns 1\n\tcache.Set(3, 3)           // evicts key 2\n\tfmt.Println(cache.Get(2)) // returns -1 (not found)\n\tcache.Set(4, 4)           // evicts key 1\n\tfmt.Println(cache.Get(1)) // returns -1 (not found)\n\tfmt.Println(cache.Get(3)) // returns 3\n\tfmt.Println(cache.Get(4)) // returns 4\n}\n```\n\n### Explanation\n- **Data Structures**:\n  - `LRUCache`: Contains the cache's capacity, a map for quick lookups, and pointers to the head and tail of the doubly linked list.\n  - `DLinkedNode`: Represents a node in the doubly linked list with pointers to previous and next nodes.\n\n- **Operations**:\n  - **Set**: Adds or updates a key-value pair. If the key exists, updates its value and moves it to the front. If the cache is full, removes the least recently used item before adding the new item.\n  - **Get**: Retrieves the value for a given key and moves the corresponding node to the front to mark it as recently used.\n  - **moveToFront**: Moves a node to the front of the list.\n  - **removeNode**: Removes a node from the list.\n  - **addToFront**: Adds a node to the front of the list.\n  - **removeTail**: Removes the tail node from the list.\n\nThis implementation ensures that both set and get operations are performed in O(1) time complexity, making it efficient for caching purposes."
    }
]